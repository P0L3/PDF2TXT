test2_jgra.pickle ---------- ['Characteristics of stratospheric warming events during Northern winter']
10.1002/2015JD024226 The strong interest in Sudden Stratospheric Warmings (SSWs) is motivated by their role in the two-way stratospheric-tropospheric dynamical coupling. While most studies only investigate major SSWs (vortex breakdown), the minor ones (strong vortex deceleration) are overlooked. This work aims at overcoming this gap by providing a comprehensive description of stratospheric warming events without a priori distinctions between major and minor SSWs, leading to a more complete estimate of the stratospheric variability. Warming events are extracted from reanalysis data sets by means of a midstratospheric polar cap temperature daily index. Events are characterized by a bimodal distribution in amplitude, with a broad peak at small amplitudes (inferior to ) and a sharp peak at around . Due to the intrinsic polar vortex dynamics, the warming amplitude presents a distinct seasonal distribution. Small amplitude warmings mainly occur during early and late wintertime by contrast with the larger-amplitude ones occurring during midwintertime. From mid-November to mid-March, the large-amplitude warmings (i.e., strong warming events, SWEs) include both major and minor SSWs, as well as Canadian and Final warmings. Although major SSWs belong to the tail of the SWEs distribution, there is no clear distinction between the major and minor SSWs according to the considered properties of the events. Such result brings out the idea of “warming continuum.” Furthermore, diagnostics of heat ﬂux reveal that there is no statistical diﬀerence between SWEs with regard to their feedbacks on the planetary waves and hence on their potential inﬂuence into the troposphere. Due to the polar night in wintertime, the high-latitude midstratosphere is characterized by westerly winds around the pole: the so-called polar vortex. The polar vortex is one of the most variable features of the zonal mean circulation of the Earth’s atmosphere, which results from a nonlinear interaction between planetary-scale Rossby waves and the zonal ﬂow [ Charney and Drazin , 1961; Matsuno , 1971]. In a span of a few days, this wave mean-ﬂow interaction leads to a zonal ﬂow weakening and a temperature rising over the polar cap by more than in extreme cases [ Scherhag , 1952; Labitzke , 1977]. Such phenomena are known as Sudden Stratospheric Warmings (SSWs) and constitute, since their discovery in 1952 [ Scherhag , 1952], the most impressive dynamical event in the physical climate system. SSWs are commonly deﬁned by the reversal of the meridional temperature gradient, and the diﬀerentiation between major and minor SSWs is made according to the reversal of the westerly stratospheric polar ﬂow at 60 N and 10 hPa ( McInturﬀ [1978], Andrews et al. [1987], and Butler et al. [2015], for a recent discussion on SSW deﬁnitions). Because major SSWs play an important role in the two-way stratospheric-tropospheric dynamical coupling, many studies have focused almost exclusively on them [e.g., Charlton and Polvani , 2007; Gerber et al. , 2009; Cohen and Jones , 2011]. However, to understand the response of the stratosphere to external tropospheric forcing and to better characterize the role of the stratosphere in pathways of climate variability, focusing solely on the extreme SSWs may be insuﬃcient. Indeed, the mean stratospheric response during Northern wintertime to global warming is not necessarily directly related to changes in major SSW frequency [ Karpechko and Manzini , 2012]. A comprehensive estimate of the variability of the wintertime stratosphere, including nonextreme cases, is needed to understand such mean stratospheric changes. Few studies ( Limpasuvan et al. [2004], among others) suggest that minor SSWs can also have a tropospheric signature, justifying the examination of minor SSWs MAURY ET AL. STRATOSPHERIC WARMING EVENTS as well. Moreover, Coughlin and Gray [2009] have shown that minor and major SSWs belong to a continuum of stratospheric warmings, without a well-deﬁned threshold between both SSW types. Such studies raise the question whether considering major and minor SSWs as distinct events makes sense. In this context, this work aims at (i) reducing the gap in the knowledge of nonextreme stratospheric variability, by using less restrictive event deﬁnitions and (ii) addressing the question of how distinct are major and minor SSWs. To achieve these aims, we provide a comprehensive description of the stratospheric warming events occurring during 54 Northern Hemisphere consecutive winters from 1959 to 2013 without any distinction between major and minor SSWs. The stratospheric temperature anomalies tend to propagate downward, and it has been shown that an empirical orthogonal function (EOF) analysis of the polar cap-averaged temperature is well adapted to capture the variability of the stratospheric polar vortex and to study its vertical structure [ Kodera et al. , 2000; Kuroda and Kodera , 2004; Zhou et al. , 2002; Hitchcock et al. , 2013; Hitchcock and Shepherd , 2013]. The originality of the present study lies in considering only positive anomalies of a daily polar cap vertically (50–10 hPa) averaged temperature greater than 1 standard deviation from smoothed climatological mean. By construction our method allows to select events corresponding to a warm middle stratosphere, corresponding to the second temperature EOF in the study of Hitchcock et al. [2013] [see Hitchcock et al. , 2013, Figures 2 and 3]. This paper thoroughly documents and examines the global statistics of the warm events in terms of amplitude and duration and discuss their associated dynamical properties. The paper is organized as follows: The data set and method used are introduced in section 2. Section 3 presents general statistics of stratospheric warm events. It will be shown that stratospheric warm anomalies occurring during the winter can be divided into two populations with regard to their amplitude. Thus, section 4 focuses on the stronger warm anomalies and gives a comprehensive comparison between the aforementioned warm anomalies and well-known climatologies of SSWs. Finally, a summary and a conclusion are provided in section 5. We evaluate the properties of stratospheric warmings for the period from the beginning of October to the end of April, hereafter deﬁned as “winter.” To extend the range of years investigated, two reanalysis products from the European Centre for Medium-Range Weather Forecasts (ECMWF), have been used. The ﬁrst set considers daily data over 20 years from ERA-40 [ Uppala et al. , 2005], from 1 October 1959 to 30 April 1979. The second one considers daily data over 34 years from ERA-Interim (ERA-I) [ Dee et al. , 2011], from 1 October 1979 to 30 April 2013. Considering that ERA-40 data sets are available until 2002, a Student’s test has been used to check that both reanalysis products do not statistically diﬀer in terms of mean and variability during the wintertime for the 20 overlapping years. In this way, 54 consecutive winters are used, spanning from 1959 to 2013, and the resulting merged product is noted ERA in the following. Stratospheric warming events are extracted from the ERA temperature daily time series by means of a midstratospheric polar cap temperature anomaly index. 1. For each year, a stratospheric polar cap temperature is computed from the daily zonal mean temperature by averaging (i) latitudinally, the cosine-weighted temperature between 70 N and 90 N, and (ii) vertically, the pressure-weighted mean between 50 hPa and 10 hPa. This daily ﬁeld is noted , where refers to the temperature and to the time with the subscripts and denoting the day and the year, respectively. 2. For each year, a 21 day running window is applied on the daily values to remove high-frequency variis represented in ations. From the resulting ﬁltered ﬁeld (hereafter, low-frequency)—noted —the mean and the standard deviation Figure 1a, together with its deviation by are calculated. The low-frequency mean 3. The index of midstratospheric polar cap temperature anomalies are eventually deﬁned as the unﬁltered daily temperature deviation from the low-frequency mean, normalized by the low-frequency standard deviation: . MAURY ET AL. STRATOSPHERIC WARMING EVENTS (1) Stratospheric warmings are extracted by selecting only the days for which 1. Thereafter, a stratoremains spheric warming event is deﬁned by a set of consecutive days for which the criterion satisﬁed, allowing to select 188 warming events over the 54 winters. Each stratospheric warming event is characterized by (i) a duration, (ii) an amplitude, (iii) a date of temperature maximum, , and (iv) the 5 day zonal mean zonal wind (60 N,10 hPa) minimum, . The event duration (in days) corresponds to the time remains satisﬁed. The event amplitude (in Kelvin) is calculated during which the criterion from the integral of the daily temperature deviation from the low-frequency mean, divided by the duration. For instance, considering a warming , is evaluated following (2) and ,respectively, denote the ﬁrst and the last days of the warming . Over the duration of each where event, corresponds to the day of the largest daily temperature and corresponds to a 5 day average of the zonal mean zonal wind at 60 N and 10 hPa around the date of zonal wind minimum. The eﬀectiveness of our approach is demonstrated by comparing the low-frequency standard deviation from the mean with the percentile values— —evaluated from the daily temperature time series (Figure 1a, see legend for details). Note that the low-frequency standard deviation approximates the and percentile values (Figure 1a). Therefore, our stratospheric warming events comprise the upper MAURY ET AL. STRATOSPHERIC WARMING EVENTS 20th percentile of the temperatures. We thus selected large anomaly events, while not restricting our selection to the sole extreme events that are conﬁned to the upper 5th or 10th percentile [ Stephenson et al. , 2008]. A selection based on lower thresholds (0.5 and 0 ) would include additional ﬂuctuations. Such ﬂuctuations would either increase the number of small amplitude and short events or extend the duration and lower the amplitude of the events (not shown). The latter eﬀect is caused by an addition of days with small ﬂuctuations before and after the events selected with 1 threshold. The dependence reported in section 3.2 would therefore be blurred. The 1 threshold appears to be the best compromise between maximizing the ensemble size and the rejection of small ﬂuctuations. Figure 1a also indicates that the temperature range between and is largest from December to February, minimal in October–November, and still relatively substantial in March–April, and evidences the well-known subseasonal variations in interannual variability. In addition, the larger temperature range between the high percentile and in comparison with the temperature range between the low percentile and indicates that over the 54 considered winters, strong temperature variability is dominated by strong warmings. To illustrate this point, the midstratospheric polar cap average temperature for three speciﬁc winters is added in Figure 1a. Independently of the winter considered, there is a large day-to-day variability, highlighted by sudden temperature rises, which occur more than twice a winter and exceed the value. Finally, the zonal mean zonal wind at 60 N and 10 hPa for the three previous winters (Figure 1b) illustrates the strong anticorrelation between the wind and the temperature, conﬁrming the using of as an indicator of the perturbation stage of the polar vortex. To assess the characteristics of the warmings, the event amplitude is represented as a function of the date at which the warming maximum occurs (Figure 2a), together with the box-and-whisker plots to quantify the spread of the amplitude values for each month from October to April (Figure 2b). The amplitude of the warm events presents a seasonal dependence. All the October events and 75% of the November ones have amplitudes which never exceed , whereas about 80% of the warmings occurring between December and February (DJF) have an amplitude larger than , extending up to around . During March, the mean and median of the event amplitudes are smaller than during January and February, and are similar to the ones in December, but the probability to have larger amplitude events in December is higher than in March. MAURY ET AL. STRATOSPHERIC WARMING EVENTS In April, around 75% of the warmings have an amplitude less than , like in November. The box size is larger for DJF than for the other months, indicating a larger spread of the amplitude values for the DFJ warmings than the October–November or March–April warmings. When the amplitude is reported as a function of the duration, a large correlation is observed between both (Figure 3a). Overall, the duration of the warmings increases with the amplitude, but this correlation is dependent on season. For instance, warmings with amplitudes tend to be longer in November, March, and April compared to those occurring in DJF. For November this can be explained by a longer radiative damping time than in DJF [ Newman and Rosenﬁeld , 1997], but this does not apply for March–April. Compared to midwinter period, amplitude warmings may be large enough to disturb durably the late-winter vortex. Indeed, due to the strong midwinter vortex, the stratospheric circulation may return faster to its climatological state than during late winter. Figure 4 shows the probability density function (PDF) of the event amplitude (i.e., the axis in Figure 2a) and duration (i.e., the axis in Figure 3a). The PDF of the amplitudes reveals a bimodal distribution with two relative maxima. The ﬁrst relative maximum is a broad peak at low amplitudes ( ), approaching the amplitude median value, and the second one is at around and delimits the upper 20% of the larger-amplitude warm events. When the early wintertime (October to mid-November), the midwintertime (mid-November to mid-March), and the late wintertime (mid-March to April) are considered separately, Figure 4a reveals a subseasonal dependence of the frequency in amplitude values. The ﬁrst warming set ( ) mainly consists of (i) early-winter warmings and (ii) around the half of late-winter warmings. Conversely, the second warming set ( ) mainly consists of midwinter warmings and the other half of late-winter warmings. Note that the secondary peak is almost exclusively explained by midwinter events. The PDF of the event duration (Figure 4b) is rather sharply decreasing for small-duration values, given that 50% of the selected events last less than 10 days (Figure 3a, and see also the positive skewness seen in Figure 3b). Although less pronounced than for the amplitude values, the PDF of event duration also hints at bimodality. This possibility is more apparent for the midwinter PDF (break point around 20 day duration and a second maximum at around 30 day duration). In this section, the temporal distribution of warm events is analyzed together with the stage of the polar vortex during the events. Figure 5 reports the warm events as a function of the date with their amplitude and duration, stratiﬁed according to their amplitude ( , , and , see legend for details). The daily values of the zonal mean zonal wind at 60 N and 10 hPa are also superimposed in Figure 5 for the 54 winters. The total frequency of the event occurrence by winter (3.8) is quasi uniformly distributed over the 54 winters (not shown). Main diﬀerences between winters come from the numbers of small amplitude ( ) warmings MAURY ET AL. STRATOSPHERIC WARMING EVENTS (see, for instance, winters 1971–1972 and those from 1990 to 1994). As already noticed in Figure 2, these small amplitude events ( ) mainly occur during October, November, and April, and they tend to happen twice or more in a short time period. For larger amplitude events ( ) there are two distinct distributions of events according to their duration. Short-time events are essentially occurring closely to other events (e.g., December/January 1975/1976 to January/February 1991), whereas long-time ones are rather “isolated” MAURY ET AL. STRATOSPHERIC WARMING EVENTS (e.g., February 1963 to January 1985). Note that during the second part of November, warm events with last more than 10 days and are isolated like in DJF (see, for instance, in November 1968 or 1996). Because the time between two closely occurring consecutive warmings is generally less than 20 days (not shown), it is natural to interpret such a group of events as a response to pulses of planetary wave activity [ Zhou et al. , 2002]. Such successive warm events are thus not independent from each other and belong to the same perturbation stage of the polar vortex, and we label them “clustered events.” This interpretation is supported by the zonal wind value associated to each clustered events (e.g., December/January 1976–1977 or January/February 1991). Figure 5 suggests that a distinct seasonal dependence between the amplitude of the events and the strength of the polar vortex tend to be related to a weak vortex during November (around 10 m s ) but to a total wind reversal at the end of the winter in March and April due to the vortex decay. In the same way, events with are associated with zonal wind values of 15–20 m s during October and the ﬁrst part of November, MAURY ET AL. STRATOSPHERIC WARMING EVENTS but with negative wind values during the second part of March and April. These small events are indicative of some ﬂuctuations of the vortex intensity during the polar vortex strengthening (early winter) or decay (late winter) but do not lead to dramatic vortex perturbations. On the opposite, during midwinter the warmings with are generally accompanied with dramatic vortex perturbations. The majority of the warmings having are associated with a total vortex breakdown, whereas events with (medium circles) are mainly associated to a weak polar vortex, with zonal mean zonal wind around 10 m s . However, the amplitude value of is not a well-deﬁned threshold to separate the events into two diﬀerent vortex states. Indeed, large warming amplitudes can also be associated with a weak vortex (i.e., in February 1981 or during January–February 1989–1994). Conversely, medium-amplitude events can be associated with a total wind reversal (i.e., February 1966 to November 1968 to February 2007). To clarify the linkage between the event amplitude/duration and zonal wind by season, in Figure 6 the events are grouped according to the three winter periods: early, mid, and late winter. Figures 6a and 6b show a strong correlation between the 5 day zonal wind minimum and both amplitude and duration for the midwinter events. Both ﬁgures conﬁrm that earlyand late-wintertime events do not show the same relationship between amplitude or duration and the wind than for the midwintertime events. Thus, only midwintertime events are considered to build the PDF of the amplitude and duration, stratiﬁed according to the value of (Figures 6c and 6d). Figure 6c shows that the median value tends to separate the midm s , winter events according to the wind value m s . Considering only the events with a bell-shaped “continuum” of stratospheric warming emerges, instead of two distinct stratospheric winter states where minor and major SSWs are separated. This result corroborates the idea of warming continuum outlined in Coughlin and Gray [2009], expanding their results to a larger sample of events. Concerning duration, Figure 6d shows that the warm events associated to a total vortex breakdown tend to have longer duration than events associated to a weak vortex, 70% of the latter persisting less than 10 days. The warming duration could therefore be a condition to discriminate most of the minor SSWs from the major ones. This result is possibly consistent with the correlation between the depth and the duration of the warmings found by Hitchcock et al. [2013]. Interestingly, when considering wind anomalies instead of absolute wind values, a correlation with the warming amplitude is observed, independently of the winter season (Figure 6e). On the contrary, the correlation between the warming duration and the wind anomalies remains seasonal dependent (Figure 6f ). The analysis of the previous section has demonstrated that the median amplitude value divides the events into two groups that present both distinct seasonal and dynamical properties. We therefore chose as our threshold for large-amplitude events in the following. In addition, closely occurring events with an interwarming time lower than 20 days have been merged together. After this selection and merging, the number of stratospheric warming events is reduced to about 40%. We call this new set of events the strong (stratospheric) warming events (SWE). The meridional heat ﬂux is a fundamental quantity for understanding the Northern Hemisphere stratosphere behavior [ Newman and Nash , 2000]. The heat ﬂux at 100 hPa averaged between 55 N and 80 N [see Andrews et al. , 1987] is presented in Figure 7. Superimposed to the heat ﬂux, the SWEs are depicted in terms of their amplitude, duration, and sign of . The meridional heat ﬂux is larger from December to March, mainly positive, indicating an upward wave propagation from the troposphere, and presents interannual variability correlated with the occurrence of SWEs, coherently with Polvani and Waugh [2004]. Visual inspection of Figure 7 shows that, independently of the event amplitude, the heat ﬂux tends to be large before the date of maximum temperature of SWEs and drastically decreases thereafter. In a number of cases, the heat ﬂux actually becomes negative after the day . The meridional heat ﬂux, being directly proportional to the vertical component of the Eliassen Palm ﬂux [ Andrews et al. , 1987], informs of the planetary wave propagation through the atmosphere [ Pawson and Kubitz , 1996; Newman et al. , 2001]. In this way, a positive eddy heat ﬂux indicates that waves propagate vertically from the troposphere to the stratosphere, and conversely, a negative eddy heat ﬂux indicates a downward propagation of planetary waves to the troposphere [ Perlwitz and Harnik , 2003]. As outlined by Kodera et al. [2013, 2016], a negative meridional heat ﬂux after a major SSWs can therefore indicate reﬂection of planetary waves by the perturbed polar vortex. Such a wave reﬂection leads to an MAURY ET AL. STRATOSPHERIC WARMING EVENTS ampliﬁcation of the tropospheric planetary wave structure inducing strong westerlies over the North Atlantic and blocking over the North Paciﬁc sector and thus impact tropospheric weather [ Kodera et al. , 2016]. Interestingly, Figure 7 demonstrates that a negative meridional heat ﬂux can also appear thereafter; SWEs without a wind reversal (see, for instance, March 1972 or February 1990). This observation suggests that some minor SSWs could also lead to tropospheric impacts. Composites of heat ﬂux anomalies have been evaluated for the midwinter SWEs with and separately, centered at the date corresponding to the lag day. Composites show a signiﬁcant diﬀerence about 10 days before lag where a larger forcing is observed for events with compared with events with (Figure 8, red and orange curves). However, surprisingly, there is no signiﬁcant difference between the two composites from lag day to lag . In the case of a vortex breakdown, waves MAURY ET AL. STRATOSPHERIC WARMING EVENTS anomaly for events with , given that they are mostly made of major SSWs. But the composite for events with is not statistically diﬀerent from the one with , whereas this population of events is mainly associated with minor SSWs. To demonstrate the insensitivity to the sign of the zonal wind in the heat ﬂux evolution for the SWEs, two additional composites are shown, for which the SWEs are stratiﬁed according to the sign of (black and grey lines in Figure 8). Although the forcing and the degree of vortex perturbation Indeed, after the lag and on the entire period (up to lag ) the heat ﬂux drops below the climatology for all cases. This result suggests that a total wind reversal is not a requirement for the wave activity to drop signiﬁcantly. Therefore, the dynamics of a perturbed vortex cannot be distinguished by the sign of the zonal wind, corroborating the idea of a “continuum” of SSWs. This part intends to compare the SWEs with published lists of SSWs. Such lists have been presented by Charlton and Polvani [2007] (CP07), Mitchell et al. [2012] (Mi12), Hu et al. [2014] (Hu14), and Labitzke and Naujokat [2000] (LN00). CP07 identify SSWs following the zonal mean zonal wind reversal at 60 N and 10 hPa, whereas Mi12 use a method based on a vortex moment analysis. Both studies use the ERA-40 reanalysis from winter 1957–1958 to 2000–2001. Hu14 identify major SSWs by looking for positive meridional temperature gradient northward to 60 N at 10 hPa and a zonal mean zonal wind reversal at 65 N, with NCEP-NCAR reanalysis from winter 1957–1958 to 2011–2012 [ Kalnay et al. , 1996]. As we use the extended wintertime season from October to April, the occurrence of our earlyand late-winter SWEs can be compared to the Canadian warming (CW) and Final warming (SFW) listed in LN00 and Hu14, respectively. Note that for the CW list, only the months when the warmings occur are available. The comparison between the early-winter SWEs and CWs is justiﬁed because many of them are considered as CW [ Labitzke , 1977]. MAURY ET AL. STRATOSPHERIC WARMING EVENTS The frequency of occurrence of the SWEs is around 1.8 events a year, against 0.6/0.65 in CP07/Hu14, and close to one event a year in Mi12. Clearly, these diﬀerences are related to the inclusion of the events usually termed as minor SSW (here and in Mi12) by a textbook deﬁnition [ Andrews et al. , 1987]. Also, we consider earlyand late-winter SWEs without distinction neither between midwinter SSWs and SFWs nor between early/midwinter and CWs, whereas CP07, Hu14, and Mi12 make this distinction between their events. To contrast the SWEs presented here with other climatologies of SSWs, our selected events are represented in Figure 9 as a function of the day and the year, together with events listed in CP07, Hu14, Mi12, and LN00. Canadian warmings. Among the 18 CWs listed by LN00, about 65% (11 CWs) are indeed selected. Note that, because LN00 only report the month where the CWs happened and not the date, the SWE occurring in November 1966 is considered as the CW occurring in December 1966. The 35% missing are likely due to the fact that CWs are mainly associated with small anomalous temperatures in the lower levels of the stratosphere [ Manney et al. , 2001]. For instance, CWs in November 1962 and December 1978 are associated with a warm anomaly that occurs below 50 hPa (not shown), while our selection is based on a (pressure-weighted) temperature average between 50 and 10 hPa. Midwinter events. Most of the major SSWs identiﬁed by CP07 (red stars) and Hu14 (dark blue stars) coincide with the SWEs, except for the case of 20 March 2000 (only selected by CP07). This particular SSW has a short time period of zonal wind reversal and a positive temperature anomaly conﬁned above 20 hPa (not shown), precluding its selection by our method. It is important to note that the trend toward a diminution of SSW activity during the 1990s [ Pawson and Naukojat , 1999, CP07] is not clearly observed in Figure 9. In agreement with Mi12, SWEs are indeed observed during this decade, even though most of them are considered as minor warmings. Moreover, this observation remains consistent with Butler et al. [2015], reporting warm events during the 1990s for the methods used in Gerber et al. [2010] and Limpasuvan et al. [2004]. Final warmings. It is important to recall that SFWs happen at the end of the winter during the transition between winter (westerly winds) and summer (easterly winds) circulation. However, only about 30% of the SFWs listed in Hu14 are identiﬁed in our analysis. According to Figure 5, the selected late-winter SWEs are accompanied by a drastic wind deceleration whereas SFWs identiﬁed by Hu14 are not systematically associated with such a wind deceleration but rather to a smooth transition to easterly winds. Also, Figure 7 shows an enhanced heat ﬂux as precursor for most of the late-winter SWEs identiﬁed here, whereas the heat ﬂux is weak for most of the unselected SFWs listed in Hu14. This indicates that our method seems to discriminate SFWs due to a dynamical forcing, which can be considered as “sudden” SFWs and prevent the vortex recovery before the spring, from those—unselected—due to radiative processes [ Sun and Robinson , 2009]. This work investigated the occurrence of stratospheric warming events, from the beginning of October to the end of April, in an extended reanalysis data set based on the merging of ERA-40 and ERA-I. Two selection criteria have been used to select the stratospheric warming events. The ﬁrst one provides a general description of temperature variability in the stratosphere, including nonextreme events (section 3). The second one, a more restrictive criterion, is based on the statistical properties of the warming set and on dynamical considerations associated with them, and aims at investigating whether there is a clear separation between major SSWs and minor SSWs (section 4). The ﬁrst selection criterion was used to characterize stratospheric warming events in terms of amplitude, duration, and occurrence. A bimodality in the distribution is found for the event amplitude, with each subdistribution amounting to about half of the total events. The amplitude distribution with mostly consists of earlyand late-winter events, whereas the distribution with mostly consists of midwinter events and has a sharper amplitude maximum at . Diagnostics of the zonal mean zonal wind reveal that both amplitude and duration of the warmings correlate with the zonal wind, for events occurring from mid-November to mid-March. During this winter period, the majority of events associated with a weak zonal wind (minor SSWs) and the totality of events with negative zonal winds (major SSWs) have also an amplitude . Within our statistics, the threshold of therefore separates warm events with distinct dynamical properties. We attribute the seasonal dependence of the warming amplitude to the climatological vortex dynamics that evolves during the wintertime due to the polar night. This seasonal dependence is not as clear in the case of the warming duration. However, our analysis reveals that major SSWs tend to be longer-lived events than minor SSWs. MAURY ET AL. STRATOSPHERIC WARMING EVENTS The second selection criterion allows for selecting the “strong (stratospheric) warming events (SWEs)”, including both major and minor SSWs, and also Canadian warmings (CWs, LN00) and a subsection of Final warmings (SFWs, Hu14). Our method therefore succeeds in a broad characterization of stratospheric variability that is not only restricted to the extreme variability. Moreover, our method allows the selection of SFWs that are likely dynamically driven rather than resulting from radiative processes [ Sun and Robinson , 2009]. Among the m s —can be described as a “warming conselected SWEs, the midwinter ones—associated with a tinuum,” without distinction between the diﬀerent SSW types. This result conﬁrms the conclusion of Coughlin and Gray [2009] who introduced the existence of a warming continuum and extends it to a wider range of events. Diagnostics of heat ﬂux anomalies demonstrate that for both major and minor SSWs the heat ﬂux drops below the climatology after the warmings peak. This result suggests that a total wind reversal is not a strict prerequisite for the wave activity to drop signiﬁcantly. This drop can not be explained by a simple application of the theory of Charney and Drazin [1961], as observed by Hitchcock et al. [2013]. The warming continuum observed here explains both (i) the diﬃculties in developing a standard deﬁnition for SSWs [ Butler et al. , 2015] and (ii) the discrepancies between the SSWs selected by diﬀerent protocols [ Palmeiro et al. , 2015]. Because we demonstrate that minor SSWs are not fundamentally diﬀerent from the major ones, classiﬁcations of SSWs based on the wind reversal become questionable. Thereafter, minor SSWs may be as important as major SSWs in terms of dynamical coupling perspectives between stratosphere and troposphere, for instance, via stratospheric waves reﬂection [ Kodera et al. , 2016]. Finally, as our method is an easily derived diagnostic, based on only one variable (the temperature), the statistics presented here can be very useful in the context of evaluating atmospheric models. Previous model evaluations only focused on major SSWs and revealed large discrepancies in the occurrence of major stratospheric warmings [ SPARC , 2010; Charlton-Perez et al. , 2013]. This new diagnostic and a more extensive analysis of the stratospheric warmings may help to reduce and/or understand model biases in variability and their consequences. In a more general view, it is expected that the present contribution should help both to evaluate the simulation of the dynamical interaction between SSWs and the background ﬂow in models and to study the eﬀect of changes in both extreme and nonextreme variabilities and SSWs on the stratospheric response to global warming. 
test2_jgra.pickle ---------- ['A global electric circuit model within a community climate model']
10.1002/2015JD023562 To determine the complex dependencies of currents and electric ﬁelds within the Global Electric Circuit (GEC) on the underlying physics of the atmosphere, a new modeling framework of the GEC has been developed for use within global circulation models. Speciﬁcally, the Community Earth System Modeling framework has been utilized. A formulation of atmospheric conductivity based on ion production and loss mechanisms (including galactic cosmic rays, radon, clouds, and aerosols), conduction current sources, and ionospheric potential changes due to the inﬂuence of external current systems are included. This paper presents a full description of the calculation of the electric ﬁelds and currents within the model, which now includes several advancements to GEC modeling as it incorporates many processes calculated individually in previous articles into a consistent modeling framework. This framework uniquely incorporates eﬀects from the troposphere up to the ionosphere within a single GEC model. The incorporation of a magnetospheric potential, which is generated by a separate magnetospheric current system, acts to modulate or enhance the surface level electric ﬁelds at high-latitude locations. This produces a distinct phasing signature with the GEC potential that is shown to depend on the observation location around the globe. Lastly, the model output for Vostok and Concordia, two high-latitude locations, is shown to agree with the observational data obtained at these sites over the same time period. The global electric circuit (GEC) represents the electrical pathway by which charge is exchanged between the conductive surface of the Earth and the highly conductive ionosphere, which are held at diﬀerent potentials by electriﬁed clouds. Inherently atmospheric, this circuit is dependent on many of the physical and chemical processes that can aﬀect charge and its transport in the atmosphere, both spatially and temporally. Indications of this global circuit were ﬁrst measured by the Carnegie expedition documenting temporal variations of surface fair-weather vertical electric ﬁelds [ Harrison , 2013]. These measurements were correlated with global thunder count variations in universal time (UT) suggesting that a global circuit exists with thunderstorms acting as generators. These generators drive currents capable of inﬂuencing the electric ﬁeld behavior around the globe [ Whipple , 1938]. These currents, generated more broadly by electriﬁed clouds, produce a potential diﬀerence (PD) between the ground and ionosphere of around 250 kV. The potential diﬀerence leads to an average fair-weather return current density of a few pA/m . Many reviews have been written on the GEC discussing the generation of these parameters, such as Rycroft et al. [2008], Liu et al. [2010a], and Williams and Mareev [2014]. The ﬁrst numeric model to address the complexities of the GEC was developed by Hays and Roble [1979]. They made several assumptions on the conductivity and source distributions to represent the problem with analytic spherical harmonic functions in several distinct domains, but nonetheless were able to determine how currents were distributed throughout the atmosphere. In a separate paper, Roble and Hays [1979] included large-scale horizontal potentials maintained by the ionospheric dynamo and magnetospheric convection and broadly discussed their inﬂuence on the GEC. Since this ﬁrst model, numerous other eﬀorts have been undertaken, mostly focusing on advancing conductivity formulations or source formulations independently and then solving for the resulting electrical perturbations. Several of these models have advanced conductivity perturbations to the system, such as Tinsley and Zhou [2006] and Odzimek et al. [2010]. These models then solve for the electrical properties of the circuit by solving for vertical resistances and equivalent circuit elements. LUCAS ET AL. CESM1(WACCM) GEC MODEL Today, highly sophisticated global climate models are able to account for physical and chemical processes taking place in Earth’s atmosphere. However, these models have not considered the global electrical processes that are occurring within the system. Recently, Mareev and Volodin [2014] have implemented GEC solutions to a global circulation model. Although of similar intent, our work expands on the GEC formulation by including dynamic changes to conductivity due to clouds and aerosols, evolving source currents through internal convective processes, and external inﬂuences imposed by electric potentials from the magnetosphere. This involves implementing source and conductivity formulations within the same model and allowing them to evolve together in time. The model utilized for this work is the freely available Community Earth System Model, CESM1(WACCM), which can be obtained from their website: www.cesm.ucar.edu. The CESM1(WACCM) formulation is a comprehensive numerical model spanning the range of altitude from Earth’s surface to the thermosphere. The community-wide model uniﬁes certain aspects of the upper atmosphere, middle atmosphere, and troposphere modeling into a common numerical framework. This makes it an excellent platform for a GEC simulation as much of the detailed atmospheric physics can be incorporated. The global atmospheric model solves the primitive equations and radiative transfer equations, similar to a weather forecast model and calculates parameterizations for subgrid processes such as convection. From this, temperature, pressure, and water vapor content are obtained for every grid box and every time step. A description of the model integration and scientiﬁc capabilities within CESM1 can be found in Hurrell et al. [2013]. Additional details and references, including the major equations and processes, can be obtained within the user’s guide on the CESM website http://www.cesm.ucar.edu/models/cesm1.0/cam. For this work, we are using the stand-alone atmospheric component conﬁguration with the Community Atmosphere Model (CAM5) extended to the Whole Atmosphere Community Climate Model (WACCM). A detailed description of some of the upper atmospheric physics underlying the program can be found in Marsh et al. [2013, and references therein]. The model is free running with a time step of 30 min, a resolution of 2.5 in longitude by 1.9 in latitude, with 70 vertical levels distributed in modiﬁed pressure coordinates, which correspond to roughly 140 km as the top height of the model. This paper presents a new method for determining the electrical parameters of the global electric circuit within an evolving physics-based framework of a community climate model. Herein this new GEC model will be referred to as WACCM-GEC. An overview of the equations utilized in the model development will be covered in section 2. The required variables and the calculation of conductivity and sources within the model will be discussed in section 3. Finally, section 4 will demonstrate the variability of output electric ﬁelds from WACCM-GEC due to externally generated magnetospheric potentials. The model electric ﬁelds are shown to reproduce observed diurnal variations in the electric ﬁelds at Vostok and Concordia, two Antarctic sites. WACCM-GEC is an extension of CESM1(WACCM) that calculates fair-weather electric ﬁelds and currents within the atmosphere. The atmospheric variables that contribute to the electrical properties of the atmosphere are calculated based on the underlying physics variables computed within CESM1(WACCM) and are used for conductivity and source calculations, as discussed in sections 3.1 and 3.2. The essential process to be evaluated within the WACCM-GEC is to satisfy the current continuity equation. The two driving parameters in solving the current continuity equation, (1) for the potential are the conductivity, , and the source distribution, . The conductivity of air generally increases exponentially with altitude, following the decreasing density of the atmosphere. There are also perturbations to this exponential proﬁle caused by ion creation and loss processes, which includes clouds and aerosols. These perturbations to conductivity are covered in more detail within Baumgaertner et al. [2013], Zhou and Tinsley [2010], Tinsley and Zhou [2006], and in section 3.1. The source distribution within previous global models has relied upon thunder and convective area distributions [ Markson , 2007; Mareev and Volodin , 2014]. For a simpliﬁed representation of storms, an electriﬁed cloud will generally have a positive charge center located above a negative charge center. These two charge centers are then represented within the mathematical models as dipole current sources, as mentioned by Tzur and Roble [1985]. In WACCM-GEC the source currents are parameterized using the convective mass ﬂux generated within the model, as described in section 3.2. LUCAS ET AL. CESM1(WACCM) GEC MODEL To study the GEC, measurements are done in fair-weather regions where there are no sources around the measurement location. This can be accomplished by solving for the source currents and fair-weather currents separately and adding the solutions together due to the linearity of the partial diﬀerential equation. The two separate systems being solved are Fair-weather: Source region: (2) (3) with and satisfying representing the fair weather and source potentials, respectively, and the total potential . In this problem we apply Dirichlet (ﬁxed potential) boundary conditions on the upper and lower boundaries. Earth’s surface will be deﬁned as being a zero potential surface with zero net current ﬂow through the surface. The upper boundary potential is determined by the source and conductivity distribution in the domain while enforcing that no net current ﬂows through the boundary. A diﬀerent approach to determining the upper boundary potential is addressed in Kalinin et al. [2014], where they discuss the contribution to potential for individual storms, including source modiﬁcations due to the conductivity within the cloud. The conductivity variability within the source clouds inﬂuencing the source strengths is not implemented in this version of WACCM-GEC. The top potential brings closure to the system, so that there are no leakage currents from the GEC, which follows from ensuring current continuity as seen in equation (1). Other studies determine the contribution to the upper boundary potential directly from each storm [ Mareev and Volodin , 2014]. The use of this method implies that the atmosphere follows a known exponential conductivity proﬁle everywhere across the globe. This indicates that an increase in resistance far away from the storm would not inﬂuence the potential of the ionosphere. In this work, we relax the assumption that the conductivity of the atmosphere follows an exponential and calculate the current that storms contribute to the system and determine the potential based on the total current and resistance of the system. The potential of the ionosphere is solved in a two-step approach. First, the source region is solved with 0 V potentials on the top and bottom of the domain. Integrating over the top and bottom boundaries determines how much current is available in the domain. This allows one to know exactly how much current is required to close the system and conserve currents within the model, which is the downward current that is passing through the fair-weather regions. The second step is to calculate the total resistance of the atmosphere. Once the total resistance and total current are known, one can apply Ohm’s law to determine the potential needed at the top boundary of the fair-weather region. Another means to calculate the current is to separate the source term, , into individual source columns applying the linearity argument again, such that and which allows WACCM-GEC to calculate the total current in a grid cell, , due to the sources within that grid cell. Each electriﬁed cloud in general only covers several kilometers in the horizontal, while the horizontal resolution for WACCM is approximately 100–200 km. This means it is diﬃcult to resolve individual storms in climate models, unless they are large convective systems. Therefore, a parameterization for determining the source strength within each column is described in section 3.2. Figure 1 shows a map of the mean current produced in each column over the 3 month model simulation. Now the total current ﬂowing in the domain can be calculated by summing up all of the column contributions (4) After solving for the total source contribution current, one can focus on the fair-weather domain, equation (2), and determine the potential of the ionosphere. With the high conductivities at the boundary of the fair-weather GEC, the boundaries can be thought of as constant potential surfaces, where any excess charge is redistributed quickly compared to the time scales of interest. As a standard deﬁnition throughout the LUCAS ET AL. CESM1(WACCM) GEC MODEL results, we deﬁne the potential at the surface of the Earth to serve as our reference and set it to a value of zero. The upper atmosphere is then typically between a positive potential range of 250–350 kV relative to Earth’s surface. This now allows the potential diﬀerence between the ionosphere and ground due to GEC sources, , to be determined through the following relation between the total resistance of the atmosphere, , and the total GEC source current, , PD (5) where we have used the fact that column resistances, , will add in parallel with being the area of the column. With the PD of the upper boundary known, one can determine the vertically uniform column current densities and height-dependent electric ﬁeld in the fair-weather region by utilizing the ionospheric potential of that column as follows (where for a horizontally uniform potential in the ionosphere). (6) (7) with being the column current density for a speciﬁc column, and is the electric ﬁeld at an altitude within the column. The previous discussion assumes a constant potential surface throughout the upper boundary. However, there are separate current systems ﬂowing within the ionosphere, due to the ionosphere neutral wind dynamo, and between the ionosphere and magnetosphere, due to the solar wind-magnetosphere dynamo, that create and maintain horizontal potential diﬀerences in the ionosphere. These current systems are LUCAS ET AL. CESM1(WACCM) GEC MODEL assumed to be in a separate domain and do not contribute as a source strength to the GEC but rather modify the distribution of potentials of the upper boundary in WACCM-GEC. The horizontal potential created in the ionosphere by these two additional external current systems is incorporated into WACCM in a manner described by Liu et al. [2010b]. At high latitudes, the horizontal potential created in the ionosphere by the solar wind-magnetosphere dynamo is described by the Weimer model [ Weimer , 1995]. This model is implemented within WACCM to provide a magnetospheric potential over the entire globe. This allows for temporal and spatial variations from solar inﬂuences to be incorporated into WACCM-GEC by perturbing the upper boundary potential over every column. Weaker but horizontally structured potential in the ionosphere can also be created by the neutral wind dynamo. This is accounted for at middle to low latitudes by incorporating an empirical model based on observations described by Richmond et al. [1980]. The variable will be used to represent the potential solely due to the magnetosphere current system and neutral wind dynamo that contributes to the total upper boundary potential. Figure 2 shows the output of a typical global ionosphere potential pattern during a quiet solar day that combines both of these external current systems. The stronger and more dynamic potential diﬀerences lie at high latitudes where the solar wind-magnetosphere dynamo is most eﬀective. To maintain current continuity within the GEC system, we modify the upper boundary potential globally to ensure that the GEC currents are the only current source in the atmosphere. This can be viewed as allowing for a ﬂoating potential . PD PD The potential at every grid column is then calculated as follows: PD PD PD PD (8) (9) where the ﬂoating potential is incorporated because we are maintaining current continuity between the ground and ionosphere. Finally, this new potential diﬀerence of the column is used to calculate the current density and electric ﬁeld according to equations (6) and (7). Within WACCM-GEC the ﬂoating potential from the magnetospheric perturbation modiﬁes the global potential by less than one tenth of 1%. This small contribution is due to the fact that the magnetospheric potentials have both positive and negative components and that the column resistance, , over these areas does not vary signiﬁcantly. However, the local potential changes introduced to individual columns will be shown to have signiﬁcant local eﬀects. LUCAS ET AL. CESM1(WACCM) GEC MODEL To solve for currents and electric ﬁelds in the GEC, the full spatial and temporal distribution of the conductivity and source currents within the modeling framework need to be assessed. Numerous GEC models have been developed in the past to describe diﬀerent aspects of the circuit, as discussed in section 1. Recent model developments have allowed for better characterization of the electrical connections within the atmosphere by utilizing higher-resolution meshes and novel numerical techniques [ Odzimek et al. , 2010; Zhou and Tinsley , 2010; Kalinin et al. , 2014; Bayona et al. , 2015]. In WACCM-GEC, the conductivity follows the methodology of Baumgaertner et al. [2013, 2014] and is discussed in section 3.1, and the sources follow a similar methodology of Kalb et al. [2014] and are discussed in section 3.2. These variables are incorporated into the same computational framework to use a consistent time step and spatial grid. The conductivity within clouds considers only those fair-weather clouds aﬀecting the resistance and, consequently, the return current. Electriﬁed clouds, serving as source currents, inherently consider conductivity changes within the clouds through the source parameterization. This is in contrast to a modiﬁcation made to the conductivity within the clouds in other models [ Slyunyaev et al. , 2015]. The conductivity is calculated in the same manner as Baumgaertner et al. [2013, 2014]. This includes calculating the ion pair concentration and the mobility of the ions , such that, (10) where is the elementary charge. To create the ion pairs, ionizing sources are incorporated into WACCM-GEC which includes galactic cosmic rays (GCRs), radon emission from the ground, and solar proton events. Ion-ion recombination is also considered within the model as a loss mechanism. The conductivity can also be modiﬁed by adjusting the mobility of the particles as well; this includes accounting for ion attachment to clouds and aerosols. To characterize small-scale (not resolvable within the climate model grid size) conductivity perturbations within the circuit, a ﬁnite element method (FEM) was used in Baumgaertner et al. [2014]. This allowed for a parameterization of small-scale cloud eﬀects on conductivity that are not resolvable on global climate model scales, to account for their inﬂuence on the downward return currents. This approach is implemented in the conductivity module of WACCM-GEC to account for the converging and diverging currents around small-scale clouds in the fair-weather return path of the GEC. As shown by Baumgaertner et al. [2014], neglect of such an eﬀect can overestimate global resistance by 20%. Incorporating these physical mechanisms to determine the conductivity in the domain allows one to calculate the full 3-D spatial and temporal distributions of conductivity utilizing the Community Earth System Model framework with the Whole Atmosphere Community Climate Model, CESM1(WACCM). Calculating conductivity in a physics-based framework allows for the coupling of many diﬀerent physical and chemical mechanisms and the investigation of new parameterizations and couplings within the same model. Thunderstorms and electriﬁed shower clouds are the sources of current to the GEC that maintain a potential diﬀerence between the ground and ionosphere [ Wilson , 1921]. Through various electriﬁcation processes such as precipitation-based charging, clouds can become electriﬁed. In particular, the noninductive charging mechanism that involves ice-ice collisions in the presence of supercooled liquid water is thought to contribute signiﬁcantly to cloud electriﬁcation [ Takahashi and Miyawaki , 2002; Saunders , 2008]. Storm kinematics as well as gravitational size sorting invoke charge separation that leads to the development of larger-scale charge regions inside these clouds. Herein it is assumed that this charge separation results in a current dipole. This dipole current source (that is described by a model parameter associated with cloud dynamics and microphysics) is what drives the current in the model domain. Kalb et al. [2014] derived storm currents of electriﬁed oceanic and continental storms identiﬁed by Liu et al. [2010a] based on Tropical Rainfall Mission Measurement (TRMM) satellite precipitation radar measurements and assigned respective mean currents from Mach et al. [2010, 2011] to these storms. This produced a global current map between 35 latitude (the observational domain of the TRMM satellite). They then compared this total current map with model-based cloud parameters and found good correlations between some model parameters and global conduction currents. Herein, we use the model parameterized convective mass ﬂux [ Zhang and McFarlane , 1995] to conduction current relationship. This relationship has shown good statistical LUCAS ET AL. CESM1(WACCM) GEC MODEL correlation at estimating the total current produced from storms and to represent the conduction current sources in WACCM-GEC. The following equation describes the relationship used in this study CMF (11) where is the source conduction current, is a constant relating the convective mass ﬂux to current contribution determined from regressions to the TRMM satellite, and aircraft data ( [A (kg/m /s) ), the summation is from the 500 mb pressure level to the top boundary, is an integrated height weighting factor, and CMF is the convective mass ﬂux (kg/m /s) at that pressure level. Starting the summation at the 500 mb pressure level excludes warm rain components in clouds that likely do not contribute to cloud electriﬁcation directly. The weighting factor is utilized to represent the depth of the storm and therefore its strength. Figure 1 shows the mean global current production output from the model utilizing the parameterization in equation (11). This illustrates that the source currents within the model are strongly produced over land masses while also accounting for the convection over oceans. The simulation was run during Southern Hemisphere summer months which accounts for the preferential current production in the south. Within climate models, there is a well-known tendency to produce convection too early in time of day [ Folkins et al. , 2014; Yuan et al. , 2013; Demott et al. , 2007]. This tendency results in the source currents in WACCM-GEC to occur at earlier times than observed. As this is a known artifact of the scheme, the microphysics parameterization and the resultant current production within the model occur earlier than observed. The convective mass ﬂux and subsequently derived currents are computed within the atmospheric component of CESM, which utilizes the Community Atmosphere Model (CAM5). A description of the model physics is given in Park et al. [2014]. The cumulus parameterization for updraft mass ﬂux used within CESM is the Zhang-McFarlane scheme [ Zhang and McFarlane , 1995]. In their paper they describe the generation of updrafts within a global climate modeling framework, which depends on the moisture and convective available potential energy within the model column. They also complete a sensitivity analysis of this new scheme to determine the improvement of the model-produced updrafts throughout the globe. The ability to use the GEC parameters as a means to evaluate atmospheric convective drivers is a by-product of this development. Consequently, this will allow new convection schemes to be evaluated based on the expected UT dependence of the GEC. Previously, we have described the equations underlying WACCM-GEC and discussed how the currents and electric ﬁelds within the model are calculated. Now we will demonstrate the capabilities of WACCM-GEC by allowing the model to run for 30 days, during which observational data in the Antarctic were collected. This run allows the conductivity and sources to be generated in a free-running simulation within a consistent model framework. The magnetospheric contribution seen at high latitudes will be analyzed in detail in section 4.1, followed by a comparison of WACCM-GEC electric ﬁelds to observational electric ﬁelds in Antarctica in section 4.2. This new model formulation opens up many opportunities to explore various inﬂuences on the GEC. As a demonstration, this section elucidates the connection between the GEC current system and external current systems ﬂowing in the ionosphere. The upper boundary conditions implemented within WACCM-GEC enable the combined inﬂuences of the GEC and magnetosphere currents on electric potential distributions to be investigated. The imposed potential due to solar wind-magnetosphere interactions is best described in Earth’s geomagnetic coordinates, while the GEC source contribution to the ionosphere potential is driven by solar heating and best described in Earth’s geographic coordinates. The geomagnetic coordinate system used in WACCM to describe the magnetospheric potential is the magnetic apex coordinates as described in Richmond [1995] and then converted to geographic coordinates. These two potential patterns are summed at each time step to produce the total potential pattern for the GEC. With these two potential patterns rotating diﬀerently within the Earth-ﬁxed frame, there are times and locations on the globe where these potentials are in-phase and out of phase with each other, which can lead to an interesting dynamic response in the polar regions. Both the magnetospheric perturbation and GEC sources have dominant 24 h modes. Because the net potential in the model is determined based on equation (9), these two contributions can be decomposed into an amplitude and phase to elucidate their relative contribution to the net potential. For illustration purposes, LUCAS ET AL. CESM1(WACCM) GEC MODEL a sinusoidal function with a 24 h period plus a constant oﬀset is ﬁt to the two potentials and summed, which is represented by the following formula. PD (12) and The variables represent the magnetospheric amplitude and phase, respectively, while and are the amplitude and phase contribution from the GEC, respectively, is the constant oﬀset for the column, and the 24 h angular frequency of interest. is stronger in the polar regions due to the magnetospheric current systems at high latitudes, whereas , without a column subscript, is the same globally and independent of location. For equatorial locations is negligible, and therefore, the leads to the variations detected at ground level, which allows for comparisons to the diurnal variation of the electric ﬁeld when viewed in UT. Consequently, the neutral wind dynamo in the ionosphere at middle and low latitudes has little inﬂuence on the local GEC potential. When conducting measurements at high latitudes, one must also take into account the perturbation due to the solar wind-magnetosphere dynamo [ Burns , 2005]. To illustrate the relative contribucomputed with the following equation. %Change (13) Calculating the amplitude and phase at every model point allows one to determine the relative inﬂuence of the magnetospheric potential globally. Figure 3 shows that there are regions where the amplitude of the magnetospheric perturbation is up to 50% that of the GEC and that there are regions where these amplitudes will constructively and destructively interfere. The red shading indicates constructive interference with the diurnal variation of the electric ﬁeld, while the blue shading indicates areas that destructively interfere. The 50% perturbation is during quiet geomagnetic activity. This eﬀect could be much larger and compete with the GEC variations for certain locations in more geomagnetically active situations. Section 4.1 provided an illustrative means to demonstrate the global inﬂuence of the magnetosphere current system on GEC properties. Of course, the model is able to provide a more quantitative assessment for any given location on the globe. To analyze the eﬀect of magnetospheric perturbations and compare with high-latitude observations, we utilized data from two Antarctic stations, Vostok (106.8 E, 78.5 S) (green dot) LUCAS ET AL. CESM1(WACCM) GEC MODEL and Concordia (123.3 E, 75.1 S) (blue dot). Vostok and Concordia, while not ideal locations for detecting large magnetospheric inﬂuences, are the only long-term data sets available in the polar regions. Observations of this kind in the polar regions are sparse and the data sets from these Antarctic sites have been investigated and published by G. B. Burns in several papers, e.g., Burns et al. [2012] and Burns [2005]. These stations are at similar latitudes but diﬀerent longitudes, which will generate diﬀerent phase relationships between the GEC and external ionospheric contributions to the potential, and consequently the vertical electric ﬁeld. This can be seen in Figure 4, which shows the relative electric ﬁeld variation from WACCM-GEC over Vostok and Concordia for 1 day. Analyzing the model output, one can tell that the potential pattern over Vostok (green curve) rises and falls sooner than the model output for Concordia (blue curve). Thus, Concordia measurements would more closely resemble the typical diurnal variation near equatorial sites as it experiences little inﬂuence from UT variations in the cross-cap potential because it is more in-phase with the GEC current sources. Utilizing WACCM-GEC to analyze these results, one can separate out the inﬂuences in the data from magnetospheric contributions and GEC current contributions. The black dashed line in Figure 4 shows the eﬀective GEC source contribution to the local measurements at Vostok, which we have calculated by removing the magnetospheric component. With this decoupling of the magnetospheric system and GEC system, the inﬂuence of the magnetosphere contribution tends to shift the phase of the diurnal variation of the electric ﬁeld to earlier times. Other high-latitude locations will experience diﬀerent inﬂuences depending on their location relative to the geomagnetic pole and the magnetospheric potential pattern, a fact recognized but not fully described in previous publications. Thus far, we have analyzed stations where data sets are also concurrently available. To determine the largest inﬂuence the magnetosphere can have during a solar quiet day, we analyzed Figure 3 to ﬁnd an area that is in-phase (197.5 E, 80.5 N) and also one that is out of phase (77.5 E, 80.5 S) with the GEC current sources. Figure 5 demonstrates the diﬀerent readings one could get at diﬀerent areas around the globe, simply based on measuring ground level electric ﬁelds. The baseline electric ﬁeld variation in Figure 5 is the daily mean diurnal variation determined from WACCM-GEC at a low-latitude location (0 E, 0 N). However, at the high-latitude locations, the electric ﬁeld perturbation with UT can be signiﬁcantly accentuated or suppressed due to the inﬂuence of the magnetospheric potential [ Burns , 2005; Reddell et al. , 2004; Corney et al. , 2003]. The mapping of this horizontal potential to the surface has been discussed by Park [1976] where it was demonstrated that horizontal potential structure greater than about 200 km will experience little attenuation in reaching the surface. LUCAS ET AL. CESM1(WACCM) GEC MODEL Thus, the magnetosphere potential serves as a source of variability in the surface electric ﬁelds independent of thunderstorm activity. To display the relative inﬂuence in more absolute terms, Figure 6 shows the separate upper boundary potential values due to the GEC and magnetospheric sources for the two regions identiﬁed in Figure 5. This ﬁgure demonstrates the phase relationship of the magnetosphere to the GEC for these speciﬁc locations. The red and blue curves constructively and destructively contribute to the GEC potential, respectively. The GEC potential varies throughout the 2 days due to day-to-day variability in the model’s convective activity. The magnetospheric potential is also varying over the 2 day period as it is a function of the geomagnetic indices throughout the 2 days. The geomagnetic activity conditions imposed in this simulation are considered to be quiet with a total horizontal cross-cap potential diﬀerence of about 60 kV. Under more active geomagnetic conditions, the cross-cap potential could exceed 200 kV and rival the GEC potential in certain locations at high latitudes. Combined with dynamic conductivity behavior in the polar regions, unique conditions could setup that result in very strong or very weak regional currents. To determine the consistency and accuracy of WACCM-GEC, observational electric ﬁeld data sets for Vostok and Concordia were obtained during common observing periods. WACCM-GEC was then run for this same observing period to evaluate the results under similar conditions. Within WACCM-GEC, the electric ﬁelds are represented by grid sizes that are much larger than the observations. Also, local disturbances that inﬂuence the electric ﬁeld measurements such as wind speed, clouds, temperature, and humidity are not able to be resolved in the model due to the large grid sizes. However, general trends and correlations can be investigated to evaluate the model. Data sets for each location were collected over the 3 month span of January–March for three overlapping years of 2009–2011 to obtain enough fair-weather days for analysis. In the data sets obtained from Vostok and Concordia, the electric ﬁeld was sampled at 10 s intervals. Occasionally, the data would have large ﬂuctuations due to local disturbances, and these ﬂuctuations were ﬁltered out to only leave fair-weather times for the analysis, as described in Burns [2005]. The data at each site were averaged over 30 min time intervals, and a 24 h mean was determined and centered on the time calculated. The value divided by the 24 h mean then gave the electric ﬁeld deviations for that period. WACCM-GEC was run for 30 days beginning 1 January 2010 to produce the output electric ﬁelds and currents which were then divided by the model daily mean to obtain LUCAS ET AL. CESM1(WACCM) GEC MODEL the deviations. The mean perturbation for each 30 min time interval was then determined and is presented in Figure 7. Comparing the diﬀerences between the model output and data in Figure 7, one can see that the phase relationship of Vostok to Concordia is similar between the model and the data. This indicates that the magnetospheric potential imposed within the model agrees well with the data at those locations. One noticeable diﬀerence between the model and the data is the relative amplitude of the peaks. The model predicts a maximum of about 10–13% while the data suggest that this value is closer to 20–23%. This deviation from the LUCAS ET AL. CESM1(WACCM) GEC MODEL data suggests that the source term within the model requires further reﬁnements, as that is the major diurnal driver for variation of the ground level electric ﬁelds. Developing a better model for source term strength from electriﬁed clouds that include a more detailed analysis of the ice and water pathways and other parameters within the clouds would improve the WACCM-GEC simulation and be of great value to the community. The lack of detailed meteorological and electrical measurements of clouds makes global source quantities diﬃcult to obtain. However, the results presented are very encouraging and the broad range of capability of WACCM-GEC opens a new way to study the GEC by allowing new atmospheric and electric parameterizations to be incorporated within the same consistent modeling framework. In this paper, we have developed a new physics-based model for the global electric circuit (WACCM-GEC) which is incorporated into the model framework of the CESM. This model computes the 3-D global distribution of electric ﬁelds and currents at each model time step of 30 min, at a grid resolution of 2.5 in longitude by 1.9 in latitude, with 70 vertical levels distributed in modiﬁed pressure coordinates. To do so, WACCM-GEC calculates the evolution of global conductivity at all grid points, including the inﬂuence of aerosols and clouds produced in the model. A dynamic global source current is determined in WACCM-GEC by relating convective mass ﬂux to current generation. To account for inﬂuences on the GEC potential by external current systems occurring in the magnetosphere, potential distributions due to the neutral wind dynamo and the solar wind-magnetosphere dynamo were included in WACCM-GEC as a time-varying and horizontally structured boundary condition of the top boundary potential. WACCM-GEC reproduced the expected behavior in potential and electric ﬁeld with UT, as described by the diurnal variation of electric ﬁeld around the globe. Some discrepancies exist between the relative amplitude of the model’s electric ﬁeld to observations, but this is expected to improve as the source current parameterization improves over time. At high latitudes, the inﬂuence of the external current systems was demonstrated and signiﬁcant regional perturbations can be introduced to the GEC potential distribution depending on the magnitude of the geomagnetic activity and the relative phase of the externally and internally generated potentials with UT. The high-latitude inﬂuence of magnetospheric potentials was evaluated against two separate Antarctic sites (Vostok and Concordia) where electric ﬁeld mills have been deployed and extensively utilized and scrutinized. WACCM-GEC was able to generate a diurnal curve of the relative electric ﬁeld variation at these locations that was in good qualitative agreement with the data. To determine the validity of the magnetospheric potential pattern, electric ﬁeld data from Vostok were shown to have a phase shift relative to Concordia, and the model was able to reproduce this phase shift. More data sets at high-latitude locations are needed to discern the inﬂuence of the magnetospheric potential on the GEC potential. Geomagnetic storms, conductivity variations due to clouds, aerosols, galactic cosmic rays, and source current changes with season and year will also introduce signiﬁcant variability to the GEC vertical electric ﬁelds and currents. This integrated model formulation allows such inﬂuences to be fully investigated. Another major utility of this work is the ability to evaluate the performance of new atmospheric physics schemes by contrasting the model outcomes of GEC properties with expected GEC behavior. This was elucidated when investigating the convective mass ﬂux parameterization for source currents and observing the diurnal variation in the GEC electric ﬁeld were peaking too early. This is attributed to a known limitation in many climate models where convection starts too early. To determine whether a new convection scheme is an improvement, one could compare the GEC electric ﬁeld UT response of the two diﬀerent schemes. There are presently no feedback mechanisms implemented in WACCM-GEC to determine how the GEC could impact climate variables. Many feedback mechanisms between the electrical properties of the atmosphere and cloud microphysics have been proposed, and this model could be used to investigate some of these relationships self consistently. 
test2_jgra.pickle ---------- ['The Instantaneous Retrieval of Precipitation Over Land by Temporal Variation at 19 GHz']
10.1029/2017JD027596 YOU ET AL. The primary signal used in all current passive microwave precipitation retrieval algorithms over land is the depression of the instantaneous brightness temperature (TB) caused by ice scattering. This study presents a new methodology to retrieve instantaneous precipitation rate over land by using TB temporal variation ( ) at 19 GHz, which primarily reﬂects the surface emissivity variation due to the precipitation impact. As a proof-of-concept, we exploit observations from ﬁve polar-orbiting satellites over the Southern Great Plains of the United States. Results show that at 19 GHz correlate well with the instantaneous precipitation rate. Further analysis shows that at 19 GHz is better correlated with the precipitation rate when multiple satellite observations are used due to the much shorter revisit time for a certain location. The retrieved instantaneous precipitation rate over Southern Great Plains from at 19 GHz reasonably agrees with the surface radar observations, with the correlation, the root-mean-square error and the bias being 0.49, 2.39 mm/hr, and 6.54%, respectively. Future work seeks to combine the ice scattering signal at high frequencies and this surface emissivity variation signal at low frequencies to achieve an optimal retrieval performance. Current precipitation estimation technique via satellite passive microwave observations links the hydrometers in the air to the surface precipitation intensity. That is, the cold brightness temperature (TB) at high-frequency channels (e.g., 85 GHz) indicates heavy precipitation. The TB observations from low-frequency channels such as 19 GHz are largely discounted. This study presents a new idea to link the surface condition variation to the precipitation intensity, by using TB temporal variation ( ) at 19 GHz from ﬁve polar-orbiting satellites. Results show that at 19 GHz correlate well with the precipitation rate. The estimated instantaneous precipitation rate over the Southern Great Plains of United States from at 19 GHz reasonably agrees with the ground radar observations, with Instantaneous precipitation rate retrieval by passive microwave radiometers over land is very challenging. Over the ocean where the microwave emissivity is low, the brightness temperature (TB) increase due to the radiometrically warm raindrops is apparent. However, the high surface emissivity over land largely masks the information from liquid water (e.g., Ferraro et al., 1994; Wang et al., 2009; Wilheit, 1986; You et al., 2014). In addition, the land surface emissivity is highly inhomogeneous, which makes it diﬃcult to physically model the land surface emissivity accurately on the global scale Tian et al. (2015). Despite these challenges, precipitation retrieval algorithms have been successfully developed and implemented for several decades over land. For example, some algorithms directly establish a relation between satellite observed TB at high-frequency channels (e.g., 85 GHz) and precipitation rate through various statistical techniques, including regression (Ferraro & Marks, 1995; Laviola & Levizzani, 2011; McCollum & Ferraro, 2003; Wang et al., 2009), neural networks (Islam et al., 2014; Staelin & Chen, 2000), and Bayes’ theorem (Petty & Li, 2013; You et al., 2015, 2016). The reference precipitation rates are usually from surface radar observations (Ferraro & Marks, 1995; You et al., 2015, 2016), ground gauge observations (Kongoli et al., 2015), or spaceborne precipitation radar observations (Islam et al., 2014; Petty & Li, 2013; Wang et al., 2009). Precipitation retrieval algorithms have also been developed by including the radiative transfer model (e.g., Aonashi et al., 2009; Kidd et al., 2016; Kummerow et al., 2015; G. Liu & Curry, 1992; Sano et al., 2013; Seo et al., 2016). Often, the radiative transfer model is employed to simulate the observed TBs. To do the simulation, the hydrometeor proﬁles are either derived from a cloud-resolving model (Kidd et al., 2016; Sano et al., 2013) or satellite-based precipitation radar observations (Kummerow et al., 2015). These precipitation retrieval algorithms diﬀer greatly in detail. However, they share one common feature: linking the scattering signal from the hydrometeors aloft to the precipitation at the surface (Petty, 1995; You et al., 2011; You, Wang, et al., 2017). This study demonstrates later that TB temporal variation ( ) at 19 GHz, primarily the surface emissivity variation signal, is well correlated with the precipitation rate. Therefore, it provides a new technique to retrieve precipitation rate over land from satellite microwave observations. Using observations from eight polar-orbiting satellites, You, Peters-Lidard, et al. (2017) recently showed that at high-frequency channels (e.g., 89 and 183 7 GHz) can signiﬁcantly improve the precipitation retrieval performance over snow-covered areas, by minimizing the surface emissivity variation inﬂuence. In contrast, this study utilizes the surface emissivity variation signal contained in the TB temporal variation at 19 GHz to retrieve precipitation rate. Previous works have used the surface emissivity and soil moisture to estimate the precipitation rate. For example, You et al. (2014) estimated the rainfall rate using the emissivity at 10 GHz in a case study over the Southern Great Plains (SGP) of the United States. Brocca et al. (2014) demonstrated that it is possible to estimate the surface rain rate from soil moisture variation. Koster et al. (2016) applied this method (converting soil moisture to rain rate) globally, using soil moisture products from the Soil Moisture Active Passive mission, the Soil Moisture and Ocean Salinity satellite mission, and the Advanced Scatterometer mission. They concluded that the estimated rain rates are, on average, highly correlated with the in situ gauge-observed rain rates with a square of the correlation coeﬃcient of 0.6, at the 100 km and 5-day resolution. Birman et al. (2015) showed that the daily rainfall estimation from surface emissivity at 89 GHz agrees reasonably well with surface gauge observations in France. Incorporating soil moisture information to correct the satellite rainfall accumulation estimates has been documented to reduce errors (Crow et al., 2009; Pellarin et al., 2013). Key diﬀerences between these works and the current study are the following: (1) Previous studies based on the emissivity and soil moisture are retrieving precipitation accumulation (e.g., daily). However, this study is attempting to retrieve the instantaneous precipitation, which is a much more challenging issue. (2) This study exploits TB temporal variation to retrieve the precipitation rate, which signiﬁcantly alleviates surface contamination (details in following sections). And (3) we use a satellite constellation (ﬁve satellites) in this study to obtain a reasonably high temporal resolution from microwave radiometer observations. It is known that low-frequency channels (e.g., 10, 19, and 37 GHz) have a poorer spatial resolution compared with the high-frequency channels (e.g., 89 GHz). Nevertheless, they are more sensitive to the surface emissivity channels can replace the high-frequency channels. Rather, we show that TB temporal variation at 19 GHz primarily reﬂects the surface emissivity variation due to the precipitation impacts, which may complement the ice scattering signals from high-frequency channels in future precipitation algorithm development. In addition, we choose 19 GHz because it is the lowest frequency commonly available from the ﬁve satellites used in the current study. Therefore, it is most sensitive to the surface characteristics, compared with other commonly available frequencies (e.g., 37 and 89 GHz). We would like to emphasize that this study does not directly use 19 GHz itself to retrieve the instantaneous rain rate. Instead, we use the temporal variation of 19 GHz from ﬁve satellites, which is well correlated with the instantaneous rain rate. Additionally, it is known that the 19-GHz channel does not necessarily perform better than the 89-GHz channel over land, and our later analysis shows this point. However, it does have its merits in providing additional information, for example, when the 89 GHz is not available (e.g., WindSat). The data used in this study are described in section 2. The methodology, including the deﬁnition of the TB temporal variation, is provided in section 3. Section 4 begins with a case study to show the response of TB temporal variation at 19 GHz to the instantaneous rainfall. Then, we present the correlation geospatial distribution between rain rate and TB at 19 and 89 GHz, and between rain rate and TB temporal variation at 19 and 89 GHz. We also discuss several factors that aﬀect the correlation between rain rate and TB temporal variation, YOU ET AL. including the temperature variation, the time diﬀerences between raining and nonraining observations, and the soil texture. Finally, the conclusions are summarized in section 5. The TB used in this study is from ﬁve instruments, including the Special Sensor Microwave Imager/Sounder (SSMIS) onboard the Defense Meteorological Satellite Program F16, F17, and F18 satellites; the Advanced Microwave Scanning Radiometer 2 (AMSR2) onboard the Global Change Observation Mission-Water satellite; and the Global Precipitation Measurement (GPM) Microwave Imager (GMI) onboard the GPM core satellite. As a proof-of-concept, we use three channels from each of these ﬁve sensors (Table 1). They are 19.4 (V/H) and 91.7 (V) from SSMIS, and 18.7 (V/H) and 89.0 (V) from AMSR2 and GMI. V and H represent the vertical and horizontal polarization, respectively. As shown in Table 1, all these channels have diﬀerent footprint resolutions (Draper et al., 2015). The slightly diﬀerent frequency between SSMIS and GMI (AMSR2) also results in diﬀerent TBs for the same surface background and hydrometeor proﬁle (Yang et al., 2014). Section 3 below demonstrates a method to bring all these frequencies to a similar resolution. We adjust the TBs at similar frequencies from SSMIS and AMSR2 to the GMI frequencies, by the simultaneous conical overpass (SCO) technique (Yang et al., 2011) and a linear regression method. Section 3 presents more details regarding this adjustment. For convenience, we do not distinguish the slight frequency diﬀerences among these ﬁve sensors from now on, and these channels are referred to as V19, H19, and V89. The objective of this study is to show that the temporal variation of H19 (primarily the surface emissivity variation signal) is well correlated with the instantaneous precipitation rate. Physically, TB at the horizontal polarization is more sensitive to the land surface characteristics than its counterpart at the vertical polarization, because the horizontal polarized channel is more aﬀected by the polarization of the water particles at/near the surface. Therefore, we choose to show the temporal variation of H19, instead of V19. As a comparison to the surface emissivity variation signal, the temporal variation of V89 (mostly the ice particle scattering signature) is also computed throughout this work. In addition, SSMIS, AMSR2, and GMI have 24, 14, and 13 and highest commonly available frequency from these ﬁve sensors. The precipitation rate data are from the Multi-Radar/Multi-Sensor System (MRMS), which is at 1-km and 2-min spatial and temporal resolution (Zhang et al., 2016). Collocation between the MRMS precipitation rate and TB is discussed in section 3. Data used in this study are all from March 2014 to December 2016 over SGP of the United States (95–105 W, 30–45 N). We choose this period of time since observations from all aforementioned ﬁve satellites are available. SGP is selected because of the large dynamic emissivity variation due to the precipitation eﬀect (Tian et al., 2015; Turk et al., 2016; You et al., 2014). The ancillary data used in this study includes Ku-band precipitation radar (KuPR, 13.6 GHz) onboard GPM core satellite (Seto et al., 2013). The precipitation proﬁle observed by KuPR is utilized in the radiative transfer model experiments to distinguish the surface emissivity eﬀect from the hydrometeor eﬀect. Speciﬁcally, we select all the KuPR rain rate proﬁles over the targeted region from March 2014 to December 2016. Then these proﬁles are averaged according to diﬀerent surface rain rates (e.g., 1 mm/hr; see Figure 9). In the radiative transfer model simulation, the surface temperature, temperature, and relative humidity proﬁles are from Modern-Era Retrospective Analysis for Research and Applications, version 2, which are all at 0.625 latitude-longitude spatial resolution. The temporal resolution for the surface temperature and proﬁles are 1 YOU ET AL. and 3 hr, respectively. We used the National Ice Center’s Interactive Multisensor Snow and Ice Mapping System daily snow cover map at 24 km to screen out the possible snow cover observations. In addition, we also use the gauge-corrected hourly MRMS data for the daily rainfall accumulation computation. TB temporal variation ( ) for any channel is deﬁned as (1) (2) is the current TB associated with precipitation and is the preceding TB at the same location where without precipitation. A grid box is judged as a precipitating grid box when the TB diﬀerence between V19 and V89 is greater than 8 K (Kummerow et al., 2001; Wang et al., 2009). Otherwise, the grid box is considered as a nonprecipitating grid box. By using the 8 K as the threshold value, the probability of detection is 69.24% with the false alarm rate at 6.92% in the targeted region, according to MRMS observations. is the time diﬀerence between these two observations. By using these ﬁve satellites, varies from several minutes to as long as 24 hr. We discuss later the varying ’s eﬀect on the correlation between and precipitation rate in section 4.4. This study computes the temporal variation of H19 (hereinafter referred to as ) and of V89 (hereinafter referred to as ). We demonstrate later in the section 4.5 from radiative transfer model simulation experiments that the is largely the surface emissivity variation signal due to the precipitation impact, while is primarily the ice scattering signal. Table 1 shows the mean footprint resolution of SSMIS, AMSR2, and GMI at 19 and 89 GHz (Draper et al., 2015). The 19 GHz of SSMIS has the largest footprint size at 59 km. This study aggregates the ﬁner footprint resolution by simply averaging to roughly match this resolution. Speciﬁcally, we average 7 (59 59/22/22 7) pixels of 19 GHz from AMSR2, 16 pixels of 19 GHz from GMI, 18 pixels of 91.7 GHz from SSMIS, 140 pixels of 89 GHz from AMSR2, and 71 pixels of 89 GHz of GMI to approximately match the resolution of 19 GHz of SSMIS (59 km). For the precipitation rate, we simply average the closest 3,481 ( ) 1-km MRMS precipitation rate pixels for each TB observation at the closest time. After the footprint sizes of these ﬁve sensors being brought to a similar resolution, the TBs from SSMIS and AMSR2 for each channel are adjusted to the GMI channels. The GMI channels are taken as the reference channel because AMSR2 and SSMIS are calibrated against GMI (Berg et al., 2016). The linear relationship between the GMI TB at each channel and the TB from AMSR2 or SSMIS at the similar frequency is assumed, and it takes the following form: (3) where is from 1 to 4, which stands for sensors of SSMIS onboard F16, F17, and F18, and AMSR2. And is from 1 to 3, which represents channels of H19, V19, and V89 GHz. and The SCO technique by Yang et al. (2011) is used to obtain the coeﬃcients . The idea of SCO technique is that simultaneous measurements at a certain location from two diﬀerent sensors at similar frequencies should be highly correlated. This study takes the GMI observations as the reference. Two measurements, one from GMI and the other one from any of other four sensors, are called a SCO pair, if the ﬁeld-of-view location is less than 1 km and the ﬁeld-of-view time is less than 2 min. These threshold values are chosen by considering the trade-oﬀ between the sample size and the SCO pair accuracy. To obtain enough SCO pairs, we choose the land portion of the region from 70–130 W, 30–50 N. The scatter plots between these SCO pairs for each channel are shown in Figure 1. It is evident that the majority of the SCO pairs are close to the 1-1 line. The coeﬃcients trained by these SCO pairs are listed in Table 2. Most adjusted TBs ( 97.0%) deviate less than 2 K from the original TBs. YOU ET AL. The purpose of this study is to show that is well correlated with the precipitation rate. Therefore, for a certain location, the number of observations should be high enough to obtain a meaningful temporal variation. To this end, the data are gridded into 0.5 latitude-longitude box. Any pixel in the same grid box is taken as the observation for the same location. We choose the 0.5 resolution because the mean footprint size (59 km) is close to the 0.5 resolution. Approaches used in this study are very similar to You, Peters-Lidard, et al. (2017). A major diﬀerence between this study and You, Peters-Lidard, et al. (2017) is whether to consider the environmental variation from modify deﬁnition in section 4 to consider the environmental variation (e.g., temperature) from to , since we are able to more accurately compute the land surface emissivity at low-frequency channels under the nonprecipitating scenarios, compared to at high-frequency channels. In addition, this study grids satellite observations into a 0.5 latitude-longitude box due to the larger footprint size at 19 GHz, compared to the 0.25 latitude-longitude box in You, Peters-Lidard, et al. (2017). YOU ET AL. Figure 2 shows the time series of H19 (Figure 2a) and V89 (Figure 2b), and the corresponding precipitation rate (Figure 2e) over the 0.5 grid box of (100.5–101 W, 41.5–42 N). There are 5,483 observations at this location tions identiﬁed by greater than 8 K. The red circles in Figure 2a (observations with precipitation) do not separate themselves from the blue curve. It basically means that the precipitation signal from H19 itself is very weak. In contrast, the TB depression at V89 (Figure 2b) is evident. That is, the observations with red circles correspond well with the precipitation occurrence (the blue bar in the Figure 2e). The poor correlation between H19 and precipitation rate is immediately evident in the scatter plot (Figure 3a), where the correlation coeﬃcient is only 0.12. The poor correlation ( 0.12) is the reason why previous work primarily used the scattering signal at high-frequency channels (e.g., 89 GHz) for the precipitation retrieval over land. In contrast, V89 correlates strongly with precipitation rate with a correlation coeﬃcient of 0.66 (Figure 3c). Figures 2c and 2d show the time series of and (deﬁned in equation (1). The and are set as 0 for the observations judged as nonprecipitating observations ( 8 K). It is very clear that both (Figure 2c) and (Figure 2d) correspond very well with the precipitation occurrence (Figure 2e). There are 180 precipitation observations out of 5,483 total observations from March 2014 to December 2015 over this grid box. The vast majority of the associated with precipitation (159 out of 180 records) are less than 0, and the TB depression at can be as large as 40 K. There indeed exists a small portion of the observations (21 out of 180 records) with greater than 0. For the , all values are negative. We YOU ET AL. explain the positive and negative TB values of and by a radiative transfer model simulation in section 4.5. The much better correlation between and precipitation rate ( 0.69), compared with that between H19 itself and precipitation rate ( 0.12), is obvious in Figure 3 (cf. Figures 3b and 3a). It is worth noting that the correlation between and precipitation rate ( 0.69; Figure 3b) is slightly worse than that between and precipitation rate ( 0.76; Figure 3d). In the following sections, we show that the highly variable time difference ( ) is largely responsible for the worse performance of . Another possible reason is that the signal magnitude of is weaker than that of . The correlation between and precipitation rate ( 0.76) is also better than that between V89 and precipitation rate ( 0.66; Figure 3c) due to the mitigation of cold surface contamination. We use the daily Ice Mapping System snow cover map to ﬁlter out possible snow-covered observations. However, there may still exist some observations associated with snow cover on the ground due to the mismatch between the daily snow cover map and the instantaneous satellite observations. Speciﬁcally, the red circles associated with cold V89 at 240 K in Figure 3c represent the falsely identiﬁed precipitating observations. The inﬂuence of the falsely identiﬁed precipitation observations due to the cold surface is largely reduced when using , because the of these falsely identiﬁed observations are close to 0 (Figure 3d). More discussions regarding the mitigation of the surface contamination at 89 GHz are contained in You, Peters-Lidard, et al. (2017). In summary, it is demonstrated that is well correlated with the precipitation rate, while H19 itself has very weak correlation with the precipitation rate. The correlation between and precipitation rate (Figure 4a), between H19 and precipitation rate (Figure 4b), between and precipitation rate (Figure 4d), and between V89 and precipitation rate (Figure 4e), are computed over SGP. The precipitation occurrence number, judged by the scattering index method ( ), varies from 40 to 404 in diﬀerent grid boxes. As discussed above, it is clear that is much better correlated with the precipitation rate than H19 itself (cf. Figures 4a and 4b). The majority of the correlation coeﬃcients (64.8%) between and precipitation YOU ET AL. rate are negative (less than 0.4). As shown in the case study, most decreases due to the impact of precipitation. Mathematically, this explains why and precipitation rate is negatively correlated. Physically, precipitation usually increases the soil moisture and therefore leads to a depression in emissivity which results in a TB depression. On the other hand, out of the 600 correlation coeﬃcients, there are 14 positive ones. These positive correlation coeﬃcients caused by (1) the combined eﬀect of surface emissivity variation and hydrometeors emission/scatter in the air, which we explain in detail in section 4.5; and (2) cold surfaces misidentiﬁed as precipitation. The false positive correlation between H19 itself and precipitation rate is especially obvious in the top left corner of Figure 4b. These false positive correlations are generally caused by cold Over SGP, the vast majority of the correlation coeﬃcients between and precipitation rate (Figure 4d) are less than 0.7. Obviously, the scattering signature is better correlated with the precipitation than the surface emissivity variation signal. In the following sections, we demonstrate that the correlation between and precipitation rate is highly dependent on the variation, while the correlation between and precipitation rate is relatively independent from the variation. Even though ﬁve satellite observations are exploited in this study, the is still highly variable, which can change from several minutes to more than 12 hr. The highly variable has a larger negative impact on the correlation between and precipitation rate than that between and precipitation rate, because is more sensitive to the surface characteristics than . Another interesting phenomenon is that is better correlated with the precipitation rate than V89 itself, which is particularly evident over west of 103 W. As mentioned previously, in these regions, the can more eﬀectively mitigate the surface contamination, especially under the light precipitation scenario (You, Peters-Lidard, et al., 2017). In section 3, we deﬁne the as . In this deﬁnition, we do not consider the temperature (surface temperature and temperature proﬁle) variation from to . In other words, it explicitly assumes that the YOU ET AL. temperature information at time is the same as that at time . This assumption may lead to an error in the estimate when the temperature varies from to , especially when is large (e.g., 12 hr) between these two observations. To consider the temperature variation, may be calculated in the following way: (4) is still the observed TB under the precipitating conditions. is the simulated TB at by using where the emissivity calculated at (under the nonprecipitating condition). Speciﬁcally, the emissivity at 19 and 89 GHz is calculated at under the nonprecipitating condition by using the temperature information at . Then the emissivity values at 19 and 89 GHz are used to calculate by using the temperature information at . By doing so, the surface temperature variation from to is taken into consideration. From now on, computed in equation (4) for H19 and V89 is referred as to and , respectively. A radiative transfer model (G. Liu, 1998) computes the emissivity under the nonprecipitating conditions. This model calculates the TBs at diﬀerent microwave frequencies through the discrete ordinate method at varying stream numbers. In the current simulation, the stream number is set as 4. The water vapor absorptions from both line and continuum contributions are considered in this model. The temperature information used in the radiative transfer model calculation is from Modern-Era Retrospective Analysis for Research and Applications, version 2. By considering the temperature variation eﬀect, it is noted that the correlation between and precipitation rate is improved (cf. Figures 4a and 4c). For example, the overall mean correlation coeﬃcient in the targeted region from is 0.40, while it increases to 0.47 using . Improvement has also been made for the V89 channel, but to a lesser degree (cf. Figures 4d and 4f ). The objective of this study is to show the temporal variation of TB at 19 GHz ( ) is well correlated with the precipitation rate. Ideally, observations from a satellite constellation with the same conﬁguration or a geostationary microwave radiometer would be most suitable. However, such observations currently are not available or even planned. Therefore, we exploit observations from ﬁve low Earth orbit satellites in the GPM constellation. By doing this, the deﬁned in equation (2) is highly variable. This section demonstrates the eﬀect of variable on the correlation between and precipitation rate, and between and precipitation rate. Figure 5 shows the histogram of the time diﬀerences (i.e., ). By using ﬁve satellite observations, about 99.3% of the s are less than 12 hr. In contrast, about 78.8% of the s are greater than 12 hr when only GMI observations are used. To show the variable eﬀect, we calculate the correlation between and precipitation rate, and between and precipitation rate, corresponding to diﬀerent s (Figure 6). The correlation coefﬁcients between and precipitation rate decrease quickly from 0.5 with at 2 hr to 0.21 with at 24 hr. This result implies that with increasing time diﬀerences between and , it is more likely that the surface conditions (e.g., soil moisture variation and precipitation in between these two observations) have changed. Therefore, more likely contains other information besides the current precipitation eﬀect. YOU ET AL. In contrast, the correlation between and precipitation rate remains at about 0.7 (blue curve in Figure 6), regardless of the variation. The relative independence of indicates that V89 is less aﬀected by the surface characteristics variation in this region, compared with H19. Therefore, using single satellite observations to compute may be suﬃcient in this region. Figure 6 shows that correlations between and the precipitation rates decrease as increases. To further understand this phenomenon, we compute the number of precipitation events (Figure 7a), and the percentage of the current precipitation being the only precipitation (Figure 7b), corresponding to diﬀerent intervals, from 0–1, 1–2, , 11–12 hr. As expected, Figure 7a shows that there are more precipitation events with a larger . For example, on average, there are only 1.01 precipitation events when is 1 hr. In contrast, there are 2.78 precipitation events when is 12 hr. When the precipitation-free scene at t is less than 1 hr apart from the current precipitating scene at t , 99.12% of the time the current precipitation is the only precipitation event in the time period of (Figure 7b). When increases to 12 hr, the percentage decreases to 43.75%, meaning that 56.25% of the time there are other precipitation events in the time period of 12 hr. When there are other precipitation events occurring in the time period of , not only reﬂects impact of the current precipitation event, it may also include the impact from other precipitating events in between . Therefore, the correlation between and the current precipitation rate becomes weaker as increases. Since may reﬂect the precipitation accumulation in the time period of , it is possible to estimate the precipitation accumulation from . In fact, previous studies estimated the precipitation accumulation (e.g., daily accumulation) from emissivity at low frequencies channels (You et al., 2014) or from soil moisture (Brocca et al., 2014). However, further analysis shows that the correlation between and the precipitation accumulation in the time period of is not necessarily stronger than that between and the instantaneous precipitation, because the correlation between and the precipitation accumulation is dependent on the time interval in which the precipitation accumulation is computed. More research is necessary to pinpoint the optimal precipitation accumulation time interval. Under precipitating conditions, it is impossible to know the exact value of the emissivity because TB reﬂects the combined eﬀect from both the surface background emission and scattering/emission from the hydrometeors aloft. To show the possible emissivity variability over the targeted region, we adopt the method in channels, corresponding to diﬀerent previous 1-day precipitation accumulation amounts. We can reasonably assume that the emissivity variation under the precipitating conditions resembles the emissivity variation under the precipitation-free scenes, but with diﬀerent 1-day precipitation accumulation amounts. YOU ET AL. Figure 8a shows that the emissivity for H19 can drop as much as 0.05 from 0.95 to 0.90, or even 0.1 in some areas, corresponding to 10-mm 1-day accumulation precipitation (cf. Figures 8a and 8d). Correspondingly, H19 TB can drop as much as 20 K (cf. Figures 8e and 8h). In contrast, the emissivity at V89 and V89 itself have a much smaller variation magnitude, corresponding to the same amount previous 1-day precipitation accumulation (cf. Figures 8i and 8l, and Figures 8m and 8p). This study shows the concept of using surface emissivity temporal variation signal at the 19 GHz due to the precipitation impact. As mentioned previously, it is very diﬃcult to separate the surface emissivity contribution from the hydrometeor contribution to the satellite-observed TB, under the precipitating conditions. To disentangle the surface emissivity from hydrometeor eﬀects and better understand the eﬀect from each of them, we conduct following radiative transfer simulation experiments: (1) Simulate TB at H19 and V89 with the surface precipitation rate increasing from 0 to 20 mm/hr, corresponding to the surface emissivity at 0.8, 0.9, 0.95, and 1.0. By doing this, we can determine the hydrometeor eﬀect. (2) Simulate TB at H19 and V89 with the surface emissivity decreasing from 1.0 to 0.8, corresponding to 0, 0.5, and 5 mm/hr precipitation rate. By doing this, we can determine the surface emissivity eﬀect. The radiative transfer model, developed by G. Liu (1998), is used for the YOU ET AL. aforementioned experiments. Additionally, for simplicity the particles above (below) the freezing level height are considered as ice (liquid) particles, and no mixed phase particles are considered in the simulation. It is found that H19 decreases about 25 K from 292 to 267 K (Figure 9a, magenta curve), and about 12 K from 278 to 266 K (Figure 9a, blue curve), with the precipitation rate increasing from 0 to 20 mm/hr, corresponding to the emissivity at 1.0 and 0.95, respectively. On the contrary, H19 increases from 237 to 266 K (Figure 9a, red curve) when the precipitation rate increases from 0 to 20 mm/hr, with emissivity at 0.8. This partially explains why is positively correlated with the precipitation rate. The green curve in Figure 9a shows that H19 increases slightly when the precipitation rate increases from 0 to 8 mm/hr, then decreases slightly when the precipitation rate increases from 8 to 20 mm/hr. It is clear that TB at H19 can either increase or decrease due depression at H19 caused by hydrometeors is probably less than 12 K, since the mean emissivity at H19 under dry condition is less than 0.95 in the targeted region (Figure 8a). Figure 9b demonstrates that H19 can decrease as much as 55 K from about 292 K to about 237 K under the nonprecipitating condition (Figure 9b, red curve) when emissivity decreases from 1.0 to 0.8. Similar magnitudes of the TB depression are observed under the light precipitation scenario (Figure 9b, green curve). Under heavier precipitation (Figure 9b, blue curve), H19 can decrease about 20 K. Compared with the mixed hydrometeor eﬀect on H19, the surface emissivity depression caused by precipitation can only lead to a TB depression at H19, and the magnitude of the depression can be as large as 55 K. Our results show that the vast majority of s are negative, and its magnitude can be as large as 40 K. From the radiative transfer model simulation experiments, we conclude that the surface emissivity depression plays a larger role in the vast majority of negative s. That is, the signal from is largely from the surface emissivity depression, and the hydrometeor scattering/emission signal contributes less to . Compared with the surface emissivity variation signal, it is very clear that the hydrometeor scattering signal is responsible for the TB variation at V89. Figure 9c shows that TB at V89 does not vary when the precipitation rate is larger than 2 mm/hr, regardless of the surface emissivity values. Similar results can be found in Figure 9d. YOU ET AL. For example, V89 only decreases about 10 K when emissivity decreases from 1.0 to 0.8, with the precipitation rate at 0.5 mm/hr. To summarize, the radiative transfer model simulation shows that the largely reﬂects the surface emissivity variation. In contrast, the hydrometeor scattering signal is responsible for the TB depression of . This channel is surface blind with the precipitation rates greater than 2 mm/hr. The previous section shows that the signal from is essentially the surface emissivity variation due to the precipitation impacts. A key factor aﬀecting the surface emissivity variation is the soil texture (e.g., content and structure) . Therefore, this section explores the possible inﬂuence of the soil texture on the correlation between and precipitation rate. As a comparison, the soil texture inﬂuence on the correlation between and precipitation rate is also investigated. Of the 16 soil texture types present in the hybrid State Soil Geographic/Food and Agriculture Organization soil texture data set provided by the National Center for Atmospheric Research for the Noah land surface model (Miller & White, 1998; Reynolds et al., 2000), 10 types are represented in the targeted region. They are sand (63), loamy sand (5), sandy loam (103), silt loam (142), loam (129), silty clay loam (48), clay loam (58), silty clay (8), clay (41), and other (3). The number in the parenthesis following the soil texture types is the 0.5 grid box number for each class. For example, the soil type is sand in 63 grid boxes, out of 600 grid boxes in the whole targeted region. The following calculation omits the classes of loamy sand, silty clay and other, due to the limited sample size. The correlation between and precipitation rate (Figure 4c) is averaged for each soil texture type. Similar computation is performed for the correlation between and precipitation rate (Figure 4f ). Results are listed in Table 3. The correlations between and precipitation rate have a general decreasing trend from the sand soil to the clay soil. We hypothesize that the better correlation from the sand soil is due to the quicker response of the sand to the instantaneous precipitation impact, compared with the clay soil. Another possible reason is that precipitation events in-between (other than the current precipitation event) may have a smaller impact on the sandy soils, because water drains away faster through the sandy soils, compared with clay soils. As shown in Figure 7a, when the is larger than 1 hr, precipitation events other than the current precipitation event likely occur. More work is necessary to fully understand the underlying physical reason for this behavior. In contrast, the soil texture type has almost no inﬂuence on the correlation between and precipitation rate, as indicated by the almost constant correlation coeﬃcients ( ) between them. It is worth mentioning that using the correlation coeﬃcients between and precipitation rate (Figure 4a), and between and precipitation rate (Figure 4d) generates very similar results (see last two columns of Table 3). The ability of to retrieve precipitation is investigated by using the independent data in 2016. As a proof-of-concept, a simple linear regression line is ﬁtted between the and precipitation rate using the training data set from 2014 to 2015 in each 0.5 grid box. As comparisons, similar procedures are applied to YOU ET AL. H19, V89 and to retrieve the precipitation rate. Then the ﬁtted regression line in each grid box is used to retrieve the precipitation rate in 2016, where the MRMS precipitation rate is taken as the reference. Figure 10 shows the overall retrieval results over SGP. The retrieved precipitation rate from has a correlation of 0.49 with MRMS. Root-mean-square error is about 2.39 mm/hr, and the bias is 6.54% (Figure 10b). The retrieval result from H19 itself (Figure 10a) performs noticeably worse, as indicated by a much smaller correlation of 0.28. It is noted that the bias from H19 ( %) is smaller than that from (6.54%), because the the precipitation rate are canceled out each other in the retrieval result of (Figure 10a). The retrieval results from (Figure 10c) and (Figure 10d) are obviously better, compared with . The highly variable likely aﬀects the ’s performance, because is much more sensitive to the surface characteristics variation than . Previous analysis shows that the magnitude of the correlation between and precipitation rate decreases quickly along with the increase. This again suggests that a denser low earth orbit microwave constellation or a geostationary microwave radiometer could help to improve the performance of for the precipitation retrieval. In addition, we show that the correlation between and precipitation rate is dependent on the soil texture type, which has little inﬂuence on the correlation between and precipitation rate. This study extends our previous work (You, Peters-Lidard, et al., 2017) on temporal changes in high-frequency TBs to demonstrate the potential value of low-frequency channels to improve precipitation rate retrievals over land. For this study, we use 3-year (2014–2016) observations over SGP from surface radar measured precipitation rate and ﬁve satellites observed TBs, including SSMIS onboard F16, F17, and F18; AMSR2; and GMI. YOU ET AL. Over the whole study region, and precipitation rate is well correlated with the majority of the correlation coeﬃcients less than 0.4. The correlation can be further improved by considering the temperature temporal variation through the radiative transfer model simulation. It is also noted that the correlation from V89 or is stronger than that from . The relatively worse performance of the is due to this signal being more sensitive to the surface characteristics than . Even with observations from ﬁve sensors, varies from several minutes to more than 12 hr. It is shown that the correlation between and precipitation rate substantially weakens as increases. We suggest that the observations from a denser low Earth orbit microwave constellation or a hypothetical geostationary microwave radiometer can improve the correlation between and precipitation rate due to its high temporal resolution. We further analyze the signal source of the . Results show that the surface emissivity depression caused by the precipitation is largely responsible for the variation, while the hydrometeor scattering/emission eﬀect contributes much less to the behavior. In contrast, the TB at 89 GHz is surface blind under the moderate and heavy precipitation scenarios (e.g., 2 mm/hr in Figure 9c), and it is the hydrometeor scattering eﬀect that results in the TB depression at 89 GHz, which is well documented in the literature (Ferraro & Marks, 1995; McCollum & Ferraro, 2003; Wang et al., 2009; You et al., 2015, 2016). Further analysis shows that the correlation between and precipitation rate varies over diﬀerent soil texture types, with the largest correlation for the sand soil type. In contrast, soil texture has almost no inﬂuence on the correlation between and precipitation rate. As a proof-of-concept, a linear regression precipitation retrieval is performed over SGP by using the independent data in 2016. On average, the retrieved precipitation rate from has a correlation of 0.49, a root-mean-square error of 2.39 mm/hr and a bias of 6.54% , compared with the surface radar observations. These statistics are much better than those from H19 itself. However, it is noted that performance from is better than that from , partially due to the larger negative inﬂuence to from the highly variable time diﬀerence ( ) between two observations. As a proof-of-concept, this study only uses ﬁve satellites to derive the TB temporal variation. In fact, several other currently operational radiometers carry the low-frequency channels at 19 GHz, including Advanced Microwave Sounding Unit-A, Advanced Technology Microwave Sounder, WindSat, and FengYun-3 Microwave Radiometer Imager. By using all observations from these radiometers (10+), it could signiﬁcantly increase the temporal resolution, and therefore, the performance of is expected to improve greatly. By doing so, the previous overpasses of all used sensors (ﬁve in the current study) need to be processed and stored, which can take longer time compared with the retrieval algorithm for a single sensor. Finally, it is not our purpose to claim that the surface emissivity signal from is stronger than the scattering signal from either or V89 itself. In fact, results in Figure 10 show that the scattering signal over the targeted region is stronger than the surface emissivity variation signal from . The primary objective of this study is to show that largely reﬂects the surface emissivity variation due to the precipitation impact. Therefore, it provides an independent signal source for precipitation retrieval, which may complement the scattering signal from high-frequency channels under certain situations. For example, in the warm rain systems there are few or no ice particles. Therefore, the scattering signal at high-frequency channels is rather weak, which leads to a poor precipitation retrieval result for algorithms solely dependent on the ice scattering signature (C. Liu & Zipser, 2009; Sohn et al., 2013; You & Liu, 2012). In addition, Hamada et al. (2015) showed that a large scattering signal does not necessarily indicate heavy precipitation. Our study shows that it is possible to use the signal from the surface emissivity variation, as reﬂected in TB temporal variation derived from low-frequency channels, to measure the instantaneous precipitation rate, which currently is not considered in the instantaneous precipitation retrieval. Future work seeks to combine these two signal sources (scattering from the hydrometeors aloft and surface emission variation due to the precipitation) to achieve an optimal precipitation retrieval performance. 
test2_jgra.pickle ---------- ['Effects of desert dust and ozone on the ultraviolet irradiance at the Mediterranean island of Lampedusa during PAUR II']
JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 107, NO. D18, 8135, doi:10.1029/2000JD000139, 2002 [ ] The progressive decrease of the total atmospheric ozone amount observed at mid and high latitudes during the last few decades is expected to produce an enhancement of the ultraviolet irradiance at the surface [e.g., Madronich , 1992]. The ﬁrst analyses of the long-term behavior of the UV-B irradiance, based on the measurements of the United States network of Robertson-Berger UV-B radiometers over the period 1974 –1985, showed an unexpected decrease of the erythemal dose [ Scotto et al. , 1988]. These results pointed out the need to maintain well calibrated instruments and with continuous oversight [e.g., Kennedy and Sharp , 1992; Weatherhead et al. , 1997], and have led scientists to speculate causes due to other atmo1 2 spheric parameters, such as clouds [e.g., Frederick and Weatherhead , 1992], tropospheric ozone [ Grant , 1988; Bru¨hl and Crutzen , 1989], and aerosols [e.g., Grant , 1988; Liu et al. , 1991; Justus and Murphey , 1994], that may inﬂuence the UV-B irradiance. There is, however, now enough evidence that an increase of the UV irradiance occurs corresponding to periods characterized by low total ozone amounts [see, e.g., Seckmeyer et al. , 1994; Mims et al. , 1995; Zerefos et al. , 1995]. The evidence is particularly clear at high latitudes, mainly in the southern hemisphere [ Frederick and Alberts , 1991; Lubin et al. , 1992; Stamnes et al. , 1992; Frederick et al. , 1993; Bojkov et al. , 1995; Bais et al. , 1997; Frederick et al. , 1998; Gurney , 1998]. [ ] One of the main results of these investigations is the characterization of the dependence of the UV irradiance on the total ozone behavior. This dependence is generally expressed as a radiation ampliﬁcation factor (RAF) that gives the change (increase) of the UV irradiance (at a speciﬁc wavelength or integrated over a spectral range, weighted by a speciﬁc action spectrum) for a 1% variation (decrease) of total ozone. The value of the RAF strongly depends on wavelength, and is about 4 – 6 at 300 nm, and about 1 at 310 nm, for solar zenith angles, , around 45 [ Bais et al. , 1993; Bodhaine et al. , 1996; Fioletov et al. , 1997]. The RAF for the irradiance weighted for the erythema action spectrum is somewhat larger than 1 for near 45 [ McKenzie et al. , 1991; Kerr and McElroy , 1993; Basher et al. , 1994; Krzys´cin , 1996; Bodhaine et al. , 1996; Minschwaner , 1999; Dubrovsky´ , 2000.]. [ ] Several recent studies provide indications of a longterm increase of the UV-B radiation, related to the total ozone decrease [ Blumthaler and Ambach , 1990; Correll et al. , 1992; Kerr ans McElroy , 1993; Basher et al. , 1994; Herman et al. , 1996; McKenzie et al. , 1999; Borkowski , 2000]. [ ] However, Liu et al. [1991] show, with radiative transfer calculations, that the increase of tropospheric aerosols occurring over continental areas of the northern hemisphere as a consequence of SO emission may produce a signiﬁcant decrease of the UV-B radiation at the surface. They point out that the aerosol increase may partly offset the UV-B increase due to the ozone decline. Several experimental studies show that atmospheric aerosols may affect the ultraviolet irradiance. These investigations have been carried out in different conditions. Studies have been conducted at continental sites in Europe [ Krzys´cin and Puchalski , 1998; Can ˜ ada et al. , 2000], and in North America [ DeLuisi , 1997; Kerr , 1997; Wenny et al. , 1998]. coastal [ Kylling et al. , 1998; Can ˜ ada et al. , 2000], rural [ Meleti and Cappellani , 2000], and urban sites [ Lorente et al. , 1994; Repapis et al. , 1998]. Attenuating effects on UV by a large smoke aerosol load, as a consequence of biomass burning in Brazil, have been also reported [ Mims , 1996]. [ ] However, little is known concerning the effects of mineral aerosols on the UV irradiance. Mineral aerosol are expected to increase in the atmosphere, as a consequence of human activity: it has been estimated that a fraction ranging between 30 and 50% of the total mineral aerosols are produced in soils that have been disturbed by the human activity [ Tegen and Fung , 1995; Sokolik and Toon , 1996]. Mineral aerosol mobilization and transport is affected by large-scale phenomena, like the North Atlantic oscillation [ Moulin et al. , 1997], and El Nin˜o [ Prospero and Nees , 1986]. The dust transport is moreover characterized by intense events, with a duration generally of a few days. Thus these particles may affect the UV-B behavior on different timescales. [ ] The Photochemical Activity and Ultraviolet Radiation modulating factors II (PAUR II) campaign took place in the Mediterranean [ Zerefos et al ., 2002] during May and June 1999. An aim of the campaign was to study the combined effects of ozone and aerosol in a region characterized by large aerosol variability that is mostly due to the strong inﬂuence of dust transport events originating from the Sahara. [ ] As described by Zerefos et al. [2002], the campaign was based at the islands of Crete, Greece, and Lampedusa, Italy. In this paper, ultraviolet irradiance, ozone, and aerosol measurements collected at Lampedusa during the campaign are used to identify the interactions among these quantities. Lampedusa is a small island, 10 km long, approximately 2 km wide, in the southern Mediterranean (35.5 N, 12.6 E). During the campaign the instrumentation was based at the Station for Climate Observations of the Ente per le Nuove Tecnologie, l’Energia e l’Ambiente (ENEA) of Italy. A brief description of the site, the deployed instruments, and the results of aerosol proﬁle measurements by lidar is given by di Sarra et al. [2001a, 2001b]. [ ] An array of instruments dedicated to atmospheric observations was installed at Lampedusa during PAUR II [ di Sarra et al. , 2001b]. In this paper, data obtained from the UV spectrophotometer, the Sun photometer, and the aerosol lidar, are used. [ ] The operational UV spectrometer at Lampedusa is Brewer MK III 123. The Brewer spectrophotometer has been designed for total ozone measurements [ Brewer , 1973]. A description of the instrument and of its routine mode of operation is given by Kerr et al. [1985]. The Brewer MK III is a double monochromator spectrometer: a substantial improvement in the quality of UV measurements below 305 nm with respect to the single-monochromator measurements, due to the better stray light suppression, has been achieved with this spectrometer [ Bais et al. , 1996]. The instrument measures hemispheric UV irradiances betwen 286 and 363 nm through the teﬂon diffuser collector; spectral resolution is around 0.55 nm, and measurements are recorded at every 0.5 nm interval. During the PAUR II campaign, frequent measurements of the UV spectrum were performed (at least twice per hour) throughout the day. Up to 20 measurements of total ozone per day for 60 were also performed by the Brewer. July 1998, through a comparison with the traveling Brewer 17. A calibration of the ultraviolet irradiance scale was performed 10 days before the campaign, by means of the National Oceanic and Atmospheric Administration (NOAA) ﬁeld calibrator [ Early et al. , 1998], that uses a US National Institute of Standards and Technology (NIST) traceable 1000 W FEL lamp. The stability of the spectrometer during the campaign was monitored by using 50 W external lamps, as recommended in the Brewer operation manual. [ ] For the purpose of this analysis, the UV spectra measured by the Brewer have been interpolated at ﬁxed solar zenith angles, and corrected for changes of the Sun-Earth distance. The interpolation is performed by taking the three spectra closest-in-time to the time t corresponding to the selected value of ; a second-degree polynomial is ﬁt to the three irradiance measurements at each wavelength , and the irradiance at t is calculated. As explained below, only spectra measured in cloud-free conditions are used for the interpola3 tion. Thus we obtain simultaneous spectra for a cloud-free sky at 20, 30, 40, 50, 60, and 70 , at the mean Sun-Earth distance. The variation of and of the Sun-Earth distance has been calculated according to Spencer [1971]. The uncertainty on the observed irradiance is estimated to be around 4 –5%. The erythemally weighted irradiance at 20, 30, 40, 50, 60, and 70 at the mean Sun-Earth distance, E , is calculated by the convolution of the UV spectra interpolated at times t with the erythema action spectrum [ McKinlay and Diffey , 1987]. [ ] The values of the total ozone at times t were derived by linear interpolation between the closest measurements. The uncertainty on , for cloud-free conditions, is around 1%. [ ] A multiﬁlter rotating shadow-band radiometer (MFRSR) was operated at Lampedusa during the campaign. The MFRSR is a seven-band Sun photometer that collects sky radiation through a horizontal diffuser, and uses a rotating shadow band to separately measure the global and diffuse components of the radiative ﬁeld; the direct component is derived as the difference between the two measurements [ Harrison et al. , 1994]. The instrument installed at Lampedusa, model MFR-7, has a channel for the total shortwave radiation, and six channels centered respectively at 415, 500, 615, 671, 868, and 937 nm. The bandwidth of the last six channels is around 10 nm. The calibration of the MFRSR is obtained with the Langley plot method, after correcting the signals for changes of the Sun-Earth distance. The Langley plot has been applied to the channels centered at 415 and 868 nm, in 5 cloud-free mornings characterized by relatively low aerosol content and variability; these mornings were identiﬁed also on the results of the lidar observations. The standard deviation of the extraterrestrial constants is 2% for the 868 nm channel, and 5% for the 415 nm channel. The atmospheric optical depth is calculated by applying the Beer-Lambert law, S S e , (1) where S is the extraterrestrial constant, determined by the Langley method calibration. S is the MFRSR output signal corrected for changes of the Sun-Earth distance, is the sum of the molecular and aerosol optical depths at the selected wavelength, and m is 1/ cos . It must be mentioned that this equation is valid for a plane-parallel atmosphere, and a more complex expression for m is needed for 60 , and for Kasten and Young , 1989]. The aerosol optical depth is derived by subtracting the molecular optical depth [ Bucholtz , 1995] from . The obtained values are then averaged over 18 min intervals, and linear interpolation is used to derive the estimates of at the times t . Values of the diffuse-to-direct ratio for the observed radiation are also derived. [ ] A recent study has shown that, as a result of an intercomparison among four Sun photometers, aerosol optical depths from a well calibrated MFRSR can be retrieved with an absolute accuracy of 0.026 [ Schmid et al. , 1999]. The absolute error on , , includes the contributions of the uncertainties in the estimate of the molecular optical depth, in the signal S (the difference between the total and diffuse radiation for the MFRSR), in the air mass m , and in the extraterrestrial constant S . To emphasize the importance of the determination of the extraterrestrial constant on the obtained results, we assume that the ﬁrst three uncertainties contribute negligibly; in this case, if we deﬁne the uncertainty on S , S , (2) 1 m that is, for a ﬁxed the absolute error on is proportional to the relative uncertainty of S . Thus, for a 2% error on S , we have an uncertainty on due to S of approximately 0.02 (at small solar zenith angles). The error due to the calibration does not depend on the value of , and becomes smaller as the solar zenith angle increases. Thus the relative error on due to the calibration uncertainty may become large for small values of the optical depth, and for small solar zenith angles. In general, the various uncertainties that contribute to the error on are not negligible. In particular, for large values of solar zenith angle, the error on S may become relevant due to the reduction of the measured irradiances. Owing to the limited number of days when the Langley plot calibration was performed at Lampedusa, a relatively large systematic error could affect in low turbidity cases. This error may be as large as 30% at 868 nm (the channel with the best results of the Langley plot calibration), for 45 , and 0.05 (the smallest value of the measured optical depth throughout the campaign). For 0.2, the error becomes 7% in similar conditions. [ ] The aerosol lidar is able to measure the atmospheric backscattering proﬁles at 532 nm in the height region between 0.4 and 10 km in daylight conditions. A description of the instrumental setup and of the data retrieval procedure is given by di Sarra et al. [2001a]. In this paper the integrated backscattering IB , i.e., the integral of the backscattering coefﬁcient over height, is used as an indicator of the aerosol content of the atmosphere. [ ] During the campaign, cloudiness conditions were regularly noted. The cloudless periods identiﬁed on the basis of visual observations were later checked against the pyranometer signal: clouds are generally well identiﬁable in the pyranometer record, since the continuous signal shows a large shortterm variability. Aerosol layers vary at a slower rate, and have a smaller impact than clouds on the visible irradiance. After the comparison of the visual observation notes and of the pyranometer signals, only periods classiﬁed as cloud-free (i.e., with cloud-cover lower than 2/8, and no clouds close to the ing the lidar proﬁles. The lidar can detect optically thin clouds by generally showing a backscatter ratio larger than aerosol particles. All periods were discarded when signatures from clouds were present in the lidar proﬁles (also identiﬁed on the basis of the temporal variability and of depolarization ratio). In other words, only data collected in cloud-free intervals were retained and used in the following analyses. [ ] Figure 1 shows the time series of total ozone, aerosol integrated backscattering, aerosol optical depth at 415 and 868 nm, aerosol A˚ ngstro¨m exponent, and erythemal irradiance measured in cloud-free conditions at solar zenith angles of 20 and 40 . The total ozone daily averages are obtained from the Brewer observations; the daily total ozone measurement from the Total Ozone Mapping Spectrometer aboard the Earth Probe satellite, interpolated at 35.5 N, 12.5 E, is also shown for comparison. The average difference between the two total ozone measurements is smaller than 3 DU (about 1%). The integrated backscattering is obtained from the 30-min average 4 Evolution of (a) daily average total ozone from the Brewer spectrometer (open diamonds), daily total ozone from TOMS (pluses), and aerosol integrated backscattering (IB), calculated over the height region above 1 km (solid circles); (b) aerosol optical depth at 415 nm (open circles) and at 868 nm (solid circles), and aerosol A˚ ngstro¨m exponent (pluses); and (c) erythemally weighted irradiance at solar zenith angles of 20 (solid squares) and 40 (open squares). The data are relative to the period 6 May to 18 June 1999. Data for cloudy periods have been removed. lidar signals, and is calculated for the height region above 1 km; the contribution of clouds has been removed as described by di Sarra et al. [2001a]. The optical depths and the A ˚ ngstro¨m exponent are derived from the MFRSR observations and are the result of 18-minute averages. The erythemal irradiance is calculated from the Brewer spectra as previously described. [ ] Total ozone varies by about 40 DU around a mean value of approximately 330 DU, and the interval of variability is around 12%. IB varies between 0.0013 and 0.018 sr, at 415 nm between 0.14 and 0.97, and at 868 nm is between 0.05 and 0.86. The interval of variability is 90%, indicating that extremely different atmospheric aerosol conditions may occur. This extreme variability can be expected to produce signiﬁcant effects on the measured UV irradiances. [ ] Relatively large values of the A˚ ngstro¨m exponent, between 1 and 2, are derived for the low values of the aerosol optical depth; when large aerosol loads are detected, the A˚ ngstro¨m exponent is close to 0.5, as expected for relatively large 5 Range of Variability of the Ozone Optical Depth at Different Wavelengths particles. It is interesting to note the relationship between the IB and series. [ ] The behavior of the erythemal irradiance is mostly determined by the inﬂuence of total ozone. Large values of E generally occur at low total ozone amounts. However, signiﬁcant anomalies are present: the largest E is observed on 12–13 May, when the total ozone is around 315 DU. Lower values of the erythemal irradiance are found for 315 DU on 14 and 31 May, 1–3 June, and 6 –14 June. These anomalies are most likely due to changes of the aerosol content that contribute to the modulation of the erythemal irradiance. [ ] By using the values of the ozone absorption cross section measured by Molina and Molina [1986] and by Cacciani et al. [1989], the ozone optical depth may be estimated. The calculated values for the minimum and maximum total ozone ( , respectively) throughout the campaign are reported in Table 1. The aerosol optical depth at 415 and nm (sufﬁciently close to the ultraviolet spectral interval) is frequently larger than 0.3, i.e., aerosols are expected to play a role on the radiative transfer comparable or larger than that played by ozone for 320 nm. [ ] Figure 2 shows, for a selection of wavelengths, the behavior of the measured UV irradiance E versus total ozone for different values of . The irradiance progressively increases with wavelength, and decreases with . As expected, the effect of the ozone absorption appears at the short wavelengths. Linear ﬁts to the data have also been drawn, to illustrate the dependence of the irradiance on ozone. From these linear ﬁts, the RAF, deﬁned as RAF E E , (3) where E is the change of E , and is the total ozone change, has been calculated at 5 nm intervals. Madronich [1993] has proposed the use of a power law relationship for the deﬁnition of the RAF. By using the power law relationship very similar results are obtained from these data, as will be shown below, and we assume that the linear expression provides a satisfactory representation. [ ] In Figure 3 the behavior of RAF for different wavelengths and values of is shown. Surprisingly, a change of the sign of RAF appears at 315 nm, i.e., an increase of E Behavior of the UV irradiance at selected wavelengths and at different values of the solar zenith angle for cloud-free conditions versus total ozone. The solid and dashed curves are linear ﬁts to the data. Note the change of the vertical scale in the different graphs. 6 [ ] Where the ozone absorption is small, the RAF is expected to be close to or equal to zero. Thus it appears that the effect of the ozone, which is dominant for 315 nm, is overcome by the inﬂuence of other atmospheric parameters at longer wavelengths. This inﬂuence is also evident in the graphs of Figure 2. [ ] The data of Figure 1 show that large values of the optical depth and of the integrated backscattering occur when low total ozone is measured, and small values of and IB are recorded at high total ozone amounts. It has been shown by di Sarra et al. [2001a] that the aerosol transport from Africa to Lampedusa during PAUR II was dominated by the presence of a high-pressure system close to the island and generally centered over northern Libya. Obviously, large aerosol loads are measured in this case, due to the presence of large amounts of desert dust transported from the Sahara. The dust layer often reaches an altitude of 8 km. When the high pressure is located over western Algeria, the air reaching Lampedusa originates from the North Atlantic and Europe, and a much smaller aerosol load is observed. In these cases, aerosol is not detected at altitudes above 3 km. [ ] It is well known that a relationship between total ozone and weather exists: early ozone measurements showed that maximum ozone daily deviations occur over surface lowpressure systems, while maximum negative deviations are associated with surface high-pressure areas [ Dobson et al. , 1946]. Reed [1950] showed that this relationship is due to the effects of horizontal advection and to large-scale vertical motions. In particular, southward/northward transport of stratospheric air, from the polar ozone-rich region or the subtropical ozone-poor region, plays an important role. [ ] In this perspective, the variations of the total ozone over Lampedusa may be explained in terms of the wandering of the anticyclone over north Africa, that is associated with changes of the vertical structure of the stratosphere and transport of airmasses of different origin and ozone content. As previously explained, tropospheric aerosol transport also depends on surface pressure, and total ozone and tropospheric aerosol amounts are negatively correlated. The correlated behavior is evident in Figure 1, where large values of and IB occur only when is low, i.e., in mid May and during most of June. Around 10 May, and in the period 20 –29 May, large values of and small values of and IB are measured. [ ] Thus, tropospheric aerosols are very likely to affect the pendence of E on . In Figure 4 the observed values of E are plotted versus the aerosol optical depth at 415 nm, for various solar zenith angles. The lines in Figure 4 represent linear ﬁts to the data. Owing to the covariance of and , and to the dominating effect of the ozone at short wavelengths, an increase of E with appears for 315 nm. At 315 nm and at longer wavelengths the expected dependence of E on emerges. Since the inﬂuence of ozone decreases toward longer wavelengths, the spread of the data points with respect to the linear curves reduces for 310 nm. A similar picture is obtained when E is related to the aerosol optical depth at 868 nm. The slope at 315 nm is similar to that found by Wenny et al. [1998]. Their analysis indicated strong absorption by aerosols in central North Carolina. [ ] A simple analysis has been implemented to separate the effects of aerosols and ozone on E . A more general expression describing the dependence of the UV irradiance variability on both ozone and aerosol variability has been adopted: Behavior of the radiation ampliﬁcation factor (a) versus wavelength at different values of the solar zenith angle and (b) versus solar zenith angle, for 300, 305, and 310 nm. In Figure 3b the radiation ampliﬁcation factor has been calculated for a linear (solid lines) and a power law relationship (dashed lines). occurs for an increase of . At longer wavelengths a value of RAF smaller than 1 is derived for 60 . The values of RAF are moreover consistently lower than expected: Bais et al. [1993] obtained a linear radiation ampliﬁcation factor at difference of 40 DU. Bodhaine et al. [1996], using a power law relationship, calculated a RAF of about 4 at 300 nm, and somewhat larger than 1 at 310 nm. Fioletov et al. [1997] derived estimates of the irradiance increase associated with a 1% ozone increase from Brewer observations at seven stations for the period 1989 –1995; the increase at 300 nm is around 4% for 47.5 and 4.5% for 57.5 ; at 310 nm, the increase is 1% for 47.5 and 1.3% for 57.5 . Values of RAF , the radiation ampliﬁcation factor for the power law relationship between E and [ Madronich , 1993], have been calculated at 300, 305, and 310 nm. The obtained values are shown in Figure 3b, together with the linear RAF, as a function of . RAF is larger than RAF for all values of at 300 and 305 nm. However, signiﬁcant differences, up to 10%, are derived only for very large values of the radiation ampliﬁcation factor. RAF is generally increasing with , except at 300 nm; the behavior at this wavelength for large solar zenith angles is due to the Umkehr effect. 7 Behavior of the UV irradiance at selected wavelengths and at different values of the solar zenith angle, for cloud-free conditions, versus aerosol optical depth at 415 nm. The solid and dashed curves are linear ﬁts to the data. Note the change of the vertical scale in the different graphs. E E RAF S , (4) where S is deﬁned as the sensitivity of the irradiance on the aerosol optical depth, is the aerosol optical depth change, and RAF is the radiation ampliﬁcation factor for ozone taking into account the aerosol effects. Expression (4) is valid if ozone and aerosol act on the UV irradiance independently, and if linear relationships are assumed between E and and E [ ] In reality, the enhancement of the scattering of UV radiation due to the presence of aerosols, by increasing the length of the photon paths through the atmosphere, is expected to produce additional absorption by ozone. This effect is believed to be small, because of the relatively low concentration of tropospheric ozone; it might become signiﬁcant for large solar zenith angles when a large fraction of the measured irradiance is due to diffuse radiation, and the photon path lengths become larger. [ ] As previously discussed, similar values of the radiation ampliﬁcation factor are obtained by using a linear and a power relationship, and we assume that the linear dependence provides a satisfactory description. At wavelengths where the 0, the ﬁrst term ozone absorption is negligibly small RAF on the right side of the equation may be neglected. The variations of E may be consequently explained in terms of changes of only. As it appears in Figure 4, a linear relationship seems to describe dependence of E on reasonably well at these wavelengths ( 320 nm). The linear correlation coefﬁcients r between E and are reported in Table 2 for a selection of wavelengths, together with the number of data points for each solar zenith angle. At these wavelengths the values of r are always much larger than the squared linear correlation coefﬁcients achievable with a level of conﬁdence of 0.001 from a noncorrelated dataset. Thus we assume that the linear relationship provides a sufﬁciently good description of the dependence of E on , even though the interval of variability of is expressing the relative changes of E and in terms of a linear sensitivity, as in expression (4). [ ] Where RAF 0, S has been derived from expression (4). The values of are calculated with respect to the average optical depth calculated for the set of values observed at each solar zenith angle. We have calculated S at 5 nm steps, for 340 nm; at 340 nm the estimated optical depth of ozone is around 0.015, and the effect of its variations on the UV irradiance is considered negligible with respect to the aerosol (see Table 1). At longer wavelengths the ozone optical depth is progressively smaller, and its effect may also be neglected. In Figure 5 the average S , obtained by averaging the results at each , is depicted as a function of . The standard deviation of the average is also shown. The average S progressively increases with from 20 to 60 , and decreases from 60 to 70 ; its value is 0.1, i.e. much smaller than the estimates of RAF for 310 nm. By calculating the S from the linear ﬁts 8 Correlation Coefﬁcients r Between the Irradiance and the Optical Depth at 415 nm for the Indicated Values of the Wavelength and of the Solar Zenith Angle between E and the aerosol optical depth at 868 nm, smaller values than those derived for at 415 nm are obtained. These values are also shown in Figure 5. [ ] From the values of S it is possible to estimate the percent reduction of irradiance per unit aerosol optical depth at 415 nm. In Table 3 the average percent reduction for the wavelength interval 340 –360 nm, and the standard deviation of the average, is reported for different solar zenith angles. The reduction increases with , reaching values larger than 50% at 70 . For 20 , the reduction is about 30%. Since the linear relationship gives a good description of the dependence of the UV irradiance on , the percent reduction may be scaled to different values of the optical depth. [ ] In the previous analyses we have not attempted to identify different aerosol types, and all the cloud-free data have been considered. A main distinction between the two aerosol types is proposed: during the desert dust events, Saharan aerosol is largely dominant over the different particle types. In other periods a mixture of marine and continental aerosols is normally expected over Lampedusa. The continental aerosol particles mainly originate from Europe, and their properties are modiﬁed while traveling over the sea. [ ] With the aim of characterizing the effects of the Saharan dust aerosols, a reduced set of cases has been selected. The selection has been based on the isentropic backward trajectories, as outlined in di Sarra et al. [2001a]. The trajectories ending at Lampedusa on the days of the campaign are grouped in four separate classes, depending on the path followed by the air parcels. [ ] We have included in class a all the trajectories that do not pass over Africa; in these cases, the air masses generally originate in the North Atlantic, and travel over western Europe. Class b contains the trajectories that marginally overpass Africa. The trajectories that spend the last few days over northwestern Africa, over the Atlas Mountains and Morocco, Algeria, Tunisia, are included in class c. The trajectories that originate in central Sahara, and have spent a consistent fraction of the last 10 days over the desert are classiﬁed as class d. For the following analyses, only the days when the trajectories ending at Lampedusa between 3 and 4 km belonging to classes c and Average S , the sensitivity of the irradiance on the aerosol optical depth (see text), versus solar zenith angle. The standard deviation of the average is also indicated. S has been estimated from all the cloud-free measurements, and from the aerosol optical depth at 868 nm (solid circles), and at 415 nm (open squares), and from the desert dust cases only, for aerosol optical depth at 868 (solid triangles) and at 415 nm (open triangles). 9 Percent Reduction R (Average Over the 340-360 nm Spectral Interval) of the Ultraviolet Irradiance per Unit Increment of the Aerosol Optical Depth at 415 nm d, have been selected. In these cases the desert dust is the dominant component of the atmospheric aerosols. The lidar observations have shown that the aerosol distribution strongly depends on the origin of the airmasses: the aerosol is generally conﬁned below an altitude of 3 km for the class a proﬁles, while it reaches 7– 8 km for the conditions of classes b, c, and d. The different aerosol proﬁles are shown by di Sarra et al. [2001a]. [ ] The values of S have been also calculated for the Saharan dust subset, for the optical depth at 415 and 868 nm. The averages of S for the desert aerosol subset are also reported in Figure 5. The values of S for the reduced data set are signiﬁcantly larger, by 0.05– 0.1, than those previously obtained. The desert dust subset comprises only large values of the optical depth. As will be discussed below, the differences between the values of S for the two classes of particles may be partly due to the non homogeneity of the optical depth values in the different datasets, as well as to differences in the microphysical properties, composition, and vertical distribution of the aerosols. [ ] The average value of S (calculated over the entire data set), not dependent on wavelength, has been used to derive an estimate of RAF , by ﬁtting equation (4) to the data shown in Figures 2 and 4. The use of a S that does not depend on wavelength introduces a systematic error in the calculations. However, the wavelength dependence of is not large compared to the dependence of ozone absorption; as shown in Figure 1, the A˚ ngstro¨m exponent is smaller than 1 for most of the observations, and is smaller than 0.5 for the large values of that correspond to desert dust events. Consequently, we assume that the wavelength variability of S may be neglected [ ] In Figure 6 the obtained values of RAF are plotted vs. wavelength and solar zenith angle. The values of RAF are substantially larger than RAF, the radiation ampliﬁcation factor for ozone estimated without aerosol correction (see by comparison Figure 3). The differences between RAF and RAF are smallest, around 0.5, for low values of ; differences up to 1 are found at large solar zenith angles. The peak of the radiation ampliﬁcation factor at 300 nm is now found at 60 , instead of 50 . Values of RAF are in good agreement with the radiation ampliﬁcation factors reported in the literature [ Bais et al. , 1993; Bodhaine et al. , 1996; Fioletov et al. , 1997]. It is interesting to note that RAF is close to zero for 330 nm, as expected, for all solar zenith angles. The bias on RAF due to the assumption of a S which is not dependent on appears negligible for 330 nm and could produce an underestimate of the real radiation ampliﬁcation factor at short wavelengths. [ ] To highlight the role of the different aerosol types, the behavior of the UV irradiance at 360 nm, for different values of , versus the aerosol optical depth at 415 nm for the desert dust cases, is shown in Figure 7. These cases correspond to large values of , generally 0.2. As in Figure 4, linear curves have been ﬁtted to the data. The solid lines represent linear ﬁts for the dataset that includes only the desert dust cases; the dashed lines are the linear ﬁts derived for the whole data set, and previously shown in Figure 4. A change of the slope appears for the desert dust case, mostly for solar zenith angles between 30 and 50 . The general case groups together continental/marine aerosols and desert dust. These two aerosol classes are characterized by signiﬁcant differences in the aerosol properties: the optical depth is generally smaller for the continental/marine aerosols than for the desert dust, the particle dimensions are different, as shown by the changes of the A˚ ngstro¨m exponent (see Figure 1), and their compositions (and refractive indices) are expected to differ. It appears from Figure 7 that, for low values of the optical depth, continental/ marine aerosols produce a larger attenuation on the global irradiance than desert dust. [ ] This effect may be due to differences in the wavelength dependence of . For a given value of at 415 nm the optical depth at 360 nm is 1.24 times larger for aerosols characterized by an A˚ ngstro¨m exponent of 2, than for aerosols whose A˚ ngstro¨m exponent is 0.5. As results from Figure 1, low values of are generally associated with high values of the A˚ ngstro¨m exponent, and the enhancement of from 415 to 360 nm is comparatively larger. [ ] The behavior of the A˚ ngstro¨m exponent however does not explain the dependence on the solar zenith angle. This dependence may be attributed to the role of direct and diffuse irradiance and to the scattering geometry, under the assumption that the different slopes of the ﬁtting lines are due to differences in the single scattering albedo, and/or in the scattering phase function between the two classes of particles. At low solar zenith angles the irradiance is mostly dominated by the direct component, and the attenuation of the irradiance depends mainly on the value of the vertically integrated : in this case, a small change of the slope of the linear ﬁt is expected, as it appears in Figure 7. At high the diffuse radiation is dominant and the solar radiation is essentially scattered downward by an atmospheric layer that is above the aerosol cloud. Consequently, the measured irradiance becomes less sensitive to changes in the aerosol distribution and properties, and depends mainly on . Conversely, in the 30 –50 range of sol vertical distribution and properties, producing a different behavior for different classes of particles. [ ] To investigate the inﬂuence of aerosols on the erythemally weighted irradiance E , the following analysis has been carried out. By using the estimates of E derived from the Brewer observations and the measurements of , the erythemal radiation ampliﬁcation factor, RAF , has been derived without considering the effect of the aerosols. Then, a radiation ampliﬁcation factor for the case in which the aerosol effect has been taken into account by means of expression (4), RAF , has been calculated. The same values of S used previously have been assumed. In Figure 8 the behavior of the RAF (dashed curve) and of different estimates of RAF (solid curves) are shown. The solid circles identify the estimate of RAF obtained by using the aerosol optical depth at 868 nm, and the whole data set (all aerosol types). The squares are derived by using at 415 nm, and the the whole data set. The solid triangles and the open triangles are relative to the re10 Behavior of RAF , the ozone radiation ampliﬁcation factor, corrected for the inﬂuence of the aerosols, (a) versus wavelength at different values of the solar zenith angle and (b) versus solar zenith angle. duced dataset (desert dust cases), for at 868 and 415 nm, respectively. The values of S shown in Figure 5 for the different cases have been accordingly used in expression (4). It must be mentioned that the estimates of RAF for the desert dust cases are obtained from a dataset that is comprised of limited ozone variability, 20 –30 DU; as it appears in Figure 1, is generally about 300 DU during the dust events. As expected, the aerosol produces a considerable effect on the estimates of the erythemal radiation ampliﬁcation factor. RAF is larger than RAF by 0.4 –1, the difference increasing with . The obtained values of RAF are consistent with the erythemal radiation ampliﬁcation factors reported in the literature: DeLuisi and Harris [1983] derived values in the range 1.24 –1.26 from observations at 60 ; McKenzie et al. [1991] found a linear radiation ampliﬁcation factor around 1.25; Kerr and McElroy [1993] derived values between 1.1 and 1.3, depending on the season; Bodhaine et al. [1996], by using the power law relationship, obtained radiation ampliﬁcation factors between 1.25 and 1.44 at 45 . Somewhat smaller values, between 0.7 and 1.2 depending on , have been derived by Dubrovsky´ [2000]. Radiation ampliﬁcation factor for erythema derived by means of radiative transfer modeling are in the same range of values [e.g., Madronich and Flocke , 1997]. [ ] The erythemal radiation ampliﬁcation factor has been also derived from radiative transfer model [ Mayer et al. , 1997] estimates of the surface spectral irradiance at 30 and 60 solar zenith angle, by varying the total ozone between 300 and 380 DU. The aerosol optical depth and the atmospheric pressure have been kept constant. An aerosol layer of marine aerosols below 2 km, with a visibility of 23 km, has been assumed. The values of the erythemal radiation ampliﬁcation factor estimated from the model by means of a linear relationship and of a power law agree within less than 0.01. [ ] The erythemal RAF calculated from the model is 11 Behavior of the irradiance at 360 nm for different values of the solar zenith angle, against the aerosol optical depth at 415 nm. Only the data points which correspond to cases dominated by the desert dust are plotted. The solid curves are linear ﬁts to the data. The dashed curves are the linear ﬁts obtained by including all the data set. slightly larger than the RAFs derived by means of expression (4). This effect may be attributed to a wavelength dependence of the aerosol sensitivity, that has been neglected in the previous analyses, and to a interdependence between ozone and aerosol, possibly through increased ozone absorption following enhanced scattering by aerosols. However, the erythemal RAF depends also on the ozone vertical proﬁle (tropospheric and stratospheric ozone affect the UV irradiance differently, due to different scattering regimes and to the temperature dependence of the ozone absorption cross section). In the analysis leading to the determination of the radiation ampliﬁcation factor we have grouped together measurements carried out in very different atmospheric conditions (aerosol, total ozone, ozone vertical distribution). Consequently, we cannot expect a close correspondence between the values derived from the observations and those calculated by the model. In the followErythemal radiation ampliﬁcation factor for ozone changes, not corrected (dashed line) and corrected (solid lines) for the inﬂuence of the aerosols, versus solar zenith angle. The line identiﬁed with the solid circles is derived from all the measurements, and the aerosol correction is made with respect to the optical depth at 868 nm. The curve with the open squares is corrected for the optical depth at 415 nm, and all the measurements are included. The other two solid curves are obtained considering only the cases dominated by the desert dust, with corrections for the optical depth at 868 (solid triangles) and 415 nm (open triangles). The stars indicate the radiation ampliﬁcation factors calculated by means of a radiative transfer model. 12 Behavior of the erythemal irradiance, corrected for total ozone changes (see text), at 30 and 60 solar zenith angle, against the aerosol optical depth at 415 nm. The solid curves are linear ﬁts to the data. ing analysis aimed at estimating the role played by aerosols on the attenuation of the erythemal irradiance, we assume that the ozone effect on the erythemal UV is well represented by the results of the model. By using the model-derived erythemal RAF we have corrected the measured values of E for the ozone changes only by estimating the erythemal irradiance at 340 DU, E . In this way we have removed the ozone dependence of E , and may attribute its residual variability to the aerosols. In Figure 9, E is plotted against the aerosol optical depth at 415 nm, for solar zenith angles of 30 and 60 . A linear curve has been ﬁt to the data. As expected, aerosols signiﬁcantly affect the erythemal irradiance: the reduction of erythemal irradiance per unit optical depth at 415 nm is about 50% at 30 , and about 55% at 60 solar zenith angle. [ ] To investigate the role played by the aerosol vertical distribution on the surface UV irradiance, we have studied the dependence of E at 330 nm on the lidar-derived backscattering, integrated over different vertical intervals, and on the average altitude of the aerosol cloud, weighted by the backscattering coefﬁcient, z . The value of z provides an indication di Sarra et al. [2001a], z is always above 2.5 km during the desert dust transport events. [ ] In Table 4 the correlation coefﬁcients r of the linear regression between these quantities are reported. Largest values of r are obtained for IB integrated over the whole aerosol cloud (above 1 km) and, surprisingly, for the integrated backscattering over the altitude interval between 5 and 6 km. A weak correlation is found with IB over the 1–2 km region, and with z . The weak dependence on z seems to suggest that changes of the vertical distribution of the aerosol cloud produce a relatively small impact on the surface irradiance. However, z does not depend on the value of the aerosol optical depth, which is the dominant parameter, and the effect of the altitude distribution of the aerosol may be difﬁcult to extract in the presence of the large variability of . E appears to be mostly controlled by the total aerosol load over the column, as suggested by the good correlation with IB integrated over the column. It may be speculated that a good correlation is found with IB over the region between 5 and 6 km because this quantity is a good indicator of the presence of desert dust. A more detailed investigation is however needed to accurately address this topic. [ ] Minima of the correlation coefﬁcient are found for 20 , while maxima occur for 60 . A smoothing of the slant path of the direct radiation at large solar zenith angles, may partly explain the observed dependence of the correlation on . The presence of a diurnal evolution of the aerosol properties may also contribute to this. Correlation Coefﬁcients r Between the Irradiance at 330 nm and the Indicated Parameters for the Indicated Values of the Solar Zenith angle 13 [ ] Simultaneous measurements of aerosol properties, total ozone, and spectral ultraviolet irradiance were performed during the PAUR II campaign at Lampedusa, in the Mediterranean. Aerosol optical depth and total ozone were negatively correlated. This effect is due to the inﬂuence of tropospheric pressure systems on the transport patterns that regulate the propagation of desert dust to the southern Mediterranean, and to the relationship linking total ozone to surface pressure caused by tropopause vertical motions and stratospheric advection of ozone-poor and ozone-rich air. [ ] A marked dependence of the UV irradiance on the aerosol optical depth appears; this effect competes with the ozone absorption, due to the anti correlated behavior of the two quantities, and is larger than ozone absorption at wavelengths longer than 315 nm. The presence of tropospheric aerosols, and mainly of desert particles from Sahara strongly affects the UV irradiance-ozone dependence. A signiﬁcant reduction of the radiation ampliﬁcation factor with respect to expected values occurs. This reduction, due to the aerosol inﬂuence, is as large as 1, and is observed also for the radiation ampliﬁcation factor for the erythemally weighted irradiance. [ ] The attenuation of the UV irradiance near 350 nm per unit aerosol optical depth at 415 nm, has been estimated; the reduction is between 30 and 54%, depending on the solar zenith angle. For the same optical depth a reduction of the erythemal irradiance by 50 and 55% is estimated at 30 and 60 solar zenith angles, respectively, by assuming the dependence of the UV irradiance on total ozone calculated by means of a radiative transfer model. [ ] A simple method to correct for the aerosol inﬂuence has been developed, and applied to the observations. The radiation ampliﬁcation factors that were estimated after correction are in agreement with those reported in the literature. [ ] These results indicate that tropospheric aerosols, and desert dust in particular, may signiﬁcantly affect the propagation of the UV radiation through the atmosphere. In speciﬁc regions where large aerosol variations can occur and are often dependent on meterological parameters (or show a seasonal evolution or a long-term change), the effect on the UV (and visible) irradiance should not be neglected. In particular, longterm predictions of the UV irradiance behavior should take into account the important role of aerosols. [ ] 
test2_jgra.pickle ---------- ['Quasi-10-day wave in the atmosphere']
10.1002/2015JD023327 In the classical theory of oscillations on a spherical-rotating Earth, the quasi-10-day wave (Q10DW) exists as a westward propagating “free” or “unforced” normal mode oscillation with zonal wave number . In the present study, we employ Thermosphere Ionosphere Mesosphere Energetics and Dynamics/Sounding of the Atmosphere using Broadband Emission Radiometry temperature measurements between 20 and 100 km and 50 latitude, and extending from 2002 to 2013, to provide a comprehensive perspective on the Q10DW as it actually exists in the atmosphere. Climatological seasonal-latitudinal structures are presented which demonstrate that the Q10DW is weakest during summer months and equatorward of 50 latitude but otherwise has amplitudes ranging from 1.0 K at 45 km to 5 K at 100 km. Seasonal asymmetries and signiﬁcant interannual variability also exist. The mean period of the Q10DW is 9.8 days with a standard deviation of about 0.4 day. On average the Q10DW conforms reasonably well with theoretical expectations for a normal mode subject to the eﬀects of dissipation and mean winds, at least below 80 km. Above 80 km this conformity often breaks down. Several factors potentially contributing to this nonconformity are discussed. The atmosphere supports a wide range of wave motions at various spatial and temporal scales and forced by a variety of mechanisms. In this paper we are concerned with a special class of planetary-scale oscillation that, at least theoretically, exists in the absence of a coherent forcing distribution. If we consider the linearized equations of momentum, continuity, and thermal energy with respect to a windless background state without dissipation and assume solutions periodic in time and longitude, then a single equation that is separable in height and latitude can be obtained [see, for instance, Chapman and Lindzen , 1970]. The latitudinal equation (Laplace’s tidal equation) and height equation (“vertical structure equation”) are linked through a separation constant which is often cast in terms of an “equivalent depth” ( ) following Laplace’s initial consideration of the problem for an ocean of depth . In Chapman and Lindzen ’s [1970] application to atmospheric solar tides, the relevant zonal wave numbers ( ), wave frequencies ( ), and equivalent depths are determined by the distribution of tidal heating, and the vertical structure equation (a second-order ordinary diﬀerential equation) is solved for each and s with the corresponding component of the heating distribution speciﬁed. The vertical structure of each oscillation is determined by the equivalent depth of that oscillation as well as the vertical temperature structure. As it turns out, if the forcing in the vertical structure equation is set equal to zero and an isothermal atmosphere is assumed, a single equivalent depth emerges if the vertical velocity is set equal to zero at the lower boundary. The value of this equivalent depth is , where is the scale height for an isothermal atmosphere and is the ratio of speciﬁc heats . For = 7.5 km, = 10.5 km. In turn there is a whole series of oscillations with speciﬁc periods and zonal wave numbers that represent solutions to Laplace’s tidal equation for this particular value of . These solutions are variously referred to as free oscillations, normal modes, or sometimes Lamb waves; in this paper we will use the term “normal mode (NM)” when referring to this particular type of mathematical solution. Well-known manifestations in the actual atmosphere include westward propagating waves with periods (zonal wave numbers) near 2 ( ), 5 ( ), 10 ( ), and 16 ( ) days. In recognition of the observed variability of these wave periods in the atmosphere, they are often referred to, respectively, as the quasi-2-day wave (Q2DW), quasi-5-day wave (Q5DW), quasi-10-day wave (Q10DW), and quasi-16-day wave (Q16DW), and these designations are used to distinguish these atmospheric manifestations from NM. The latitude structures of the 5, 10, and 16 day NM obtained from solving Laplace’s tidal equation are provided in Figure 1. The 5 day and 16 day NM are symmetric about the equator, whereas the 10 day wave is antisymmetric about the equator; it has maxima at 55 latitude which are 180 out of phase. FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE The amplitudes of each of these NM all have the same vertical dependence, given by , where = and z is altitude. This simple theory predicts no phase change with height of the oscillation. As shown by Lindzen and Blake [1972] and Salby [1979], addition of dissipation to the problem introduces an energy sink that leads to vertical propagation characteristics, i.e., phase progression with height. In the actual atmosphere, the main deviations from the above picture include the presence of mean winds, meridional temperature gradients, and dissipation; the governing equations are then far from separable, and global numerical simulations must be employed. Salby [1981] forced a global linear model over a range of frequencies and with latitudinally constant symmetric and antisymmetric forcing, taking into account dissipation and realistic distributions of mean winds. He found that (1) ampliﬁed or “resonant” responses indeed occurred near the expected wave periods and zonal wave numbers; (2) some Doppler shifting of the wave periods from those based on simple theory occurred; (3) latitudinal structures often looked similar to those expected based on solutions to Laplace’s tidal equation, except in the middle atmosphere where zonal mean winds caused signiﬁcant distortion of the response and sometimes complete blocking of the oscillation. Among the notable atmospheric manifestations of NM mentioned previously, the Q2DW has been particularly well studied in the mesosphere and lower thermosphere [see, e.g., Moudden and Forbes , 2014; Yue et al. , 2012; Tunbridge et al. , 2011; Wu et al. , 1993, 1995, and references therein]. The Q5DW and Q16DW have also received some degree of attention over the same height region [ Day and Mitchell , 2010a, 2010b; Day et al. , 2011; Forbes et al. , 1995; Luo et al. , 2000, 2002a, 2002b; McDonald et al. , 2011; Miyoshi , 1999; Riggin et al. , 2006; Wu et al. , 1994]. The Q10DW wave, on the other hand, is less well studied in terms of its manifestations as a normal mode in a realistic atmosphere. Hirooka [2000] does provide some insight into the Q10DW in the stratosphere the month-to-month climatology of the Q10DW extending from the stratosphere to the lower thermosphere? To what altitudes does the Q10DW penetrate? What is the range of wave periods? What is the year-to-year variability? What are the similarities and diﬀerences with respect to NM behavior? In this paper our main objective is to characterize the westward propagating Q10DW with (hereafter just “Q10DW”) from a global perspective and to address the questions raised above. We do this by analyzing Thermosphere Ionosphere Mesosphere Energetics and Dynamics/Sounding of the Atmosphere using Broadband Emission Radiometry (TIMED/SABER) temperature measurements between 50 latitude and 20–100 km altitude during 2002–2013. Except for some relatively minor gaps, the SABER data are for all practical purposes continuous from orbit to orbit and from day to day within these intervals. These data enable us to reveal the latitude versus height structure of the Q10DW between 50 during every month of the year during 2002–2013, to ascertain the exact period of the oscillation and to reveal its interannual variability. The main shortcoming of this data set is the fact that the Q10DW possesses signiﬁcant amplitudes poleward of 50 , a latitude region not continuously measured by SABER. The following section 2 brieﬂy describes the SABER data and how we process the measurements to reveal the Q10DW and its characteristics. Section 3 concentrates on delineating climatological characteristics of the Q10DW and to what degree these conform to expectations in terms of a NM interpretation. FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE The interannual variability of the Q10DW is also revealed here. Section 4 provides a discussion of results, and a brief summary and conclusions constitute section 5. The basic data employed in this study are SABER version 2.0 temperature measurements covering 2002–2013. Since we consider SABER data equatorward of 50 latitude where sampling is uninterrupted by yaw maneuvers and relatively few data gaps exist, we have almost continuous (but asynoptic) coverage in UT and longitude. Taking measurements from ascending and descending parts of the orbit together, SABER provides measurements covering 24 h of local time within 60 day periods. Following the procedure in Forbes et al. [2008], 60 day mean migrating and nonmigrating tides are removed from the raw data by taking residuals from a 60 day running mean and then ﬁtting these residuals with various tidal periods and zonal wave numbers using a 60 day window that moves forward 1 day at a time. The 60 day mean removes most aliasing into the Sun-synchronous tides by the time-varying zonal mean [ Forbes et al. , 1997]. A second set of residuals is formed after removing the tides; amplitudes and phases of the Q10DW with are determined from ﬁts to 5 latitude averages of these secondary temperature residuals within sliding windows and extending from 50 to +50 latitude. Within each window ﬁts are performed with periods ranging from 8.0 to 12.0 days in increments of 0.125 days; the window lengths are 3 times the wave period. At any given height and latitude the Q10DW corresponds to the one ﬁt among these that has the largest amplitude, and it is assigned the corresponding wave period. In the following we will also have occasion to refer to the “10 day wave” as the oscillation with exactly 10 day period, to distinguish it from the Q10DW. The derived Q10DW amplitudes in the present study need to be evaluated in light of potential errors in the temperature measurements and the inﬂuences of these errors on the amplitudes and phases of the sinusoidal ﬁts described above. The relevant errors are the systematic and random errors of the individual temperature measurements, the random error associated with the bin-averaged temperatures being ﬁt, and the amplitude and phase uncertainties with respect to a given sinusoidal ﬁt. We address each of these sequentially in the following. Since we remove zonal means on a day-by-day basis within the data analysis, systematic errors (biases) in the temperature retrieval are removed and random errors represent the primary contributor to temperature measurement uncertainties. Remsberg et al. [2008] provide a detailed error analysis for V1.07 SABER temperatures. For the V2.0 data utilized here, there are no changes relative to V1.07 that would impact precision (random errors). The corresponding random errors in individual temperature measurements for typical midlatitude conditions are 0.3 K, 0.3 K, 0.6 K, 0.6 K, 0.7 K, 1.0 K, 1.8 K, 3.6 K, and 6.7 K at heights ranging from 20 km to 100 km in steps of 10 km. Since the temperature values that are actually ﬁt for the Q10DW are averages within 5 latitude bins, the appropriate measure of uncertainty in the ﬁtted temperatures is given by , where is the number of randomly distributed temperature measurements in a given latitude bin. The average number number at low latitudes and the highest at 50 . Taking 12 points per bin as a representative number, the 1 sigma uncertainties in the temperature values that are ﬁt to extract the Q10DW are about or 0.3 times those quoted above or 0.09 K, 0.09 K, 0.18 K, 0.18 K, 0.21 K, 0.30 K, 0.54 K, 1.1 K, and 2.0 K at heights ranging from 20 km to 100 km in steps of 10 km. The latter values listed above represent the eﬀective random errors of the temperature values being ﬁt, that is, the mean temperatures within 5 latitude bins. The 1 uncertainties in the amplitudes and phases associated with a given sinusoidal ﬁt are aﬀected by these errors if the ﬁt weights the data points according to these errors, if the errors are suﬃciently diverse, and if the number of data points being ﬁt is not too large. Accordingly, we do not ﬁnd the uncertainties in our ﬁts to be inﬂuenced very much by the above temperature errors. Instead, the primary contributor to amplitude and phase uncertainty in the present application is the variance of the data points about the least squares ﬁt (due mainly to other geophysical variability). These uncertainties are now described. The 1 uncertainties in the amplitude and phase for each ﬁt, associated with the scatter of points about the ﬁt, are standard products of any least squares ﬁtting algorithm. For the Q10DW amplitudes presented here, the corresponding 1 uncertainties increase from 0.1–0.2 K between 20 and 40 km to 0.2–0.4 K between 60 and 80 km, the larger (smaller) quoted values being more typical of local winter (summer). Between 80 FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE and 100 km amplitude uncertainties are typically 0.3–0.4 K at 80 km and 0.5–0.7 K at 100 km during all months. The amplitude uncertainties for our Q10DW ﬁts are thus appreciably less than the amplitudes shown in the following section, which tend to range from 0.5 K to 3.0 K from 20 km to 100 km for 12 year means at 50 latitude and 1.0–6.0 K during individual years under the same conditions, for example. The 1 phase uncertainties are always less than 1 day and less than 0.5 day over 80% of the domain. These represent the levels of uncertainty that should be considered when evaluating the ﬁdelity of the amplitudes and phases of the Q10DW displayed in the present work. Figure 2 illustrates the multiyear mean amplitude structure of the Q10DW temperature ﬁeld. Figure 2 (left column) provides latitudinal structures as a function of day of year for altitudes 44 km, 70 km, 86 km, and 100 km. Figure 2 (right column) provides height versus latitude structures for the ﬁtting windows centered FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE on 15 December, 15 September, 15 June, and 15 March. The dashed lines in each panel indicate the latitudinal shape of the Q10DW based on Laplace’s tidal equation (cf. Figure 1) and the amplitudes are only displayed between 50 latitude as discussed previously. In general, at least below 60 km altitude, the Q10DW is mostly active at middle latitudes during winter and around the equinoxes, irrespective of hemisphere. The winter maxima (summer minima) are consistent with the presence of primarily eastward (westward) prevailing winds in the middle atmosphere which tend to enhance (block) vertical penetration of this long-period westward propagating wave. Around equinoxes, the relatively weak prevailing eastward winds do not appreciably inhibit vertical penetration. The illustrated amplitude distributions are consistent with the horizontal shape of the Hough mode (dashed lines), taking into account the aforementioned modiﬁcations due to the prevailing winds. Some hemispheric asymmetry is seen, with larger amplitudes favoring the Northern Hemisphere. Figure 3 reinforces some of the above assertions and makes clear other features as well. Shown here are the multiyear average (2002–2013) Q10DW amplitudes as a function of height and day of year for +50 , 0 , and 50 latitude. Conﬁnement of the Q10DW to equinoctial and winter months below 60 km altitude is particularly evident at +50 latitude where the variation is more or less annual. At 50 latitude, however, there are three broad maxima around days 360–080, 120–180, 210–270, with counterparts above 70–80 km that suggest a connection with those in the stratosphere. At +50 latitude there is an upper level maximum during summer (days 180–240) that does not have a clear counterpart at lower altitudes. At least below 70 km, and consistent with Figure 2 (right column), the weak amplitudes at the equator (Figure 3, middle) comply with the antisymmetric nature of the Q10DW normal mode. FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE As noted previously, the Q10DW is determined through least squares ﬁtting of the residual data for wave periods ranging from 8.0 to 12.0 days, and from among these the amplitude and period of the Q10DW are taken to be the values from the ﬁt yielding the largest amplitude (e.g., see, for example, Tunbridge et al. [2011], who employ this technique to determine the period of the Q2DW]. Figure 4 illustrates some representative samples of the wave periods for December and March at +50 and June and March at 50 latitude. The periods range between about 9.7 and 9.9 days with a standard deviation of about 0.4 days. This result is typical of other latitudes and months. Figure 5 provides some insight into the behavior of the observed Q10DW in terms of its expected behavior as a resonant oscillation mode of the atmosphere. Results are shown for the ﬁtting window centered on 15 September (day 258) when middle atmosphere amplitudes have a maximum and the mean winds are less inﬂuential. Figure 5a illustrates the mean amplitudes over 2002–2013 at +50 and 50 latitude along with standard deviations for 50 N and the theoretical height dependence for a normal mode, namely, , where = altitude and = 0.29. (Standard deviations for 50 S are very similar and are not included for clarity purposes.) We note that the mean amplitudes in opposite hemispheres can be considered equal given the inherent variability and correspond reasonably well with the expected height dependence (as opposed, e.g., to that the amplitudes correspond solely to wave ﬁts with a 10.0 day period. As expected, this leads to somewhat reduced average amplitudes but which are more nearly equal between hemispheres above 60 km. The diﬀerence between Figures 5a and 5b reﬂects the fact that the maximum ﬁtting amplitudes occur over a range of wave periods between roughly 9.25 and 10.5 days (cf. Figure 4). However, deriving amplitudes at exactly 10.0 day period enables us to compare phases (e.g., between heights and latitudes) for a single-period wave, which leads us to Figures 5c and 5d. Figures 5c and 5d provide some information on the phase behavior of the 10 day wave (N.B. as distinct from the Q10DW). Expressing the 10 day wave in the form , we can express phase in two ways: either the time of maximum at 0 longitude or the longitude of maximum at 0 UT. Using the former deﬁnition, Figure 5c shows the mean phase diﬀerences between +50 and 50 latitude between 2002 and 2013 during September, corresponding to the mean amplitudes of the 10 day wave in Figure 5b. The expected behavior for a purely antisymmetric oscillation is a phase diﬀerence of +5 days or 5 days depending on whether 50 N is leading or lagging 50 S. Except for the region between about 30 and 40 km, phases at 50 N are (on average) sometimes in antiphase with those at 50 S (i.e., 60–90 km and 20–30 km) but between 40 and 60 km the two hemispheres are more nearly in quadrature with one another. It is important to note, however, that the standard deviations of these phases are quite large, indicating signiﬁcant interannual variability. FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE Using the second deﬁnition of phase described above, Figure 5d shows the mean phase diﬀerences for the 10-day wave at all heights from that at 40 km altitude in each respective hemisphere, again at +50 and 50 latitude. As noted previously, while a normal mode in a dissipation-less atmosphere would be expected to possess no phase variation with height, the westward tilt with height seen from about 40 km to 100 km in Figure 5 is consistent with an upward and westward propagating wave. Below 40 km altitude the phase behaviors are somewhat diﬀerent between the hemispheres but both being more evanescent-like (i.e., lacking vertical phase progression) below 35 km. Figure 6, which provides height versus time Q10DW amplitude distributions from 20 to 100 km altitude for +50 latitude (top), the equator (middle) and 50 latitude (bottom) provides some insight into the interannual variability of the Q10DW. The larger stratospheric maxima at +50 in comparison to 50 are clearly seen. Also, there is some hint of a biennial modulation of these wintertime maxima, and the equatorial penetration of these maxima is more readily seen than those originating from Southern Hemisphere winter at high latitudes. At higher altitudes, however, equatorial amplitudes are more uniform throughout the year and may not totally reﬂect presence of the Q10DW (see below). It may seem contradictory to refer to nonzero equatorial values for an antisymmetric normal mode (referred to as equatorial penetration above), but in the actual atmosphere and especially during nonequinox conditions the Q10DW does not solely consist of a normal mode. Any asymmetry in amplitude structure about the equator implies the additional existence of at least the symmetric mode with period near 10 days, which is also a solution to Laplace’s tidal equation and thereby an eigenfunction orthogonal to the normal mode. Although this mode lies on the same manifold as the 5 day wave whose latitude structure is depicted in Figure 1 and is also westward propagating with , it is an internal (Class II) wave with vertical wavelength in excess of 100 km [see Figure 9 in Forbes , 1995]. Essentially, this additional mode (plus others to a lesser degree) must exist to accommodate (in the sense of a mathematical decomposition in terms of orthogonal functions) the distortion of the Q10DW imposed by the mean wind ﬁeld. Another viewpoint is that the mean wind ﬁeld acts to couple the antisymmetric mode (see Lindzen and Hong [1974] and Walterscheid and Venkateswaran [1979a, 1979b], for demonstrations and discussions of mode coupling due to mean winds in the context of atmospheric solar tides). mode into the symmetric FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE As noted above, there are some diﬀerences between the observed behavior of the Q10DW and that expected for a theoretical NM, even under the optimal conditions corresponding to Figure 5. To be sure, the inﬂuences of zonal mean, zonal winds, and meridional temperature gradients are having some inﬂuence in this regard; for instance, the temporary interruption of amplitude growth just above 40 km in Figures 5a and 5b can be interpreted in terms of a reduction in wave index of refraction due to background atmospheric wind and temperature distributions that are broadly typical of equinox conditions [ Salby , 1981]. Hemispheric diﬀerences in phase between 50 N and 50 S in Figure 5 are furthermore not entirely consistent with an antisymmetric NM or are the phase changes with height at each of these locations. Based on theory and modeling, phase gradients with height are expected both as the result of dissipation [ Lindzen and Blake , 1972; Salby , 1979] and the presence of mean winds [ Salby , 1981]. Phase diﬀerences from NM behavior are expected when the mean gradient winds calculated from SABER temperatures [see Figure 5 in Zhang et al. , 2010, for example] and ﬁnd this to be the case even for September conditions. Therefore, we attribute much of the phase behavior in Figure 5 that is diﬀerent from that of a NM to the eﬀects of dissipation and mean winds. There are additional and more subtle factors that can possibly aﬀect determination of the Q10DW from SABER temperature measurements as well as interpretation of the derived Q10DW characteristics, especially above 80 km; in the interest of completeness, these are brieﬂy described below. The ﬁrst of these factors is imposed by the way that the TIMED/SABER instrument samples the atmosphere, which opens the possibility for aliasing by other waves. In the present analysis, we remove 60 day mean tidal components and analyze the residuals in 24 to 36 day windows to extract the Q10DW. It is therefore not possible to explicitly ascertain the presence of Q10DW modulation of solar tides, although we know from ground-based observations that such modulations exist in the 80–100 km height region [ Forbes , 1995; Pancheva et al. , 2000, 2003; Pancheva and Mukhtarov , 2000; Pancheva and Mitchell , 2004]. Nevertheless, as demonstrated by Moudden and Forbes [2010] for Mars’ atmosphere [see Forbes and Moudden , 2012, for a terrestrial application], it is possible to gain insights into planetary wave-tide interactions in satellite measurements through examination of spectra with respect to pseudolongitude , that is, longitude incremented by each day and used instead of time to create the spectra. These authors, in fact, demonstrate that the spectral peak corresponding to a planetary wave is indistinguishable from that associated with secondary FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE waves [ Teitelbaum and Vial , 1991] generated by modulation of that same planetary wave with any migrating (Sun-synchronous) solar tide. In the present context this is equivalent to saying that such secondary waves can alias into determination of the Q10DW. Applying this theory further, it is simple to show that modulation of the westward propagating diurnal tides with and and westward propagating semidiurnal tides with and by the Q10DW produce secondary waves that also alias into determination of the Q10DW. All of the aforementioned tides and the Q10DW have been identiﬁed in satellite measurements in the 80–100 km height region [see, e.g., Forbes and Wu , 2006, and Pancheva et al. , 2007, respectively]. Since tides grow exponentially with height and become especially prominent above about 80 km, we must admit the possibility that the Q10DW presented here may be contaminated to some degree by the above aliasing contributions and could account for some nonconformity with expected NM behavior above about 80 km. A second factor that could aﬀect behavior of our derived Q10DW, again above roughly 80 km, is the possible secondary generation of the Q10DW by momentum deposition due to dissipating gravity waves ﬁltered by the Q10DW wind ﬁeld at lower heights. This mechanism seems to be rather well established in the context of much larger amplitude stationary planetary waves [ Holton , 1984; Miyahara , 1985; Schoeberl and Strobel , 1984; McLandress and McFarlane , 1993; Smith , 1996, 1997] but has also been demonstrated in numerical simulations for the Q16DW and Q2DW [ Meyer , 1999]. A suﬃciently large “pseudo Q10DW” at upper levels could interfere with the primary Q10DW, leading to departures from NM behavior in the total observed Q10DW. However, the magnitude of this eﬀect would depend upon the amplitude of the Q10DW wind ﬁeld at lower altitudes. In this paper the height, seasonal-latitudinal, and interannual character of the quasi-10-day normal mode is presented for the 2002–2013 decade using TIMED/SABER temperature measurements. The overall conclusions to emerge from this study are as follows: 1. Q10DW periods generally occur between 9.7 and 9.9 days with a standard deviation of about 0.4 day. 2. The Q10DW is most active at middle latitudes during winter and around the equinoxes, irrespective of hemisphere. 3. The seasonal-latitudinal structure of the Q10DW is consistent with the expected eﬀects of mean winds on this oscillation, particularly away from equinoctial periods. 4. There is a hemispheric asymmetry: The Q10DW is generally more intense in Northern Hemisphere winter than Southern Hemisphere winter, with much reduced amplitudes in local summer due to the blocking eﬀects of zonal mean winds. There is some evidence for a biennial modulation of the Northern Hemisphere winter amplitudes in the stratosphere. 5. Equatorial penetration is more conspicuous in the stratosphere for Northern Hemisphere winter as opposed to Southern Hemisphere winter. 6. Between 80 and 100 km, temporal variability of the Q10DW throughout the year is less well correlated with that at, e.g., 44 km, than between 70 km and 44 km. This suggests that the derived Q10DW above 80 km may be inﬂuenced by other processes in additional to vertical propagation of the Q10DW and also leading to nonconformity with NM behavior. 7. Above 80 km the secondary waves due to Q10DW modulation of migrating tides, and modulation of some nonmigrating tides by the Q10DW with , can alias into determination of the Q10DW as observed from the TIMED/SABER instrument. This can perhaps account in part for some of the reported lack of correlation and nonconformity to NM behavior above 80 km altitude noted above. 8. Another possibly relevant inﬂuence above 80 km altitude is that of momentum deposition near 10 day period by gravity waves ﬁltered by the Q10DW oscillation in the wind ﬁeld at lower altitudes. In principle this is a possible contributor to nonconformity of the observed Q10DW to expected NM behavior in this altitude regime, but its relevance depends on the magnitude of the Q10DW ﬁeld at lower heights as well as properties of the gravity wave spectrum. It is noted that some of the observed Q10DW characteristics are consistent with the previous work of Hirooka [2000], who examined the Q10DW in geopotential heights in UKMO data and those derived from UARS/ISAMS (Upper Atmosphere Research Satellite/Improved Stratosphere and Mesospheric Sounder) temperature measurements up to about 80 km. For instance, Hirooka found similar departures from classical NM behavior in amplitude and phase structures with respect to height and latitude and interpreted these in terms of wave damping and index of refraction of the background atmospheric state. He also noted a cessation FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE of exponential growth in the vicinity of 80 km. The UARS/ISAMS data also provided a view of the Q10DW up to about 80 latitude. The Hirooka [2000] depictions of the Q10DW amplitude and phase behavior were, however, restricted to 7–14 April and 14–21 May 1992. The present work complements that of Hirooka [2000] by providing climatological perspectives on the Q10DW covering every month of the year for over a decade extending up to 100 km, as well as interannual variability, albeit conﬁned to the 50 latitude region. 
test2_jgra.pickle ---------- ['Diurnal variation in Sahara desert sand emissivity during the dry season from IASI observations']
10.1002/jgrd.50863 The problem of diurnal variation in surface emissivity over the Sahara Desert during non-raining days is studied and assessed with observations from the Infrared Atmospheric Sounding Interferometer (IASI). The analysis has been performed over a Sahara Desert dune target area during July 2010. Spinning Enhanced Visible and Infrared Imager observations from the European geostationary platform Meteosat-9 (Meteorological Satellite 9) have been also used to characterize the target area. Although the amplitude of this daily cycle has been shown to be very small, we argue that suitable nighttime meteorological conditions and the strong contrast of the reststrahlen absorption bands of quartz (8–14 m) can amplify its eﬀect over the surface spectral emissivity. The retrieval of atmospheric parameters show that, at nighttime, an atmospheric temperature inversion occurs close to the surface yielding a thin boundary layer which acts like a lid, keeping normal convective overturning of the atmosphere from penetrating through the inversion. This mechanism traps water vapor close to the land and drives the direct adsorption of water vapor at the surface during the night. The diurnal variation in emissivity at 8.7 m has been found to be as large as 0.03 with high values at night and low values during the day. At 10.8 m and 12 m, the variation has the same sign as that at 8.7 m, but with a smaller amplitude, 0.019 and 0.014, respectively. The impact of these diurnal variations on the retrieval of surface temperature and atmospheric parameters has been analyzed. Diurnal variations in desert sand emissivity during the dry season have been brought to the public’s attention recently by Li et al. [2012] who performed an analysis with SEVIRI (Spinning Enhanced Visible and Infrared Imager) observations from the European geostationary platform Meteosat (Meteorological Satellite). A recent analysis [ Masiello et al. , 2013b] performed by some of the authors of this paper with SEVIRI data conﬁrms this eﬀect and also shows that the time variation of emissivity closely follows the daily cycle for temperature. Diurnal variation in surface emissivity is very likely to occur in the natural environment because emissivity ( ) is inﬂuenced by soil water content ( ), which even in nonrainfall seasons, can change due to dew condensation at night, for example. However, the emissivity variation we are investigating occurs in desert areas, during non-raining days when the surface temperature does not necessarily drop below the dew point temperature at night. There are a series of basic studies, which can help to explain the phenomenon of diurnal emissivity variations during non-raining days in the dry season and in environmental conditions that do not favor the occurrence of dew formation on a bare sand dune. Agam and Berliner [2004, 2006] brought evidence of a new mechanism of direct water vapor adsorption on land surface. They also showed that the resulting soil moisture variations (with the soil moisture expressed by weight as the ratio of the mass of water present to the dry weight of the soil sample, units of kg kg ) follow the daily cycle [ Agam and Berliner , 2004] and the uppermost soil layer (0–1 cm) can change its water content from below kg kg (around midday) to above kg kg before sunrise. Mira et al. [2007a, 2007b] showed that the thermal infrared emissivity of rich-quartz sand strongly depends on soil moisture content. For low values of soil water content (around 0.02 kg kg ), the incremental ratio, , at wave numbers of reststrahlen absorption, is very large: per kg kg [ Mira et al. , 2007a, 2007b]. MASIELLO ET AL. 1626 The present study is devoted to complement the analysis by Li et al. [2012] and to provide further evidence that the mechanisms outlined in Agam and Berliner [2004, 2006] and Mira et al. [2007a, 2007b] are those responsible for the satellite-based emissivity diurnal variations observed in arid regions. Toward this objective we have analyzed IASI (Infrared Atmospheric Sounding Interferometer) spectra recorded over a Sahara desert area during the dry season (July 2010). Both descending (daytime) and ascending (nighttime) orbits have been considered, and the surface emissivity spectrum has been retrieved simultaneously with skin temperature and atmospheric parameters, namely temperature, water vapor, and ozone proﬁles, from IASI radiances. Space colocated day and night IASI observations have been used to assess diurnal emissivity variations. A quantitative analysis of the impact of these variations on the retrieval of surface temperature and atmospheric parameters is also carried out. We stress that the eﬀect of soil moisture over thermal infrared emissivity has been assessed both with laboratory measurements and satellite observations [e.g., Ogawa et al. , 2006; Mira et al. , 2010; Hulley et al. , 2010]. However, the present study focuses on the phenomenon of diurnal variation in emissivity of desert sand in situations in which soil moisture does not change because of rain or dew condensation. Diurnal variation in emissivity has also been evidenced with IASI observations by Zhou et al. [2011], who performed a retrieval of emissivity on a global scale. However, no attempt was made to assess the driving mechanism of these variations for desert regions. IASI was developed in France by the Centre National d’Etudes Spatiales (CNES) and is ﬂying on board the Metop-A (Meteorological Operational Satellite) platform, the ﬁrst of three satellites of the European Organization for the Exploitation of Meteorological Satellite (EUMETSAT) European Polar System (EPS). IASI has been primarily put in orbit for a meteorological mission; hence, its main objective is to provide suitable information on temperature and water vapor proﬁles. The instrument has a spectral coverage extending from 645 to 2760 cm , which with a sampling interval cm gives 8461 data points or channels for each single spectrum. Data samples are taken at intervals of 25 km along and across track, each sample having a minimum diameter of about 12 km. With a swath width on Earth’s surface of about 2000 km, global coverage is achieved in 12 h, during which the instrument records about 650,000 spectra. Further details on IASI and its mission objectives can be found in Hilton et al. [2012]. Regarding the assessment of the origin and mechanism of diurnal variation in emissivity, the complementary role of IASI stands out in its atmospheric sounding capability, which provides information about the thermodynamical state of the atmosphere together with surface parameters. The retrieval of surface and atmospheric parameters from IASI spectral radiances is carried out with a package that we call -IASI, the methodological aspects and validation of which have been described in many papers [ Amato et al. , 1995, 1999; Lubrano et al. , 2000; Masiello et al. , 2003; Masiello and Serio , 2004; Grieco et al. , 2007; Amato et al. , 2009; Masiello et al. , 2009; Grieco et al. , 2010; Masiello et al. , 2011, 2012a, 2012b]. The reader is referred to these papers for further details. For our analysis, it was important to identify a target area with surface features characterized as much as possible by sand rich in quartz and without vegetation. In addition, it was important to identify a series of IASI observations over a relatively long sequence of clear sky days in order to perform the analysis in non-raining meteorological conditions. To this end, together with IASI (level 1C) observations, we have also used high rate level 1.5 image data from SEVIRI on board Meteosat-9. SEVIRI channel emissivity maps over the North-West Sahara [ Masiello et al. , 2013b] helped to identify a target area characterized by sand dunes, whereas time sequences of SEVIRI radiances were used to identify long periods of clear skies. The present study is organized as follows. Section 2 shows the data used in the analysis, whereas section 3 describes the methodology. Section 4 is devoted to the results. Conclusions are summarized in section 5. The selected study area is located over the Sahara Desert, Ouargla Province, Algeria (see Figure 1). The area extends from to of East longitude and 29 to 33 North latitude, at an average altitude of about 200 m. Sand dunes prevail with a low vegetative cover. IASI data have been acquired for the month of July 2010, that is, in the middle of the dry season. Observed spectra correspond to the descending (day) orbits and ascending (night) orbits. The IASI scan pattern of footprints for a typical day (ascending and descending MASIELLO ET AL. 1627 orbits) is shown in Figure 1. Normally, we have approximately 400 spectra per day, of which half are in the morning (around 9 to 10 UTC) and the remaining half in the evening (around 20 to 21 UTC). The spectra were qualiﬁed as clear sky using the stand alone IASI cloud detection scheme developed by Serio et al. [2000]; Masiello et al. [2002, 2003, 2004] and Grieco et al. [2007]. A select few day-night spectra are shown in Figure 2 for the IASI band 1. The daytime IASI spectrum shows the characteristic peak at 8.7 m (1149.40 cm ), which corresponds to the center of the reststrahlen doublet of quartz. The nighttime spectrum clearly shows H O lines in emission in the atmospheric window around 1100 cm (9 m), which signals a temperature inversion at the surface. It has to be stressed here that ascending/descending IASI footprints (see also Figure 1a) are not perfectly overlapped. Therefore, the surface seen in the morning orbit could be diﬀerent from that seen during the night. To limit as much as possible any bias due to spatial collocation, we have considered day-night footprints with an overlap greater than 40% (see, e.g., Figure 1b). Another source of possible emissivity variation is the zenith angle. According to García-Santos et al. [2012], desert sand emissivity has an angular behavior, which becomes important for zenith angles . For this reason we have considered IASI pairs with a ﬁeld of view angle lower than . Based on the two selection rules above, the number of day-night month are shown in Figure 3. Meteosat 9 high rate SEVIRI level 1.5 image data in the infrared for the same target area and time period were also extensively used to characterize the surface emissivity [ Masiello et al. , 2013b]. The SEVIRI instrument has eight infrared channels with peaks at 13.4 (746.30), 12.0 (833.33), 10.8 (925.90), 9.7 (1030.9), 8.7 (1149.40), 7.3 (1369.9), 6.2 (1612.9), and 3.9 (2564.10) m (cm ), respectively. The time resolution of the data is 15 min, whereas each pixel has a size of km . Particularly interesting for the present analysis is the SEVIRI channel at 8.7 m (1149.40 cm ). In fact, this channel is MASIELLO ET AL. 1628 located just in the quartz doublet peak of the reststrahlen band, which has a very high contrast within the atmospheric window. Using SEVIRI observations for July 2010 [ Masiello et al. , 2013b], it was possible to check that the selected study area shows emissivity features common to desert sand rich of quartz. In addition, SEVIRI data (colocated with IASI footprints) have been also used to identify clear sky through a direct inspection of the time sequence at SEVIRI window channels, such as that at 12 m (833.33 cm ). An example is shown in Figure 4, where the temporal evolution of SEVIRI radiances at 12 m is plotted for the month of July. The ﬁgure corresponds to SEVIRI pixels at 30.66 North latitude and 5.56 East longitude. The radiance sequence follows exactly the daily cycle. Deviations (even small) from the smooth signal expected for clear sky allow us to detect the presence of clouds. From this plot we see that the ﬁrst 10 days of the month were characterized as clear sky, whereas clouds were present at the end of the month (around 25 July). IASI spectra have been inverted for emissivity, skin temperature, and atmospheric parameters using the -IASI package. As mentioned in section 1, the details of the package have been described at length in a series of papers. Here we limit ourselves to describe the methodology we use for emissivity, which is a relatively new aspect of the scheme. We use the optimal estimation [ Rodgers , 2000] with the emissivity spectrum represented with a truncated Fourier transform series [ Masiello and Serio , 2013a]. Emissivity Fourier coeﬃcients, skin temperature ( ), and atmospheric parameters, temperature ( ), water vapor mixing ratio , and ozone mixing ratio proﬁles, are simultaneously retrieved. For the forward model, we use -IASI [ Amato et al. , 2002], which can handle the radiance term reﬂected from the surface either with a specular or Lambertian model. For the analysis shown in this paper, we use the Lambertian model. Within the inverse scheme, an important issue is the background vector and covariance matrix for emissivity. For the purpose of developing a suitable background for emissivity, we have used the University of Wisconsin (UW) Baseline Fit (BF) Emissivity database (UW/BFEMIS database, e.g., http://cimss.ssec.wisc. edu/iremis/ [ Seemann et al. , 2008]). The UW/BFEMIS database is derived from the monthly mean operational Aqua/MODIS (Moderate Resolution Imaging Spectroradiometer) products (called MYD11C3) using a conceptual model called the MASIELLO ET AL. 1629 Baseline Fit method developed from laboratory measurements of surface emissivity. This method is applied to ﬁll in the spectral gaps between the six emissivity wavelengths available in MYD11C3 products. The UW/BFEMIS database is available from the year 2003 to 2012 globally with 0.05 spatial resolution at 10 wavelengths (3.6, 4.3, 5.0, 5.8, 7.6, 8.3, 9.3, 10.8, 12.1, and 14.3) m. Those wavelengths were chosen as hinge points to capture as much of the shape of the higher resolution emissivity spectra as possible between 3.6 and 14.3 m. The available band emissivities cannot be straightly interpolated to the IASI spectral bands, because this would be too crude an approximation. This problem has been addressed in Borbas and Ruston [2010] where an Empirical Orthogonal Function (EOF) regression was applied between the UW/BFEMIS database and the ﬁrst ﬁve eigenvectors at high spectral resolution of a representative set of laboratory measurements of surface emissivity. In this study a similar algorithm has been developed to interpolate a low spectral resolution emissivity spectrum to the IASI wave number range. As in Borbas and Ruston [2010], the interpolation is based on the EOF decomposition of a suitable training data set of high spectral resolution emissivity spectra from laboratory measurements. For the present study, we used a total of 134 emissivity spectra from the ASTER (Advanced Spaceborne Thermal Emission Reﬂection Radiometer) Spectral Library version 2.0 [ Baldridge et al. , 2009] and the MODIS UCSB (Moderate Resolution Imaging Spectrometer, University of California, Santa Barbara) Emissivity Library (http://www. icess.ucsb.edu/modis/EMIS/html/em.html). An example of the interpolation from UW/BFEMIS to IASI is presented in Figure 5. Derived from the UW/BFEMIS database, these IASI spectral resolution emissivity spectra have been used to build up an appropriate a priori or background (mean and covariance) for the optimal estimation retrieval. For the emissivity-covariance matrix, we only considered the diagonal elements (variances). As noted, in our retrieval procedure, the emissivity spectrum is represented through decomposition in a truncated Fourier cosine series. The truncation point can depend on the surface type. For desert sand, we need to resolve the reststrahlen absorption band at 8.7 m. For this reason, we have used 400 Fourier coeﬃcients, which correspond to render the emissivity spectrum with a spectral resolution of cm . Comparison with laboratory measurements shows that this spectral resolution is enough to resolve the spectral structures present within desert sand emissivity [ Masiello and Serio , 2013a]. Further details on how we handle the retrieval of surface emissivity can be found in Masiello and Serio [2013a]. Here we limit to show a retrieval example from one IASI spectrum recorded over desert sand. The example (see Figure 6) is shown here also to exemplify the precision of the retrieval. The precision is computed as the square root of the diagonal of the a posteriori covariance matrix. An additional important aspect of the methodology is that we can retrieve the emissivity spectrum over the entire IASI spectral coverage, even though we only used a limited number of IASI channels (see Figure 6). At wave numbers not used for the mathematical inversion of IASI radiances, the retrieved emissivity spectrum is just an interpolation of the Fourier cosine series. It is also important to stress that as the IASI spectrum is mostly sensitive to surface emission in atmospheric window spectral regions, the emissivity retrieval is most signiﬁcant in those regions. MASIELLO ET AL. 1630 where As described earlier, we use the optimal estimation [ Rodgers , 2000] to retrieve the state vector. Within the context of optimal estimation theory we can also address the issue of the sensitivity of the retrieval to the variation by a model parameter, which, e.g., is not included in the state vector. The general problem of sensitivity to a given interfering parameter can be handled by considering the derivative of the retrieved vector, with respect to the perturbation introduced by the interfering parameter, e.g., spectral emissivity. According to Carissimo et al. [2005], this derivative can be written as (1) 1. is the retrieved state vector, 2. denotes the generic interfering parameter-vector, 3. 4. 5. is the Jacobian matrix of the state vector, 6. is the Jacobian matrix of the emissivity vector. is the state vector background matrix, is the observational covariance matrix, (e.g., IASI radiometric noise), The sensitivity of the state vector, to a given perturbation, is obtained as (2) As already mentioned, the way we handle the various Jacobian terms and covariance matrix has been detailed at a length in previous papers. In particular, the reader interested in the details of in our retrieval scheme, is referred to Masiello et al. [2012a]. , which we use If we identify with the diurnal variation in emissivity, the methodology above can be used to assess the impact over the estimated state vector of this variation in case the emissivity is not retrieved and its value is taken, e.g., from a suitable atlas, such as the UW/BFEMIS database. Finally, we recall that the soil moisture ( ) is deﬁned according to its gravimetric method of measurement, (3) where is the mass of wet soil and that of the dry soil. The IASI spectra corresponding to day-night pairs identiﬁed in Figure 3 have been inverted for the simultaneous retrieval of , , , , and , according to the methodology outlined in section 3. The number of IASI channels considered for the retrieval are those shown in Figure 6. To make a proper comparison, e.g., with the results shown in Li et al. [2012] and also to capture salient characteristics in the diurnal emissivity variation, the IASI emissivity retrieval has been transformed to the SEVIRI channel emissivity at 12, 10.8, and 8.7 m, by convolving the IASI spectrum emissivity with the SEVIRI instrument response at 12, 10.8, and 8.7 m, respectively. The results for the days for which we had available MASIELLO ET AL. 1631 pairs to allow computation are shown in Figure 7. Averaging the results over the whole month, we found an average diurnal emissivity variation of 0.029 at 8.7 m, 0.019 at 10.8 m, and 0.014 at 12 m. From Figure 7, we see that the largest diurnal variations are seen around periods with heavy cloudiness (compare with Figure 4). If we focus on the most stable, non-raining period, that is, the ﬁrst 10 days of the month, we see that the diurnal variation is conﬁned below 0.04 at 8.7 m and, normally, well below 0.02 at 10.8 and 12.8 m. According to Li et al. [2012], we also see that the diurnal variation is larger at 8.7 m than at 10.8 m, which, in turn, is larger than that at 12 m. Details of the diurnal variation in spectral emissivity for 6 and 20 July, which correspond to two clear sky days with the larger number of couples of IASI day-night spectra and in the middle of two long periods of clear skies are shown in Figures 8 (left) and 8 (middle), respectively. A direct computation of the dew point temperature, derived from the IASI retrieval, shows that the diurnal variation we see in Figure 8 cannot be due to the formation of dew, because the dew point temperature is found well below the surface temperature. An example is shown in Figure 9 for 20 July 2010. A similar behavior was also found by Li et al. [2012]. As a consequence, on the assumption that the observed diurnal emissivity variation seen in Figures 8 (left) and 8 (middle) is due to soil moisture, according to Agam and Berliner [2004, 2006], the only mechanism responsible for the change is that of direct water vapor adsorption at the surface. To support this conclusion, we have analyzed the thermodynamical state of the atmosphere close to the surface. For 6 and 20 July 2010, this analysis is shown again in Figures 8 (left) and 8 (middle). The daytime retrieval does not show any inversion close to the surface and has a normal shape that favors evaporation. Conversely, the nighttime temperature proﬁles show an evident inversion, which traps water vapor close to the surface. This temperature inversion is consistent with the mechanism for H O adsorption and drives the day-night emissivity variation. In the same ﬁgures, the water vapor proﬁle is also shown. It is possible to see O is very low. For 6 and 20 July, the diurnal variation in water vapor column amount (day-night) is of 0.23 cm and 0.16 cm, respectively. This very small variation leads us to conclude that the atmosphere was very stable, and the presence of moisture by large scale atmospheric circulation was likely absent. To further support the above conclusion, Figure 8 (right) also shows the results for 26 July 2010. On this day, the diurnal variation was very low (below 0.005 at 8.7 m) and the emissivity retrieval at 9 UTC was almost identical to that at 20 UTC. However, for this day, the nighttime temperature proﬁles do not show any evident inversion in the boundary layer (see again Figure 9, right). This result conﬁrms that the mechanism which causes the diurnal emissivity variation is governed by a boundary layer temperature inversion. Also, a strong diurnal temperature diﬀerence seems to be important for the emissivity variation. This diﬀerence was 12 K for 26 July, whereas for 6 and 20 July, this was 19 K and 20 K, respectively. The temperature proﬁles shown in Figure 8 have been averaged over the number of soundings available for the given days. This averaging operation tends to smooth the inversion in the lower troposphere. However, the inversion is very well seen in each single retrieval and takes place very close to the surface. This is exempliﬁed for one single temperature retrieval in Figure 10a, which also compares the IASI retrieved temperature with the time-space colocated ECMWF analysis. The ECMWF analysis at the canonical hours of 00, 06, 12, 18, 24 UTC were used for the time interpolation. It is seen that the ECMWF model greatly MASIELLO ET AL. 1632 MASIELLO ET AL. 1633 smoothes the temperature day-night dynamic in the lower troposphere, which, conversely, appears much more pronounced in the IASI retrieval. From Figure 10, we see that an inversion occurs in between 975 and 925 hPa, which corresponds to a boundary layer altitude of m. It could be questionable whether or not IASI has this high vertical spatial resolution close to the surface. To demonstrate that in fact IASI does have this high spatial vertical resolution, Figures 10b and 10c show the averaging kernels for the two IASI temperature retrievals shown in Figure 10a. The very highly resolved averaging kernels close to the surface, as already mentioned, are a result of the desert sand emissivity, which yields a strong contrast throughout most of the IASI bands 1 and 3. What is important to capture in Figures 10b and 10c is the fact that the averaging kernels peak almost exactly at the corresponding layer pressure. This behavior shows that the retrieval is spatially resolved in the vertical at those layers in the lower troposphere. The results we have shown have been obtained over a target area, whose surface consists of bare sand dunes. In these conditions, the emissivity is largely determined by a mixture of two components: soil water content and sand. According to Hillel [1998], the process responsible for water vapor adsorption by soils is a reversible physical adsorption, which allows us to deal with moist soil as if it were mainly a mixture of water and sand. Chemical processes do not play an important role in this adsorption mechanism [ Hillel , 1998]. In this respect, if these two components are additively combined, according to their abundance in the mixture, we obtain a composite emissivity, given by (4) where is the emissivity of sand and that of water. MASIELLO ET AL. 1634 Under a variation of soil moisture, a variation is given by (5) in the whole infrared range, Since the diﬀerence has a very large amplitude (contrast) at the reststrahlen doublet of quartz, where can be as low as 0.6 [ Baldridge et al. , 2009]. This is why we see that the eﬀect of diurnal variation is larger at 8.7 m than at 10.8 and 12.0 m. In addition, the above model states that a reverse sign in the diurnal variation is possible in spectral regions where the diﬀerence changes its signs. For the type of surface we have analyzed, we expect that, within the atmospheric window, water has the larger emissivity. Therefore, the sign of the diurnal variation (nighttime-daytime) should normally be positive at window channels such as 8.7, 10.8, and 12 m. However, especially at 12 m, we may have land features with emissivities larger than that of water and a reverse sign could be possible. This reverse sign has been observed by Li et al. [2012], who examined a much larger area than that analyzed in this paper. According to Agam and Berliner [2004, 2006], diurnal variations in the uppermost 1 cm soil layer moisture due to the direct H O adsorption have amplitudes of approximately 2%. This variation might be not enough to explain the diurnal variation we have observed in the atmospheric window. However, thermal infrared measurements from satellite are sensitive to the top few micrometers. Thus, a 2% amplitude below the surface could not be representative of what is occurring in the topmost layer, where the eﬀect could be larger, and therefore explains the magnitude of diurnal variation we see at 8.7 m. It is also fair to say that a non-Lambertian behavior has been evidenced in quartz powder [ Wald and Salisbury , 1992], which at large angles ( ) has the eﬀect of decreasing the emissivity. A similar behavior has been evidenced in a recent paper by García-Santos et al. [2012], who also claimed that a non-Lambertian behavior begins to be evident at zenith angle larger than 40 . However, as already discussed, to limit possible angular dependence of the sand emissivity, the IASI day-night couples we have analyzed in this paper refer to zenith angles below 40 . In addition, the relative zenith angle, that is, the day-night diﬀerence of the ﬁeld of view angle does not exceed for any single day-night pair analyzed in this paper. In other words, the two IASI spectra of any single pair are observed with almost the same ﬁeld of view angle. This is exempliﬁed for 6 July 2010 in Figure 11. How signiﬁcant are these diurnal variations and what impact do they have on the retrieval of skin temperature, and MASIELLO ET AL. 1635 atmospheric parameters, temperature, water vapor, and ozone, ( , , and )? These issues have been addressed by applying the sensitivity analysis illustrated in section 3 to the retrieval obtained for 6 July 2010. This day is in the middle of a non-raining period with an average diurnal variation in emissivity at 8.7 m of 0.04. We have 28 day-night IASI soundings for 6 July 2010, the day and night average emissivity for which is shown in Figure 12. For each single daytime sounding, we have computed corresponding to the perturbation , (6) In this way, we mimic the eﬀect of using the nighttime emissivity to invert daytime IASI soundings. The results have been averaged over the 28 daytime IASI soundings and are shown in Figure 13. For the case of , we ﬁnd that this parameter would be negatively biased, because we use an emissivity, which is larger than the (supposedly) correct one, obtained within the simultaneous retrieval (section 4). The average negative bias for the surface temperature is equal to K. For the atmospheric parameters we also see a consistent bias, which means that the diurnal variation has a large impact over the retrieval of these parameters. The bias for temperature has a peak value of 8 K in the lower troposphere, whereas for water vapor we observe a diﬀerence of g/kg. For ozone we also observe a consistent bias of 1 ppmv. A second example is obtained by considering a variation with respect to the emissivity obtained by the UW/BFEMIS database. Derived from MODIS day-night products, the UW/BFEMIS database emissivity assumes a constant emissivity between day and night in the retrieval. Thus, it does not represent an average of diurnal variations, but it is simply one emissivity per day and, therefore, the present sensitivity exercise is also important to check the quality of satellite products, where emissivity is assumed to be diurnally invariant. In performing the sensitivity exercise, the UW/BFEMIS emissivity is imposed on the retrieval and the diﬀerence is considered for the case in which emissivity is itself retrieved along with , , , and . This latter For the 28 day-night IASI soundings, the average UW/BFEMIS emissivity is compared to the retrieved emissivity in Figure 12. In the case of the daytime IASI soundings, the emissivity perturbation is computed according to In the same way for the nighttime soundings, we have (7) (8) The results of the sensitivity analysis are summarized in Figure 14. For the case of skin temperature, we have that the assumption of imposing on the retrieval the UW/BFEMIS emissivity instead of simultaneously retrieving it with the other parameters, would result in a downward bias in during the day and, the reverse, an upward bias in would result at night. However, on average, the degree of this bias is conﬁned to within K ( K in the daytime and K at nighttime). The impact on atmospheric parameters appears to be much larger. The temperature can be aﬀected by K in the lower troposphere, the water vapor mixing ratio by g/kg and ozone by up to 2 ppmv in the stratosphere. MASIELLO ET AL. 1636 We have addressed the issue of diurnal variation in the emissivity spectrum of desert sand with a series of day-night IASI soundings recorded over the Sahara Desert during July 2010. In our analysis, great care has been taken to ensure that (a) the target area included only bare sand dunes, (b) there was a long sequence of clear sky with no rain, and (c) the IASI angle of views were below to minimize other possible sources of emissivity variation. In agreement with Li et al. [2012], our analysis does ﬁnd evidence of diurnal variations in the emissivity spectrum. Nighttime emissivity is found to be systematically larger than that retrieved during the daytime, which leads us to conclude that the soil moisture undergoes a daily cycle with a dip around midday and a peak at night. This conclusion is consistent with previous results by Agam and Berliner [2004, 2006], who showed that H O can be directly adsorbed at the surface without the formation of dew. During the dry season, the amplitude of the soil moisture cycle is normally 1–2%. These values refer to the top few centimeters of soil moisture, while thermal infrared measurements represent the top few micrometers. Accounting also for nonlinear volume scattering eﬀects and further experimental evidence [ Mira et al. , 2007a, 2007b] about the eﬀect of soil moisture on rich-quartz sand, we conclude that this amplitude is enough to yield diurnal variations in emissivity at 8.7 m as large as 0.04. The question of how common this phenomenon is can be raised. Direct adsorption of water vapor has been shown for arid and semiarid regions [ Agam and Berliner , 2006]. However, the phenomenon depends on the thermal and hydraulic properties of the surface and these properties can vary signiﬁcantly for diﬀerent soil types. Normally, the presence of clay improves the adsorption mechanism [ Agam and Berliner , 2006]. If we limit to stable, dry meteorological conditions, the transport of water vapor is driven by moisture and temperature gradients. Thus, a temperature inversion close to the surface is important to transport moisture toward the surface, as well, it is necessary that relative humidity of the soils pores is lower than the relative humidity of the air. As far as the transport of atmospheric water vapor toward the surface is concerned, IASI retrieval of the thermodynamic state of the atmosphere has shown that at nighttime an atmospheric temperature inversion occurs close to surface and creates a thin boundary layer which acts like a lid, trapping water vapor close to land and supposedly driving the direct adsorption of H O at the surface during the night. The results we have found lead us to conclude that the common belief that the desert sand emissivity is stable during the year is not correct and that diurnal variations have to be properly taken into account for a correct retrieval of surface and atmospheric parameters. In this respect, our ﬁndings speciﬁcally point out the importance of using physically based algorithms to retrieve surface temperature and emissivity. Split-window type algorithms, which are commonly used to retrieve surface parameters from satellite imaging radiometer instruments, such as MODIS and SEVIRI do not take these diurnal emissivity variations into account, and neither does the MODIS/Terra Land Surface Temperature and Emissivity Daily Level 3 Global 5 km Grid (short name MOD11B1) day-night approach, which could result in large surface and lower troposphere temperature errors. 
test2_jgra.pickle ---------- ['A simulation study on the electric ﬁeld spectral dependence of thunderstorm ground enhancements and gamma ray glows']
10.1002/2016JD026422 We have done a thorough simulation analysis on the variability of the photon spectra produced with (due to Relativistic Runaway Electron Avalanche—RREA) and without (Modiﬁcation of Spectra) the avalanche multiplication process. Despite some measurements obviously showing a variability of the spectra, numerous theoretical studies consider RREA spectrum independent on the electric ﬁeld. However, analytical calculations by Cramer et al. (2014) have shown that RREA spectrum under low electric ﬁelds is not constant and stops being exponential. Using the Relativistic Electron Avalanche Model code, we model various layouts of the electric ﬁeld conﬁguration and study the predicted photon spectra. The primary focus of the present paper is to study the photon energy spectra, as gamma rays are more often observed by ground-based detectors. The simulation analysis of photon spectra potentially can help to deduce electric ﬁelds in thunderclouds. The energetic radiation from thunderstorms is currently being measured by ground-based particle detectors worldwide [ Torii et al. , 2002; Khaerdinov et al. , 2005; Chilingarian et al. , 2010; Tsuchiya et al. , 2011], by means of aircraft [ Kelley et al. , 2015] and balloon measurements [ Eack et al. , 2000]. These phenomena can last for tens of minutes and are much longer than submillisecond Terrestrial Gamma-ray Flashes (TGFs) typically observed by spaceborne instruments [ Fishman et al. , 1994]. The long-lasting ﬂuxes are usually referred as Thunderstorm Ground Enhancements (TGEs) when observed from ground-based detectors or gamma ray glows when observed from airborne detectors. The understanding of processes leading to the observed particle ﬂuxes was signiﬁcantly improved during the electric ﬁelds lower than conventional breakdown ﬁeld. The idea was that the atmospheric electric ﬁelds accelerate ambient electrons, which produce secondary knock-on electrons and consequently bremsstrahlung photons. Dwyer [2003] studied these eﬀects by means of Monte Carlo simulations focusing on the high-energy radiation named Relativistic Runaway Electron Avalanches (RREAs) rather than lightning initiation. The good agreement between the simulations and measurements of TGFs and gamma ray glows suggests that RREA is the probable mechanism of the observed electron and gamma ray production in thunderclouds. In this study, we will focus on ground-based measurements as they provide an opportunity of constant monitoring of the high-energy atmospheric phenomena in highly active thunderstorm regions, for example, Tampa Bay or Lake Maracaibo in Venezuela [ Albrecht et al. , 2016]. As electrons rapidly attenuate in the atmosphere, most of the information comes from gamma rays [ Torii et al. , 2002; Chilingarian et al. , 2014; Tsuchiya et al. , 2011]. In fact, Chilingarian et al. [2014] was the ﬁrst to suggest that the intracloud electric ﬁeld during TGEs can be measured based on observing the gamma ray spectrum on the ground. There are only few cases where electrons were measured at the ground level. Chilingarian et al. [2012, 2013] were able to estimate the energy spectra of TGE electrons along with gamma ray spectra for the ﬁrst time. In general, the measurements are in a good agreement with the large-scale RREA model. However, as it was stated in several papers [see, e.g., Dwyer , 2004; Dwyer and Babich , 2011], the energy spectrum of RREA electrons is expected to have an exponential cutoﬀ at 7 MeV. Unlike this model prediction, when measuring TGEs, the electron spectra CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS diﬀer from event to event with mean energies that are less than 7 MeV. At the same time, the analytical calculations by Cramer et al. [2014] showed that RREA energy spectra at low electric ﬁelds ( kV/m) stop being exponential with 7 MeV cutoﬀ and can be described by a convolution of exponential and power law functions. Most interestingly, a dependence of the RREA energy spectra on the atmospheric electric ﬁeld was found, which explains the measured diversity of the TGEs presented by Chilingarian et al. [2012, 2013]. For most of the TGE glows, only gamma ray spectra are possible to estimate. At the same time, the estimations of Chilingarian et al. [2014] showed that some of the events correspond to cases where the electric ﬁelds are lower than the critical ﬁeld necessary for the RREA initiation. This process is termed Modiﬁcation of Spectra (MOS), when secondary cosmic ray electron spectra are modiﬁed without an avalanche multiplication process earlier suggested by Chilingarian et al. [2012]. In this paper, we will focus on the electric ﬁelds below and slightly above RREA threshold to study the variability of the spectra and their dependence on the electric ﬁeld layout. As there are experimental indications and analytical estimations that RREA electron and gamma ray spectra are varying with the electric ﬁeld, the RREA particle measurements give a unique possibility to probe atmospheric electric ﬁelds. We will discuss the possibilities of the deduction of electric ﬁeld parameters based on the Monte Carlo simulations by Relativistic Electron Avalanche Model (REAM) [ Dwyer , 2003, 2004, 2005, 2007, 2008; Coleman and Dwyer , 2006]. In addition, we make comparisons with a Monte Carlo code developed by Celestin and Pasko [2011]. In this work, we use the runaway electron avalanche model (REAM) to simulate the production and propagation of high-energy electrons inside thunderstorms. REAM is a Monte Carlo code that includes the relevant cross sections for the interactions of electrons, photons, and positrons with air [ Dwyer , 2003]. These processes include atomic excitation, Møller scattering, bremsstrahlung emission, pair production, and annihilation. We then study the transport of the resulting X-rays and gamma rays to the observation level. We use an initial population of 10,000 runaway electrons as seeds to the avalanche. The electrons are injected with energies following a secondary cosmic ray power law spectrum. The spectrum is estimated by using the Excel-based Program for calculating Atmospheric Cosmic-ray Spectrum (EXPACS) [ Sato , 2015]. EXPACS was also used to estimate the seed electron spectrum in Chilingarian et al. [2012, 2014]. The power law index of 1.13 was calculated for 5000 m corresponding to typical thundercloud altitudes at Mount Aragats [ Chilingarian et al. , 2014]. We run several diﬀerent electric ﬁeld strengths and acceleration lengths of 500, 1000, and 1500 m. It is worth mentioning that for the sake of future comparisons, these distances were used under sea level density. For instance, because of the similarity of the system under diﬀerent air densities, at 12 km altitude, 1500 m at sea level corresponds to 6.3 km. This acceleration length is the most extreme case to consider, as we think that larger values are improbable to observe. The electric ﬁelds used in the simulation were normalized by the threshold value for which electrons run away, = 286 kV/m. This value is higher than the break even ﬁeld ( = 215 kV/m), which is the strength where minimum ionizing electrons lose energy [ Cramer et al. , 2016]. Note that the calculations to obtain these values are done for an atomic number density of air equal to atoms/m . Values at diﬀerent altitudes and conditions may be found by scaling these results with the atomic number density. The diﬀerence between and is due to Coulomb scattering, which increases the path length of the electrons [ Dwyer , 2004]. Hence, we use the quantity , where is the local electric ﬁeld, to characterize the external ﬁeld conditions. We speciﬁcally study ﬁeld values slightly above and below (i.e., is close to 1) in order to compare modeling results with the experimental results of Chilingarian et al. [2014] and the theoretical predictions made by Cramer et al. [2014]. Using the model described above, we calculate the resulting photon energy spectrum at the end of the electric ﬁeld region using diﬀerent scenarios, dependent on the ﬁeld length and strength. The hardness ratio of the spectra were calculated to quantify the variability of the photon energy distribution. In Figures 1–3, the spectra (per 10,000 seed electrons) are shown for the electric ﬁelds with delta = 1, 1.05, and 1.1, respectively. The blue, black, and red colors are to display the 500 m, 1000 m, and 1500 m ﬁeld length cases, respectively. For the = 1 and length of 500 m case, we obtain a good ﬁt from 2 to 50 MeV by a power law with an index 1.6, displayed as a green line in Figure 1. With the increase of the ﬁeld length (potential diﬀerence) the spectrum becomes softer as the RREA population grows and starts to dominate the gamma ray emission, but CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS still can be approximated by a power law function in the conﬁgurations studied in the present paper. However, the pattern changes for the higher ﬁeld strength and lengths. In the case of an electron propagation length of 500 m, the power law index decreases from 1.6 to 1.8 for a ﬁt between 2 and 50 MeV when increasing the ﬁeld from = 1.0 to = 1.05 (Figure 2). For the = 1.1, the gamma ray distribution cannot be well approximated by a power law function and turns to exponential regime as can be seen in Figure 3. For the intermediate potential diﬀerences and ﬁeld strengths the spectra at energies above 1 MeV become a mixture of both power law and exponential distributions. Cramer et al. [2014] found that as the electric ﬁeld approaches the runaway electron threshold value, the solution to the electron energy spectrum is a convolution between a power law function and a Gaussian distribution [see Cramer et al. , 2014, equation (39)]. At the same time, it is worth mentioning that even if the power law ﬁts seem not to be correct at relatively high ﬁelds above = 1.05, as it was shown by Chilingarian et al. [2012, 2014], most of the measured TGEs correspond to lower ﬁeld cases, where power law still applies. Moreover, it was shown that most of the TGEs or glows occur under ﬁelds below the runaway threshold, so called Modiﬁcation of Spectra (MOS) process [ Chilingarian et al. , 2012]. Without avalanche multiplication, secondary cosmic ray electrons get extra energy from the electric ﬁeld and due to the increased path lengths emit more gamma rays than without the presence of the electric ﬁeld in a thundercloud. In Figures 4 and 5, the gamma ray distributions are displayed for the case where the electric ﬁeld is below the runaway threshold, for = 0.5 and = 0.75, respectively. Unlike above the RREA threshold cases, when the ﬁeld length is increased for a certain value of the electric ﬁeld strength, we have fewer gamma rays reaching the boundary of the region where the electric ﬁeld is applied in comparison to the shorter ﬁeld lengths for the same value of the electric ﬁeld. The attenuation dominates the multiplication in this regime. The situation was opposite for above the RREA threshold cases. At the same time, again, there CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS is a trend of softening of spectra with the increase of the electric ﬁeld strength. In particular, for an electron propagation length of 500 m, the power law ﬁt between 2 and 50 MeV gives an index of 1.2 and 1.3 when increasing the ﬁeld from = 0.5 to = 0.75. One can also note that the shape of the spectrum does not change signiﬁcantly with the electron propagation length for ﬁelds . The next step in our analysis was to propagate the resulting bremsstrahlung photons from the source region to the observation point. Compared to space based observations of TGFs, these ground enhancements experience much less signiﬁcant atmospheric attenuation. For instance, high-altitude mountainous laboratories such as Aragats allow measurements to be made tens of meters away from the source, which is practically within the thundercloud. Typical thundercloud altitudes from these observation points range from 100 to 200 m. In Figure 6 we present the cases for which = 0.5 (below the runaway threshold) and 1.1 (slightly above the runaway threshold). The electric ﬁeld length for these cases was 1000 m. For the source distances of 100 and 200 m, a decrease of total number of photons can be seen; however, the spectral shape changes are not as signiﬁcant. Notice that the number of photons below 1 MeV increases between the initial population (RREA) and after the propagation of 100 m through the atmosphere. At this energy range, Compton scattering is the most dominant energy loss process for photons. Due to this scattering process, high-energy photons losing their energy are observed as lower energy particles. However, as the attenuation eﬀect is not as signiﬁcant than for TGFs, often corrections for propagation are not done assuming the measured spectral shape is the CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS It is important to note that for sea level stations, e.g., lightning and thunderstorm active regions such as the Florida or Louisiana coast lines, the corrections for propagation from the source to the observational point are vital as the distances can be as long as several kilometers. These locations are important as they already contain signiﬁcant scientiﬁc infrastructure to study lightning-related phenomena [e.g., Dwyer et al. , 2012a; Ringuette et al. , 2013]. The runaway electron avalanche length is a parameter that represents the average distance an electron travels before the number of runaway electrons is increased by a factor of ( ) [ Dwyer , 2003]. This parameter depends on the electric ﬁeld, as higher strengths will pull more low-energy electrons to the runaway regime, thus decreasing the distance for which more particles are created and/or attenuated. At high electric ﬁeld values, Coleman and Dwyer [2006] showed that the avalanche length can be calculated by the following analytical ﬁt kV kV/m (1) However, at lower ﬁelds just above the runaway threshold value ( ), the following relationship applies kV kV/m (2) We compare the current simulation results for = 1.0, 1.05, and 1.1 to this analytical equation in Figure 7. As we can see from the ﬁgure, there is a large discrepancy between our RREA simulation results and those of Coleman and Dwyer [2006] at = 1.0, near the threshold ﬁeld value. Note that equation (2) is not valid for electric ﬁelds 285 kV/m and = 1.0 corresponds to a ﬁeld of 286 kV/m. The diﬀerent avalanche lengths corresponding to diﬀerent propagation lengths are obtained in the simulation results and can be explained by the fact that in the ﬁeld range close to threshold, the avalanche length is on the order of several kilometers. Hence, even for the longest propagation distance used in the present study, the electron distribution does not reach steady state. At the same time, it is important to note that in this work we use a diﬀerent input energy spectrum from that of Coleman and Dwyer [2006] (exponential with an average energy of 7.3 MeV). Therefore, even typical thundercloud ﬁeld lengths would not be able to produce RREA reaching steady state in this regime. Concurrently, particle ﬂuxes can be observed by ground-based particle detectors even without reaching a steady state, and even below the runaway electron threshold [ Chilingarian et al. , 2012]. For relatively higher ﬁeld values, we get agreement with Coleman and Dwyer [2006], suggesting the steady state regime CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS has been reached. This is not surprising taking into account the avalanche length for = 1.05 and 1.1 is 313 and 186 m, respectively. This means that for the propagation distances we consider here, we are modeling runaway electron propagation through a few avalanche lengths. We have done a Monte Carlo simulation study of electron propagation in air under a homogeneous electric ﬁeld with or without RREA ampliﬁcation that results in particle enhancements named TGEs or gamma ray glows. Despite the widely discussed 7 MeV cutoﬀ and independence of the RREA spectrum on the electric ﬁeld that is usually assumed [see, e.g., Dwyer , 2004; Dwyer and Babich , 2011], there are some experimental evidences that actually the spectrum is not constant. For example, the measured TGE electron spectra have smaller than predicted 7 MeV average energy [ Chilingarian et al. , 2012, 2013]. It should be noted, however, that the 7 MeV cutoﬀ assumption is valid if the RREA reaches a steady state; i.e., the acceleration region is large ( ). Besides experimental results, there are also analytical calculations indicating the RREA spectrum variability with electric ﬁeld [ Cramer et al. , 2014]. Cramer et al. [2014] studied the eﬀect of the electric ﬁeld on the energy spectra of electrons, and the same procedure can be used here to determine the photon spectrum. At electric ﬁelds close to threshold, the bremsstrahlung energy losses are signiﬁcant and the spectrum becomes a convolution of a power law and exponential function [ Cramer et al. , 2014]. It was found that the spectrum was sensitive to the value of , which is the uppermost energy an electron can have for a certain electric ﬁeld value before a balance is reached between the energy gained from the electric ﬁeld and that lost due to ionization and bremsstrahlung. In Cramer et al. [2014], the analysis was done for the runaway electron spectra and the corresponding photon spectrum can be deduced by assuming the bremsstrahlung power law dependence. In this paper, we have additionally studied the spectral dependence on the electric ﬁeld length and the eﬀect of the particle passage from source to the detector. A typical distance from the acceleration region to the observational level is on the order of 200 m for most of the observations made at Mount Aragats [ Chilingarian et al. , 2012]. Torii et al. [2004] made Monte Carlo simulations of the particle ﬂuxes from winter thunderstorms in Japan. In Figure 4 of Torii et al. [2004], it is shown that the total photon ﬂux near the Lower Positive Charge Region (LPCR) is dominant compared to the ﬁeld regions above. This is the case of measurements performed at Mount Aragats, and therefore, as a ﬁrst approximation, only considering the lower charge region is reasonable. As we can see from Figure 6, there are no signiﬁcant diﬀerences in the energy spectra between the acceleration region and the point of observation. Thus, the measured spectrum contains valuable information about the acceleration electric ﬁelds. In Figure 8, we present the dependence of a hardness ratio, deﬁned as the number of photons with energy 10 MeV divided by the number of photons 1 MeV and 10 MeV, on the electric ﬁeld strength. As we mentioned above, the spectrum softens as a result of increased electric ﬁeld length for . For the lower values of the electric ﬁeld strength, the spectrum becomes harder as low-energy photons attenuate in air. We can see from the plot that the hardness ratio is diﬀerent for various electric ﬁeld strengths; however, for diﬀerent potential diﬀerences (ﬁeld lengths), we cannot distinguish the electric ﬁelds by measuring only the hardness ratios. For example, the case for which = 1.05 and m gives near the same hardness ratio as the case of = 1.0 and m. This means to probe the atmospheric electric ﬁelds at the time of the gamma ray event, more parameters need to be measured. The degeneracy on ﬁeld length (total potential diﬀerence) should be solved by the observed intensity (see Figure 9), if the distance to the cloud is known. However, in some cases, we can infer the electric ﬁeld based on the hardness ratio. For example, if a hardness ratio of 0.4 is measured, this should correspond to an electric ﬁeld close to . In Figure 9, the number of photons per 10,000 seed electrons is displayed. As expected, the intensity increases with increasing ﬁeld strength. Also, it is not surprising that there is an enhancement of the number of particles as the ﬁeld length increases for . The eﬀect is opposite and the number of photons decreases for . This indicates that the true threshold is slightly below the used value for the runaway electron threshold ﬁeld ( kV/m), shown in Figure 9 as an intersection of three curves where the number of seed particles equal the number of relativistic electrons at the end of the acceleration region. We possibly can attribute this diﬀerence in the simulation to small variations in the multiple scattering cross section, as care should be taken in comparing multiple Monte Carlo codes as discussed in the RREA Simulation Techniques section of Dwyer et al. [2012b]. CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS We present the dependence of the hardness ratio of the photon distribution with photon ﬂux intensity in Figure 10. The hardness ratio for this plot is calculated the same as in Figure 8. The colors of the plot are to indicate the diﬀerent electric ﬁeld lengths used in the simulation of 500, 1000, and 1500 m, respectively. The diﬀerent symbols are to display the various electric ﬁeld values that were used in the Monte Carlo code. Following the work by Chilingarian et al. [2014], we suggest using hardness ratios along with the measured total ﬂux for the recovery of the atmospheric electric ﬁelds in thunderclouds. It should be noted that care should be taken when considering lower electric ﬁelds ( ) since slight variations of spectra are possible due to the initial electron angular distribution. For higher electric ﬁelds ( ), energetic electrons will tend to be aligned with the electric ﬁeld and the initial cosmic ray angular distribution will not be as essential. As we already mentioned above, the RREA photon spectra are not power law but products of electrons which are distributed by the convolution function of a Gaussian and power law. As we can see from Figure 10, the photon intensity can be a good indicator of the magnitude of the electric ﬁeld in thundercloud as the hardness ratio alone does not vary much at = 1.0 to 1.1. However, for the below threshold electric ﬁelds, the hardness CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS ratio is very sensitive to changes in the ﬁeld value and has a broader distribution. It is worth mentioning that the intensity spans several orders of magnitudes and the hardness ratio varies between 0.03 and 0.6, which is beneﬁcial for remote sensing the atmospheric electric ﬁeld. The combination between ﬁeld length and ﬁeld strength complicates the estimation of the electric ﬁeld in the thundercloud, for instance, the case of = 1.05 and ﬁeld length equal to 1500 m can imitate the case of = 1.1 and ﬁeld length of 1000 m. However, within some errors, it is possible to distinguish between cases. Also, care should be taken as our method should be model independent. Currently, there are many other simulation tools used for high-energy atmospheric physics, e.g., GEANT4 and CORSIKA [ Skeltved et al. , 2014; Köhn and Ebert , 2015]. In Figure 11, we have compared the code from Celestin and Pasko [2011] and the REAM Monte Carlo code used in this work. As shown, there is good agreement between the resulting photon energy spectra, which is another step in validating the spectral results obtained by the REAM code. CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS Based on the above estimations, we conclude that particle measurements can give us valuable information about the conditions inside thunderstorm regions. The electric ﬁeld predictions reported in this work could be tested experimentally if concurrent gamma ray and intracloud measurements were made available. However, for the high-precision quantitative estimates of the electric ﬁelds to be deduced from the measured photon spectra, the contributions of other species of secondary cosmic rays should be considered. In addition to lightning detectors that are designed to measure currents and ﬁelds on the ground, radiation detectors will signiﬁcantly improve our understanding of atmospheric physics in lightning active regions. 
test_jgra.pickle ---------- ['The Instantaneous Retrieval of Precipitation Over Land by Temporal Variation at 19 GHz']
10.1029/2017JD027596 YOU ET AL. The primary signal used in all current passive microwave precipitation retrieval algorithms over land is the depression of the instantaneous brightness temperature (TB) caused by ice scattering. This study presents a new methodology to retrieve instantaneous precipitation rate over land by using TB temporal variation ( ) at 19 GHz, which primarily reﬂects the surface emissivity variation due to the precipitation impact. As a proof-of-concept, we exploit observations from ﬁve polar-orbiting satellites over the Southern Great Plains of the United States. Results show that at 19 GHz correlate well with the instantaneous precipitation rate. Further analysis shows that at 19 GHz is better correlated with the precipitation rate when multiple satellite observations are used due to the much shorter revisit time for a certain location. The retrieved instantaneous precipitation rate over Southern Great Plains from at 19 GHz reasonably agrees with the surface radar observations, with the correlation, the root-mean-square error and the bias being 0.49, 2.39 mm/hr, and 6.54%, respectively. Future work seeks to combine the ice scattering signal at high frequencies and this surface emissivity variation signal at low frequencies to achieve an optimal retrieval performance. Current precipitation estimation technique via satellite passive microwave observations links the hydrometers in the air to the surface precipitation intensity. That is, the cold brightness temperature (TB) at high-frequency channels (e.g., 85 GHz) indicates heavy precipitation. The TB observations from low-frequency channels such as 19 GHz are largely discounted. This study presents a new idea to link the surface condition variation to the precipitation intensity, by using TB temporal variation ( ) at 19 GHz from ﬁve polar-orbiting satellites. Results show that at 19 GHz correlate well with the precipitation rate. The estimated instantaneous precipitation rate over the Southern Great Plains of United States from at 19 GHz reasonably agrees with the ground radar observations, with Instantaneous precipitation rate retrieval by passive microwave radiometers over land is very challenging. Over the ocean where the microwave emissivity is low, the brightness temperature (TB) increase due to the radiometrically warm raindrops is apparent. However, the high surface emissivity over land largely masks the information from liquid water (e.g., Ferraro et al., 1994; Wang et al., 2009; Wilheit, 1986; You et al., 2014). In addition, the land surface emissivity is highly inhomogeneous, which makes it diﬃcult to physically model the land surface emissivity accurately on the global scale Tian et al. (2015). Despite these challenges, precipitation retrieval algorithms have been successfully developed and implemented for several decades over land. For example, some algorithms directly establish a relation between satellite observed TB at high-frequency channels (e.g., 85 GHz) and precipitation rate through various statistical techniques, including regression (Ferraro & Marks, 1995; Laviola & Levizzani, 2011; McCollum & Ferraro, 2003; Wang et al., 2009), neural networks (Islam et al., 2014; Staelin & Chen, 2000), and Bayes’ theorem (Petty & Li, 2013; You et al., 2015, 2016). The reference precipitation rates are usually from surface radar observations (Ferraro & Marks, 1995; You et al., 2015, 2016), ground gauge observations (Kongoli et al., 2015), or spaceborne precipitation radar observations (Islam et al., 2014; Petty & Li, 2013; Wang et al., 2009). Precipitation retrieval algorithms have also been developed by including the radiative transfer model (e.g., Aonashi et al., 2009; Kidd et al., 2016; Kummerow et al., 2015; G. Liu & Curry, 1992; Sano et al., 2013; Seo et al., 2016). Often, the radiative transfer model is employed to simulate the observed TBs. To do the simulation, the hydrometeor proﬁles are either derived from a cloud-resolving model (Kidd et al., 2016; Sano et al., 2013) or satellite-based precipitation radar observations (Kummerow et al., 2015). These precipitation retrieval algorithms diﬀer greatly in detail. However, they share one common feature: linking the scattering signal from the hydrometeors aloft to the precipitation at the surface (Petty, 1995; You et al., 2011; You, Wang, et al., 2017). This study demonstrates later that TB temporal variation ( ) at 19 GHz, primarily the surface emissivity variation signal, is well correlated with the precipitation rate. Therefore, it provides a new technique to retrieve precipitation rate over land from satellite microwave observations. Using observations from eight polar-orbiting satellites, You, Peters-Lidard, et al. (2017) recently showed that at high-frequency channels (e.g., 89 and 183 7 GHz) can signiﬁcantly improve the precipitation retrieval performance over snow-covered areas, by minimizing the surface emissivity variation inﬂuence. In contrast, this study utilizes the surface emissivity variation signal contained in the TB temporal variation at 19 GHz to retrieve precipitation rate. Previous works have used the surface emissivity and soil moisture to estimate the precipitation rate. For example, You et al. (2014) estimated the rainfall rate using the emissivity at 10 GHz in a case study over the Southern Great Plains (SGP) of the United States. Brocca et al. (2014) demonstrated that it is possible to estimate the surface rain rate from soil moisture variation. Koster et al. (2016) applied this method (converting soil moisture to rain rate) globally, using soil moisture products from the Soil Moisture Active Passive mission, the Soil Moisture and Ocean Salinity satellite mission, and the Advanced Scatterometer mission. They concluded that the estimated rain rates are, on average, highly correlated with the in situ gauge-observed rain rates with a square of the correlation coeﬃcient of 0.6, at the 100 km and 5-day resolution. Birman et al. (2015) showed that the daily rainfall estimation from surface emissivity at 89 GHz agrees reasonably well with surface gauge observations in France. Incorporating soil moisture information to correct the satellite rainfall accumulation estimates has been documented to reduce errors (Crow et al., 2009; Pellarin et al., 2013). Key diﬀerences between these works and the current study are the following: (1) Previous studies based on the emissivity and soil moisture are retrieving precipitation accumulation (e.g., daily). However, this study is attempting to retrieve the instantaneous precipitation, which is a much more challenging issue. (2) This study exploits TB temporal variation to retrieve the precipitation rate, which signiﬁcantly alleviates surface contamination (details in following sections). And (3) we use a satellite constellation (ﬁve satellites) in this study to obtain a reasonably high temporal resolution from microwave radiometer observations. It is known that low-frequency channels (e.g., 10, 19, and 37 GHz) have a poorer spatial resolution compared with the high-frequency channels (e.g., 89 GHz). Nevertheless, they are more sensitive to the surface emissivity channels can replace the high-frequency channels. Rather, we show that TB temporal variation at 19 GHz primarily reﬂects the surface emissivity variation due to the precipitation impacts, which may complement the ice scattering signals from high-frequency channels in future precipitation algorithm development. In addition, we choose 19 GHz because it is the lowest frequency commonly available from the ﬁve satellites used in the current study. Therefore, it is most sensitive to the surface characteristics, compared with other commonly available frequencies (e.g., 37 and 89 GHz). We would like to emphasize that this study does not directly use 19 GHz itself to retrieve the instantaneous rain rate. Instead, we use the temporal variation of 19 GHz from ﬁve satellites, which is well correlated with the instantaneous rain rate. Additionally, it is known that the 19-GHz channel does not necessarily perform better than the 89-GHz channel over land, and our later analysis shows this point. However, it does have its merits in providing additional information, for example, when the 89 GHz is not available (e.g., WindSat). The data used in this study are described in section 2. The methodology, including the deﬁnition of the TB temporal variation, is provided in section 3. Section 4 begins with a case study to show the response of TB temporal variation at 19 GHz to the instantaneous rainfall. Then, we present the correlation geospatial distribution between rain rate and TB at 19 and 89 GHz, and between rain rate and TB temporal variation at 19 and 89 GHz. We also discuss several factors that aﬀect the correlation between rain rate and TB temporal variation, YOU ET AL. including the temperature variation, the time diﬀerences between raining and nonraining observations, and the soil texture. Finally, the conclusions are summarized in section 5. The TB used in this study is from ﬁve instruments, including the Special Sensor Microwave Imager/Sounder (SSMIS) onboard the Defense Meteorological Satellite Program F16, F17, and F18 satellites; the Advanced Microwave Scanning Radiometer 2 (AMSR2) onboard the Global Change Observation Mission-Water satellite; and the Global Precipitation Measurement (GPM) Microwave Imager (GMI) onboard the GPM core satellite. As a proof-of-concept, we use three channels from each of these ﬁve sensors (Table 1). They are 19.4 (V/H) and 91.7 (V) from SSMIS, and 18.7 (V/H) and 89.0 (V) from AMSR2 and GMI. V and H represent the vertical and horizontal polarization, respectively. As shown in Table 1, all these channels have diﬀerent footprint resolutions (Draper et al., 2015). The slightly diﬀerent frequency between SSMIS and GMI (AMSR2) also results in diﬀerent TBs for the same surface background and hydrometeor proﬁle (Yang et al., 2014). Section 3 below demonstrates a method to bring all these frequencies to a similar resolution. We adjust the TBs at similar frequencies from SSMIS and AMSR2 to the GMI frequencies, by the simultaneous conical overpass (SCO) technique (Yang et al., 2011) and a linear regression method. Section 3 presents more details regarding this adjustment. For convenience, we do not distinguish the slight frequency diﬀerences among these ﬁve sensors from now on, and these channels are referred to as V19, H19, and V89. The objective of this study is to show that the temporal variation of H19 (primarily the surface emissivity variation signal) is well correlated with the instantaneous precipitation rate. Physically, TB at the horizontal polarization is more sensitive to the land surface characteristics than its counterpart at the vertical polarization, because the horizontal polarized channel is more aﬀected by the polarization of the water particles at/near the surface. Therefore, we choose to show the temporal variation of H19, instead of V19. As a comparison to the surface emissivity variation signal, the temporal variation of V89 (mostly the ice particle scattering signature) is also computed throughout this work. In addition, SSMIS, AMSR2, and GMI have 24, 14, and 13 and highest commonly available frequency from these ﬁve sensors. The precipitation rate data are from the Multi-Radar/Multi-Sensor System (MRMS), which is at 1-km and 2-min spatial and temporal resolution (Zhang et al., 2016). Collocation between the MRMS precipitation rate and TB is discussed in section 3. Data used in this study are all from March 2014 to December 2016 over SGP of the United States (95–105 W, 30–45 N). We choose this period of time since observations from all aforementioned ﬁve satellites are available. SGP is selected because of the large dynamic emissivity variation due to the precipitation eﬀect (Tian et al., 2015; Turk et al., 2016; You et al., 2014). The ancillary data used in this study includes Ku-band precipitation radar (KuPR, 13.6 GHz) onboard GPM core satellite (Seto et al., 2013). The precipitation proﬁle observed by KuPR is utilized in the radiative transfer model experiments to distinguish the surface emissivity eﬀect from the hydrometeor eﬀect. Speciﬁcally, we select all the KuPR rain rate proﬁles over the targeted region from March 2014 to December 2016. Then these proﬁles are averaged according to diﬀerent surface rain rates (e.g., 1 mm/hr; see Figure 9). In the radiative transfer model simulation, the surface temperature, temperature, and relative humidity proﬁles are from Modern-Era Retrospective Analysis for Research and Applications, version 2, which are all at 0.625 latitude-longitude spatial resolution. The temporal resolution for the surface temperature and proﬁles are 1 YOU ET AL. and 3 hr, respectively. We used the National Ice Center’s Interactive Multisensor Snow and Ice Mapping System daily snow cover map at 24 km to screen out the possible snow cover observations. In addition, we also use the gauge-corrected hourly MRMS data for the daily rainfall accumulation computation. TB temporal variation ( ) for any channel is deﬁned as (1) (2) is the current TB associated with precipitation and is the preceding TB at the same location where without precipitation. A grid box is judged as a precipitating grid box when the TB diﬀerence between V19 and V89 is greater than 8 K (Kummerow et al., 2001; Wang et al., 2009). Otherwise, the grid box is considered as a nonprecipitating grid box. By using the 8 K as the threshold value, the probability of detection is 69.24% with the false alarm rate at 6.92% in the targeted region, according to MRMS observations. is the time diﬀerence between these two observations. By using these ﬁve satellites, varies from several minutes to as long as 24 hr. We discuss later the varying ’s eﬀect on the correlation between and precipitation rate in section 4.4. This study computes the temporal variation of H19 (hereinafter referred to as ) and of V89 (hereinafter referred to as ). We demonstrate later in the section 4.5 from radiative transfer model simulation experiments that the is largely the surface emissivity variation signal due to the precipitation impact, while is primarily the ice scattering signal. Table 1 shows the mean footprint resolution of SSMIS, AMSR2, and GMI at 19 and 89 GHz (Draper et al., 2015). The 19 GHz of SSMIS has the largest footprint size at 59 km. This study aggregates the ﬁner footprint resolution by simply averaging to roughly match this resolution. Speciﬁcally, we average 7 (59 59/22/22 7) pixels of 19 GHz from AMSR2, 16 pixels of 19 GHz from GMI, 18 pixels of 91.7 GHz from SSMIS, 140 pixels of 89 GHz from AMSR2, and 71 pixels of 89 GHz of GMI to approximately match the resolution of 19 GHz of SSMIS (59 km). For the precipitation rate, we simply average the closest 3,481 ( ) 1-km MRMS precipitation rate pixels for each TB observation at the closest time. After the footprint sizes of these ﬁve sensors being brought to a similar resolution, the TBs from SSMIS and AMSR2 for each channel are adjusted to the GMI channels. The GMI channels are taken as the reference channel because AMSR2 and SSMIS are calibrated against GMI (Berg et al., 2016). The linear relationship between the GMI TB at each channel and the TB from AMSR2 or SSMIS at the similar frequency is assumed, and it takes the following form: (3) where is from 1 to 4, which stands for sensors of SSMIS onboard F16, F17, and F18, and AMSR2. And is from 1 to 3, which represents channels of H19, V19, and V89 GHz. and The SCO technique by Yang et al. (2011) is used to obtain the coeﬃcients . The idea of SCO technique is that simultaneous measurements at a certain location from two diﬀerent sensors at similar frequencies should be highly correlated. This study takes the GMI observations as the reference. Two measurements, one from GMI and the other one from any of other four sensors, are called a SCO pair, if the ﬁeld-of-view location is less than 1 km and the ﬁeld-of-view time is less than 2 min. These threshold values are chosen by considering the trade-oﬀ between the sample size and the SCO pair accuracy. To obtain enough SCO pairs, we choose the land portion of the region from 70–130 W, 30–50 N. The scatter plots between these SCO pairs for each channel are shown in Figure 1. It is evident that the majority of the SCO pairs are close to the 1-1 line. The coeﬃcients trained by these SCO pairs are listed in Table 2. Most adjusted TBs ( 97.0%) deviate less than 2 K from the original TBs. YOU ET AL. The purpose of this study is to show that is well correlated with the precipitation rate. Therefore, for a certain location, the number of observations should be high enough to obtain a meaningful temporal variation. To this end, the data are gridded into 0.5 latitude-longitude box. Any pixel in the same grid box is taken as the observation for the same location. We choose the 0.5 resolution because the mean footprint size (59 km) is close to the 0.5 resolution. Approaches used in this study are very similar to You, Peters-Lidard, et al. (2017). A major diﬀerence between this study and You, Peters-Lidard, et al. (2017) is whether to consider the environmental variation from modify deﬁnition in section 4 to consider the environmental variation (e.g., temperature) from to , since we are able to more accurately compute the land surface emissivity at low-frequency channels under the nonprecipitating scenarios, compared to at high-frequency channels. In addition, this study grids satellite observations into a 0.5 latitude-longitude box due to the larger footprint size at 19 GHz, compared to the 0.25 latitude-longitude box in You, Peters-Lidard, et al. (2017). YOU ET AL. Figure 2 shows the time series of H19 (Figure 2a) and V89 (Figure 2b), and the corresponding precipitation rate (Figure 2e) over the 0.5 grid box of (100.5–101 W, 41.5–42 N). There are 5,483 observations at this location tions identiﬁed by greater than 8 K. The red circles in Figure 2a (observations with precipitation) do not separate themselves from the blue curve. It basically means that the precipitation signal from H19 itself is very weak. In contrast, the TB depression at V89 (Figure 2b) is evident. That is, the observations with red circles correspond well with the precipitation occurrence (the blue bar in the Figure 2e). The poor correlation between H19 and precipitation rate is immediately evident in the scatter plot (Figure 3a), where the correlation coeﬃcient is only 0.12. The poor correlation ( 0.12) is the reason why previous work primarily used the scattering signal at high-frequency channels (e.g., 89 GHz) for the precipitation retrieval over land. In contrast, V89 correlates strongly with precipitation rate with a correlation coeﬃcient of 0.66 (Figure 3c). Figures 2c and 2d show the time series of and (deﬁned in equation (1). The and are set as 0 for the observations judged as nonprecipitating observations ( 8 K). It is very clear that both (Figure 2c) and (Figure 2d) correspond very well with the precipitation occurrence (Figure 2e). There are 180 precipitation observations out of 5,483 total observations from March 2014 to December 2015 over this grid box. The vast majority of the associated with precipitation (159 out of 180 records) are less than 0, and the TB depression at can be as large as 40 K. There indeed exists a small portion of the observations (21 out of 180 records) with greater than 0. For the , all values are negative. We YOU ET AL. explain the positive and negative TB values of and by a radiative transfer model simulation in section 4.5. The much better correlation between and precipitation rate ( 0.69), compared with that between H19 itself and precipitation rate ( 0.12), is obvious in Figure 3 (cf. Figures 3b and 3a). It is worth noting that the correlation between and precipitation rate ( 0.69; Figure 3b) is slightly worse than that between and precipitation rate ( 0.76; Figure 3d). In the following sections, we show that the highly variable time difference ( ) is largely responsible for the worse performance of . Another possible reason is that the signal magnitude of is weaker than that of . The correlation between and precipitation rate ( 0.76) is also better than that between V89 and precipitation rate ( 0.66; Figure 3c) due to the mitigation of cold surface contamination. We use the daily Ice Mapping System snow cover map to ﬁlter out possible snow-covered observations. However, there may still exist some observations associated with snow cover on the ground due to the mismatch between the daily snow cover map and the instantaneous satellite observations. Speciﬁcally, the red circles associated with cold V89 at 240 K in Figure 3c represent the falsely identiﬁed precipitating observations. The inﬂuence of the falsely identiﬁed precipitation observations due to the cold surface is largely reduced when using , because the of these falsely identiﬁed observations are close to 0 (Figure 3d). More discussions regarding the mitigation of the surface contamination at 89 GHz are contained in You, Peters-Lidard, et al. (2017). In summary, it is demonstrated that is well correlated with the precipitation rate, while H19 itself has very weak correlation with the precipitation rate. The correlation between and precipitation rate (Figure 4a), between H19 and precipitation rate (Figure 4b), between and precipitation rate (Figure 4d), and between V89 and precipitation rate (Figure 4e), are computed over SGP. The precipitation occurrence number, judged by the scattering index method ( ), varies from 40 to 404 in diﬀerent grid boxes. As discussed above, it is clear that is much better correlated with the precipitation rate than H19 itself (cf. Figures 4a and 4b). The majority of the correlation coeﬃcients (64.8%) between and precipitation YOU ET AL. rate are negative (less than 0.4). As shown in the case study, most decreases due to the impact of precipitation. Mathematically, this explains why and precipitation rate is negatively correlated. Physically, precipitation usually increases the soil moisture and therefore leads to a depression in emissivity which results in a TB depression. On the other hand, out of the 600 correlation coeﬃcients, there are 14 positive ones. These positive correlation coeﬃcients caused by (1) the combined eﬀect of surface emissivity variation and hydrometeors emission/scatter in the air, which we explain in detail in section 4.5; and (2) cold surfaces misidentiﬁed as precipitation. The false positive correlation between H19 itself and precipitation rate is especially obvious in the top left corner of Figure 4b. These false positive correlations are generally caused by cold Over SGP, the vast majority of the correlation coeﬃcients between and precipitation rate (Figure 4d) are less than 0.7. Obviously, the scattering signature is better correlated with the precipitation than the surface emissivity variation signal. In the following sections, we demonstrate that the correlation between and precipitation rate is highly dependent on the variation, while the correlation between and precipitation rate is relatively independent from the variation. Even though ﬁve satellite observations are exploited in this study, the is still highly variable, which can change from several minutes to more than 12 hr. The highly variable has a larger negative impact on the correlation between and precipitation rate than that between and precipitation rate, because is more sensitive to the surface characteristics than . Another interesting phenomenon is that is better correlated with the precipitation rate than V89 itself, which is particularly evident over west of 103 W. As mentioned previously, in these regions, the can more eﬀectively mitigate the surface contamination, especially under the light precipitation scenario (You, Peters-Lidard, et al., 2017). In section 3, we deﬁne the as . In this deﬁnition, we do not consider the temperature (surface temperature and temperature proﬁle) variation from to . In other words, it explicitly assumes that the YOU ET AL. temperature information at time is the same as that at time . This assumption may lead to an error in the estimate when the temperature varies from to , especially when is large (e.g., 12 hr) between these two observations. To consider the temperature variation, may be calculated in the following way: (4) is still the observed TB under the precipitating conditions. is the simulated TB at by using where the emissivity calculated at (under the nonprecipitating condition). Speciﬁcally, the emissivity at 19 and 89 GHz is calculated at under the nonprecipitating condition by using the temperature information at . Then the emissivity values at 19 and 89 GHz are used to calculate by using the temperature information at . By doing so, the surface temperature variation from to is taken into consideration. From now on, computed in equation (4) for H19 and V89 is referred as to and , respectively. A radiative transfer model (G. Liu, 1998) computes the emissivity under the nonprecipitating conditions. This model calculates the TBs at diﬀerent microwave frequencies through the discrete ordinate method at varying stream numbers. In the current simulation, the stream number is set as 4. The water vapor absorptions from both line and continuum contributions are considered in this model. The temperature information used in the radiative transfer model calculation is from Modern-Era Retrospective Analysis for Research and Applications, version 2. By considering the temperature variation eﬀect, it is noted that the correlation between and precipitation rate is improved (cf. Figures 4a and 4c). For example, the overall mean correlation coeﬃcient in the targeted region from is 0.40, while it increases to 0.47 using . Improvement has also been made for the V89 channel, but to a lesser degree (cf. Figures 4d and 4f ). The objective of this study is to show the temporal variation of TB at 19 GHz ( ) is well correlated with the precipitation rate. Ideally, observations from a satellite constellation with the same conﬁguration or a geostationary microwave radiometer would be most suitable. However, such observations currently are not available or even planned. Therefore, we exploit observations from ﬁve low Earth orbit satellites in the GPM constellation. By doing this, the deﬁned in equation (2) is highly variable. This section demonstrates the eﬀect of variable on the correlation between and precipitation rate, and between and precipitation rate. Figure 5 shows the histogram of the time diﬀerences (i.e., ). By using ﬁve satellite observations, about 99.3% of the s are less than 12 hr. In contrast, about 78.8% of the s are greater than 12 hr when only GMI observations are used. To show the variable eﬀect, we calculate the correlation between and precipitation rate, and between and precipitation rate, corresponding to diﬀerent s (Figure 6). The correlation coefﬁcients between and precipitation rate decrease quickly from 0.5 with at 2 hr to 0.21 with at 24 hr. This result implies that with increasing time diﬀerences between and , it is more likely that the surface conditions (e.g., soil moisture variation and precipitation in between these two observations) have changed. Therefore, more likely contains other information besides the current precipitation eﬀect. YOU ET AL. In contrast, the correlation between and precipitation rate remains at about 0.7 (blue curve in Figure 6), regardless of the variation. The relative independence of indicates that V89 is less aﬀected by the surface characteristics variation in this region, compared with H19. Therefore, using single satellite observations to compute may be suﬃcient in this region. Figure 6 shows that correlations between and the precipitation rates decrease as increases. To further understand this phenomenon, we compute the number of precipitation events (Figure 7a), and the percentage of the current precipitation being the only precipitation (Figure 7b), corresponding to diﬀerent intervals, from 0–1, 1–2, , 11–12 hr. As expected, Figure 7a shows that there are more precipitation events with a larger . For example, on average, there are only 1.01 precipitation events when is 1 hr. In contrast, there are 2.78 precipitation events when is 12 hr. When the precipitation-free scene at t is less than 1 hr apart from the current precipitating scene at t , 99.12% of the time the current precipitation is the only precipitation event in the time period of (Figure 7b). When increases to 12 hr, the percentage decreases to 43.75%, meaning that 56.25% of the time there are other precipitation events in the time period of 12 hr. When there are other precipitation events occurring in the time period of , not only reﬂects impact of the current precipitation event, it may also include the impact from other precipitating events in between . Therefore, the correlation between and the current precipitation rate becomes weaker as increases. Since may reﬂect the precipitation accumulation in the time period of , it is possible to estimate the precipitation accumulation from . In fact, previous studies estimated the precipitation accumulation (e.g., daily accumulation) from emissivity at low frequencies channels (You et al., 2014) or from soil moisture (Brocca et al., 2014). However, further analysis shows that the correlation between and the precipitation accumulation in the time period of is not necessarily stronger than that between and the instantaneous precipitation, because the correlation between and the precipitation accumulation is dependent on the time interval in which the precipitation accumulation is computed. More research is necessary to pinpoint the optimal precipitation accumulation time interval. Under precipitating conditions, it is impossible to know the exact value of the emissivity because TB reﬂects the combined eﬀect from both the surface background emission and scattering/emission from the hydrometeors aloft. To show the possible emissivity variability over the targeted region, we adopt the method in channels, corresponding to diﬀerent previous 1-day precipitation accumulation amounts. We can reasonably assume that the emissivity variation under the precipitating conditions resembles the emissivity variation under the precipitation-free scenes, but with diﬀerent 1-day precipitation accumulation amounts. YOU ET AL. Figure 8a shows that the emissivity for H19 can drop as much as 0.05 from 0.95 to 0.90, or even 0.1 in some areas, corresponding to 10-mm 1-day accumulation precipitation (cf. Figures 8a and 8d). Correspondingly, H19 TB can drop as much as 20 K (cf. Figures 8e and 8h). In contrast, the emissivity at V89 and V89 itself have a much smaller variation magnitude, corresponding to the same amount previous 1-day precipitation accumulation (cf. Figures 8i and 8l, and Figures 8m and 8p). This study shows the concept of using surface emissivity temporal variation signal at the 19 GHz due to the precipitation impact. As mentioned previously, it is very diﬃcult to separate the surface emissivity contribution from the hydrometeor contribution to the satellite-observed TB, under the precipitating conditions. To disentangle the surface emissivity from hydrometeor eﬀects and better understand the eﬀect from each of them, we conduct following radiative transfer simulation experiments: (1) Simulate TB at H19 and V89 with the surface precipitation rate increasing from 0 to 20 mm/hr, corresponding to the surface emissivity at 0.8, 0.9, 0.95, and 1.0. By doing this, we can determine the hydrometeor eﬀect. (2) Simulate TB at H19 and V89 with the surface emissivity decreasing from 1.0 to 0.8, corresponding to 0, 0.5, and 5 mm/hr precipitation rate. By doing this, we can determine the surface emissivity eﬀect. The radiative transfer model, developed by G. Liu (1998), is used for the YOU ET AL. aforementioned experiments. Additionally, for simplicity the particles above (below) the freezing level height are considered as ice (liquid) particles, and no mixed phase particles are considered in the simulation. It is found that H19 decreases about 25 K from 292 to 267 K (Figure 9a, magenta curve), and about 12 K from 278 to 266 K (Figure 9a, blue curve), with the precipitation rate increasing from 0 to 20 mm/hr, corresponding to the emissivity at 1.0 and 0.95, respectively. On the contrary, H19 increases from 237 to 266 K (Figure 9a, red curve) when the precipitation rate increases from 0 to 20 mm/hr, with emissivity at 0.8. This partially explains why is positively correlated with the precipitation rate. The green curve in Figure 9a shows that H19 increases slightly when the precipitation rate increases from 0 to 8 mm/hr, then decreases slightly when the precipitation rate increases from 8 to 20 mm/hr. It is clear that TB at H19 can either increase or decrease due depression at H19 caused by hydrometeors is probably less than 12 K, since the mean emissivity at H19 under dry condition is less than 0.95 in the targeted region (Figure 8a). Figure 9b demonstrates that H19 can decrease as much as 55 K from about 292 K to about 237 K under the nonprecipitating condition (Figure 9b, red curve) when emissivity decreases from 1.0 to 0.8. Similar magnitudes of the TB depression are observed under the light precipitation scenario (Figure 9b, green curve). Under heavier precipitation (Figure 9b, blue curve), H19 can decrease about 20 K. Compared with the mixed hydrometeor eﬀect on H19, the surface emissivity depression caused by precipitation can only lead to a TB depression at H19, and the magnitude of the depression can be as large as 55 K. Our results show that the vast majority of s are negative, and its magnitude can be as large as 40 K. From the radiative transfer model simulation experiments, we conclude that the surface emissivity depression plays a larger role in the vast majority of negative s. That is, the signal from is largely from the surface emissivity depression, and the hydrometeor scattering/emission signal contributes less to . Compared with the surface emissivity variation signal, it is very clear that the hydrometeor scattering signal is responsible for the TB variation at V89. Figure 9c shows that TB at V89 does not vary when the precipitation rate is larger than 2 mm/hr, regardless of the surface emissivity values. Similar results can be found in Figure 9d. YOU ET AL. For example, V89 only decreases about 10 K when emissivity decreases from 1.0 to 0.8, with the precipitation rate at 0.5 mm/hr. To summarize, the radiative transfer model simulation shows that the largely reﬂects the surface emissivity variation. In contrast, the hydrometeor scattering signal is responsible for the TB depression of . This channel is surface blind with the precipitation rates greater than 2 mm/hr. The previous section shows that the signal from is essentially the surface emissivity variation due to the precipitation impacts. A key factor aﬀecting the surface emissivity variation is the soil texture (e.g., content and structure) . Therefore, this section explores the possible inﬂuence of the soil texture on the correlation between and precipitation rate. As a comparison, the soil texture inﬂuence on the correlation between and precipitation rate is also investigated. Of the 16 soil texture types present in the hybrid State Soil Geographic/Food and Agriculture Organization soil texture data set provided by the National Center for Atmospheric Research for the Noah land surface model (Miller & White, 1998; Reynolds et al., 2000), 10 types are represented in the targeted region. They are sand (63), loamy sand (5), sandy loam (103), silt loam (142), loam (129), silty clay loam (48), clay loam (58), silty clay (8), clay (41), and other (3). The number in the parenthesis following the soil texture types is the 0.5 grid box number for each class. For example, the soil type is sand in 63 grid boxes, out of 600 grid boxes in the whole targeted region. The following calculation omits the classes of loamy sand, silty clay and other, due to the limited sample size. The correlation between and precipitation rate (Figure 4c) is averaged for each soil texture type. Similar computation is performed for the correlation between and precipitation rate (Figure 4f ). Results are listed in Table 3. The correlations between and precipitation rate have a general decreasing trend from the sand soil to the clay soil. We hypothesize that the better correlation from the sand soil is due to the quicker response of the sand to the instantaneous precipitation impact, compared with the clay soil. Another possible reason is that precipitation events in-between (other than the current precipitation event) may have a smaller impact on the sandy soils, because water drains away faster through the sandy soils, compared with clay soils. As shown in Figure 7a, when the is larger than 1 hr, precipitation events other than the current precipitation event likely occur. More work is necessary to fully understand the underlying physical reason for this behavior. In contrast, the soil texture type has almost no inﬂuence on the correlation between and precipitation rate, as indicated by the almost constant correlation coeﬃcients ( ) between them. It is worth mentioning that using the correlation coeﬃcients between and precipitation rate (Figure 4a), and between and precipitation rate (Figure 4d) generates very similar results (see last two columns of Table 3). The ability of to retrieve precipitation is investigated by using the independent data in 2016. As a proof-of-concept, a simple linear regression line is ﬁtted between the and precipitation rate using the training data set from 2014 to 2015 in each 0.5 grid box. As comparisons, similar procedures are applied to YOU ET AL. H19, V89 and to retrieve the precipitation rate. Then the ﬁtted regression line in each grid box is used to retrieve the precipitation rate in 2016, where the MRMS precipitation rate is taken as the reference. Figure 10 shows the overall retrieval results over SGP. The retrieved precipitation rate from has a correlation of 0.49 with MRMS. Root-mean-square error is about 2.39 mm/hr, and the bias is 6.54% (Figure 10b). The retrieval result from H19 itself (Figure 10a) performs noticeably worse, as indicated by a much smaller correlation of 0.28. It is noted that the bias from H19 ( %) is smaller than that from (6.54%), because the the precipitation rate are canceled out each other in the retrieval result of (Figure 10a). The retrieval results from (Figure 10c) and (Figure 10d) are obviously better, compared with . The highly variable likely aﬀects the ’s performance, because is much more sensitive to the surface characteristics variation than . Previous analysis shows that the magnitude of the correlation between and precipitation rate decreases quickly along with the increase. This again suggests that a denser low earth orbit microwave constellation or a geostationary microwave radiometer could help to improve the performance of for the precipitation retrieval. In addition, we show that the correlation between and precipitation rate is dependent on the soil texture type, which has little inﬂuence on the correlation between and precipitation rate. This study extends our previous work (You, Peters-Lidard, et al., 2017) on temporal changes in high-frequency TBs to demonstrate the potential value of low-frequency channels to improve precipitation rate retrievals over land. For this study, we use 3-year (2014–2016) observations over SGP from surface radar measured precipitation rate and ﬁve satellites observed TBs, including SSMIS onboard F16, F17, and F18; AMSR2; and GMI. YOU ET AL. Over the whole study region, and precipitation rate is well correlated with the majority of the correlation coeﬃcients less than 0.4. The correlation can be further improved by considering the temperature temporal variation through the radiative transfer model simulation. It is also noted that the correlation from V89 or is stronger than that from . The relatively worse performance of the is due to this signal being more sensitive to the surface characteristics than . Even with observations from ﬁve sensors, varies from several minutes to more than 12 hr. It is shown that the correlation between and precipitation rate substantially weakens as increases. We suggest that the observations from a denser low Earth orbit microwave constellation or a hypothetical geostationary microwave radiometer can improve the correlation between and precipitation rate due to its high temporal resolution. We further analyze the signal source of the . Results show that the surface emissivity depression caused by the precipitation is largely responsible for the variation, while the hydrometeor scattering/emission eﬀect contributes much less to the behavior. In contrast, the TB at 89 GHz is surface blind under the moderate and heavy precipitation scenarios (e.g., 2 mm/hr in Figure 9c), and it is the hydrometeor scattering eﬀect that results in the TB depression at 89 GHz, which is well documented in the literature (Ferraro & Marks, 1995; McCollum & Ferraro, 2003; Wang et al., 2009; You et al., 2015, 2016). Further analysis shows that the correlation between and precipitation rate varies over diﬀerent soil texture types, with the largest correlation for the sand soil type. In contrast, soil texture has almost no inﬂuence on the correlation between and precipitation rate. As a proof-of-concept, a linear regression precipitation retrieval is performed over SGP by using the independent data in 2016. On average, the retrieved precipitation rate from has a correlation of 0.49, a root-mean-square error of 2.39 mm/hr and a bias of 6.54% , compared with the surface radar observations. These statistics are much better than those from H19 itself. However, it is noted that performance from is better than that from , partially due to the larger negative inﬂuence to from the highly variable time diﬀerence ( ) between two observations. As a proof-of-concept, this study only uses ﬁve satellites to derive the TB temporal variation. In fact, several other currently operational radiometers carry the low-frequency channels at 19 GHz, including Advanced Microwave Sounding Unit-A, Advanced Technology Microwave Sounder, WindSat, and FengYun-3 Microwave Radiometer Imager. By using all observations from these radiometers (10+), it could signiﬁcantly increase the temporal resolution, and therefore, the performance of is expected to improve greatly. By doing so, the previous overpasses of all used sensors (ﬁve in the current study) need to be processed and stored, which can take longer time compared with the retrieval algorithm for a single sensor. Finally, it is not our purpose to claim that the surface emissivity signal from is stronger than the scattering signal from either or V89 itself. In fact, results in Figure 10 show that the scattering signal over the targeted region is stronger than the surface emissivity variation signal from . The primary objective of this study is to show that largely reﬂects the surface emissivity variation due to the precipitation impact. Therefore, it provides an independent signal source for precipitation retrieval, which may complement the scattering signal from high-frequency channels under certain situations. For example, in the warm rain systems there are few or no ice particles. Therefore, the scattering signal at high-frequency channels is rather weak, which leads to a poor precipitation retrieval result for algorithms solely dependent on the ice scattering signature (C. Liu & Zipser, 2009; Sohn et al., 2013; You & Liu, 2012). In addition, Hamada et al. (2015) showed that a large scattering signal does not necessarily indicate heavy precipitation. Our study shows that it is possible to use the signal from the surface emissivity variation, as reﬂected in TB temporal variation derived from low-frequency channels, to measure the instantaneous precipitation rate, which currently is not considered in the instantaneous precipitation retrieval. Future work seeks to combine these two signal sources (scattering from the hydrometeors aloft and surface emission variation due to the precipitation) to achieve an optimal precipitation retrieval performance. STOP CONTENT EXTRACTION HERE IN THE NAME OF GOD
test_jgra.pickle ---------- ['A global electric circuit model within a community climate model']
10.1002/2015JD023562 To determine the complex dependencies of currents and electric ﬁelds within the Global Electric Circuit (GEC) on the underlying physics of the atmosphere, a new modeling framework of the GEC has been developed for use within global circulation models. Speciﬁcally, the Community Earth System Modeling framework has been utilized. A formulation of atmospheric conductivity based on ion production and loss mechanisms (including galactic cosmic rays, radon, clouds, and aerosols), conduction current sources, and ionospheric potential changes due to the inﬂuence of external current systems are included. This paper presents a full description of the calculation of the electric ﬁelds and currents within the model, which now includes several advancements to GEC modeling as it incorporates many processes calculated individually in previous articles into a consistent modeling framework. This framework uniquely incorporates eﬀects from the troposphere up to the ionosphere within a single GEC model. The incorporation of a magnetospheric potential, which is generated by a separate magnetospheric current system, acts to modulate or enhance the surface level electric ﬁelds at high-latitude locations. This produces a distinct phasing signature with the GEC potential that is shown to depend on the observation location around the globe. Lastly, the model output for Vostok and Concordia, two high-latitude locations, is shown to agree with the observational data obtained at these sites over the same time period. The global electric circuit (GEC) represents the electrical pathway by which charge is exchanged between the conductive surface of the Earth and the highly conductive ionosphere, which are held at diﬀerent potentials by electriﬁed clouds. Inherently atmospheric, this circuit is dependent on many of the physical and chemical processes that can aﬀect charge and its transport in the atmosphere, both spatially and temporally. Indications of this global circuit were ﬁrst measured by the Carnegie expedition documenting temporal variations of surface fair-weather vertical electric ﬁelds [ Harrison , 2013]. These measurements were correlated with global thunder count variations in universal time (UT) suggesting that a global circuit exists with thunderstorms acting as generators. These generators drive currents capable of inﬂuencing the electric ﬁeld behavior around the globe [ Whipple , 1938]. These currents, generated more broadly by electriﬁed clouds, produce a potential diﬀerence (PD) between the ground and ionosphere of around 250 kV. The potential diﬀerence leads to an average fair-weather return current density of a few pA/m . Many reviews have been written on the GEC discussing the generation of these parameters, such as Rycroft et al. [2008], Liu et al. [2010a], and Williams and Mareev [2014]. The ﬁrst numeric model to address the complexities of the GEC was developed by Hays and Roble [1979]. They made several assumptions on the conductivity and source distributions to represent the problem with analytic spherical harmonic functions in several distinct domains, but nonetheless were able to determine how currents were distributed throughout the atmosphere. In a separate paper, Roble and Hays [1979] included large-scale horizontal potentials maintained by the ionospheric dynamo and magnetospheric convection and broadly discussed their inﬂuence on the GEC. Since this ﬁrst model, numerous other eﬀorts have been undertaken, mostly focusing on advancing conductivity formulations or source formulations independently and then solving for the resulting electrical perturbations. Several of these models have advanced conductivity perturbations to the system, such as Tinsley and Zhou [2006] and Odzimek et al. [2010]. These models then solve for the electrical properties of the circuit by solving for vertical resistances and equivalent circuit elements. LUCAS ET AL. CESM1(WACCM) GEC MODEL Today, highly sophisticated global climate models are able to account for physical and chemical processes taking place in Earth’s atmosphere. However, these models have not considered the global electrical processes that are occurring within the system. Recently, Mareev and Volodin [2014] have implemented GEC solutions to a global circulation model. Although of similar intent, our work expands on the GEC formulation by including dynamic changes to conductivity due to clouds and aerosols, evolving source currents through internal convective processes, and external inﬂuences imposed by electric potentials from the magnetosphere. This involves implementing source and conductivity formulations within the same model and allowing them to evolve together in time. The model utilized for this work is the freely available Community Earth System Model, CESM1(WACCM), which can be obtained from their website: www.cesm.ucar.edu. The CESM1(WACCM) formulation is a comprehensive numerical model spanning the range of altitude from Earth’s surface to the thermosphere. The community-wide model uniﬁes certain aspects of the upper atmosphere, middle atmosphere, and troposphere modeling into a common numerical framework. This makes it an excellent platform for a GEC simulation as much of the detailed atmospheric physics can be incorporated. The global atmospheric model solves the primitive equations and radiative transfer equations, similar to a weather forecast model and calculates parameterizations for subgrid processes such as convection. From this, temperature, pressure, and water vapor content are obtained for every grid box and every time step. A description of the model integration and scientiﬁc capabilities within CESM1 can be found in Hurrell et al. [2013]. Additional details and references, including the major equations and processes, can be obtained within the user’s guide on the CESM website http://www.cesm.ucar.edu/models/cesm1.0/cam. For this work, we are using the stand-alone atmospheric component conﬁguration with the Community Atmosphere Model (CAM5) extended to the Whole Atmosphere Community Climate Model (WACCM). A detailed description of some of the upper atmospheric physics underlying the program can be found in Marsh et al. [2013, and references therein]. The model is free running with a time step of 30 min, a resolution of 2.5 in longitude by 1.9 in latitude, with 70 vertical levels distributed in modiﬁed pressure coordinates, which correspond to roughly 140 km as the top height of the model. This paper presents a new method for determining the electrical parameters of the global electric circuit within an evolving physics-based framework of a community climate model. Herein this new GEC model will be referred to as WACCM-GEC. An overview of the equations utilized in the model development will be covered in section 2. The required variables and the calculation of conductivity and sources within the model will be discussed in section 3. Finally, section 4 will demonstrate the variability of output electric ﬁelds from WACCM-GEC due to externally generated magnetospheric potentials. The model electric ﬁelds are shown to reproduce observed diurnal variations in the electric ﬁelds at Vostok and Concordia, two Antarctic sites. WACCM-GEC is an extension of CESM1(WACCM) that calculates fair-weather electric ﬁelds and currents within the atmosphere. The atmospheric variables that contribute to the electrical properties of the atmosphere are calculated based on the underlying physics variables computed within CESM1(WACCM) and are used for conductivity and source calculations, as discussed in sections 3.1 and 3.2. The essential process to be evaluated within the WACCM-GEC is to satisfy the current continuity equation. The two driving parameters in solving the current continuity equation, (1) for the potential are the conductivity, , and the source distribution, . The conductivity of air generally increases exponentially with altitude, following the decreasing density of the atmosphere. There are also perturbations to this exponential proﬁle caused by ion creation and loss processes, which includes clouds and aerosols. These perturbations to conductivity are covered in more detail within Baumgaertner et al. [2013], Zhou and Tinsley [2010], Tinsley and Zhou [2006], and in section 3.1. The source distribution within previous global models has relied upon thunder and convective area distributions [ Markson , 2007; Mareev and Volodin , 2014]. For a simpliﬁed representation of storms, an electriﬁed cloud will generally have a positive charge center located above a negative charge center. These two charge centers are then represented within the mathematical models as dipole current sources, as mentioned by Tzur and Roble [1985]. In WACCM-GEC the source currents are parameterized using the convective mass ﬂux generated within the model, as described in section 3.2. LUCAS ET AL. CESM1(WACCM) GEC MODEL To study the GEC, measurements are done in fair-weather regions where there are no sources around the measurement location. This can be accomplished by solving for the source currents and fair-weather currents separately and adding the solutions together due to the linearity of the partial diﬀerential equation. The two separate systems being solved are Fair-weather: Source region: (2) (3) with and satisfying representing the fair weather and source potentials, respectively, and the total potential . In this problem we apply Dirichlet (ﬁxed potential) boundary conditions on the upper and lower boundaries. Earth’s surface will be deﬁned as being a zero potential surface with zero net current ﬂow through the surface. The upper boundary potential is determined by the source and conductivity distribution in the domain while enforcing that no net current ﬂows through the boundary. A diﬀerent approach to determining the upper boundary potential is addressed in Kalinin et al. [2014], where they discuss the contribution to potential for individual storms, including source modiﬁcations due to the conductivity within the cloud. The conductivity variability within the source clouds inﬂuencing the source strengths is not implemented in this version of WACCM-GEC. The top potential brings closure to the system, so that there are no leakage currents from the GEC, which follows from ensuring current continuity as seen in equation (1). Other studies determine the contribution to the upper boundary potential directly from each storm [ Mareev and Volodin , 2014]. The use of this method implies that the atmosphere follows a known exponential conductivity proﬁle everywhere across the globe. This indicates that an increase in resistance far away from the storm would not inﬂuence the potential of the ionosphere. In this work, we relax the assumption that the conductivity of the atmosphere follows an exponential and calculate the current that storms contribute to the system and determine the potential based on the total current and resistance of the system. The potential of the ionosphere is solved in a two-step approach. First, the source region is solved with 0 V potentials on the top and bottom of the domain. Integrating over the top and bottom boundaries determines how much current is available in the domain. This allows one to know exactly how much current is required to close the system and conserve currents within the model, which is the downward current that is passing through the fair-weather regions. The second step is to calculate the total resistance of the atmosphere. Once the total resistance and total current are known, one can apply Ohm’s law to determine the potential needed at the top boundary of the fair-weather region. Another means to calculate the current is to separate the source term, , into individual source columns applying the linearity argument again, such that and which allows WACCM-GEC to calculate the total current in a grid cell, , due to the sources within that grid cell. Each electriﬁed cloud in general only covers several kilometers in the horizontal, while the horizontal resolution for WACCM is approximately 100–200 km. This means it is diﬃcult to resolve individual storms in climate models, unless they are large convective systems. Therefore, a parameterization for determining the source strength within each column is described in section 3.2. Figure 1 shows a map of the mean current produced in each column over the 3 month model simulation. Now the total current ﬂowing in the domain can be calculated by summing up all of the column contributions (4) After solving for the total source contribution current, one can focus on the fair-weather domain, equation (2), and determine the potential of the ionosphere. With the high conductivities at the boundary of the fair-weather GEC, the boundaries can be thought of as constant potential surfaces, where any excess charge is redistributed quickly compared to the time scales of interest. As a standard deﬁnition throughout the LUCAS ET AL. CESM1(WACCM) GEC MODEL results, we deﬁne the potential at the surface of the Earth to serve as our reference and set it to a value of zero. The upper atmosphere is then typically between a positive potential range of 250–350 kV relative to Earth’s surface. This now allows the potential diﬀerence between the ionosphere and ground due to GEC sources, , to be determined through the following relation between the total resistance of the atmosphere, , and the total GEC source current, , PD (5) where we have used the fact that column resistances, , will add in parallel with being the area of the column. With the PD of the upper boundary known, one can determine the vertically uniform column current densities and height-dependent electric ﬁeld in the fair-weather region by utilizing the ionospheric potential of that column as follows (where for a horizontally uniform potential in the ionosphere). (6) (7) with being the column current density for a speciﬁc column, and is the electric ﬁeld at an altitude within the column. The previous discussion assumes a constant potential surface throughout the upper boundary. However, there are separate current systems ﬂowing within the ionosphere, due to the ionosphere neutral wind dynamo, and between the ionosphere and magnetosphere, due to the solar wind-magnetosphere dynamo, that create and maintain horizontal potential diﬀerences in the ionosphere. These current systems are LUCAS ET AL. CESM1(WACCM) GEC MODEL assumed to be in a separate domain and do not contribute as a source strength to the GEC but rather modify the distribution of potentials of the upper boundary in WACCM-GEC. The horizontal potential created in the ionosphere by these two additional external current systems is incorporated into WACCM in a manner described by Liu et al. [2010b]. At high latitudes, the horizontal potential created in the ionosphere by the solar wind-magnetosphere dynamo is described by the Weimer model [ Weimer , 1995]. This model is implemented within WACCM to provide a magnetospheric potential over the entire globe. This allows for temporal and spatial variations from solar inﬂuences to be incorporated into WACCM-GEC by perturbing the upper boundary potential over every column. Weaker but horizontally structured potential in the ionosphere can also be created by the neutral wind dynamo. This is accounted for at middle to low latitudes by incorporating an empirical model based on observations described by Richmond et al. [1980]. The variable will be used to represent the potential solely due to the magnetosphere current system and neutral wind dynamo that contributes to the total upper boundary potential. Figure 2 shows the output of a typical global ionosphere potential pattern during a quiet solar day that combines both of these external current systems. The stronger and more dynamic potential diﬀerences lie at high latitudes where the solar wind-magnetosphere dynamo is most eﬀective. To maintain current continuity within the GEC system, we modify the upper boundary potential globally to ensure that the GEC currents are the only current source in the atmosphere. This can be viewed as allowing for a ﬂoating potential . PD PD The potential at every grid column is then calculated as follows: PD PD PD PD (8) (9) where the ﬂoating potential is incorporated because we are maintaining current continuity between the ground and ionosphere. Finally, this new potential diﬀerence of the column is used to calculate the current density and electric ﬁeld according to equations (6) and (7). Within WACCM-GEC the ﬂoating potential from the magnetospheric perturbation modiﬁes the global potential by less than one tenth of 1%. This small contribution is due to the fact that the magnetospheric potentials have both positive and negative components and that the column resistance, , over these areas does not vary signiﬁcantly. However, the local potential changes introduced to individual columns will be shown to have signiﬁcant local eﬀects. LUCAS ET AL. CESM1(WACCM) GEC MODEL To solve for currents and electric ﬁelds in the GEC, the full spatial and temporal distribution of the conductivity and source currents within the modeling framework need to be assessed. Numerous GEC models have been developed in the past to describe diﬀerent aspects of the circuit, as discussed in section 1. Recent model developments have allowed for better characterization of the electrical connections within the atmosphere by utilizing higher-resolution meshes and novel numerical techniques [ Odzimek et al. , 2010; Zhou and Tinsley , 2010; Kalinin et al. , 2014; Bayona et al. , 2015]. In WACCM-GEC, the conductivity follows the methodology of Baumgaertner et al. [2013, 2014] and is discussed in section 3.1, and the sources follow a similar methodology of Kalb et al. [2014] and are discussed in section 3.2. These variables are incorporated into the same computational framework to use a consistent time step and spatial grid. The conductivity within clouds considers only those fair-weather clouds aﬀecting the resistance and, consequently, the return current. Electriﬁed clouds, serving as source currents, inherently consider conductivity changes within the clouds through the source parameterization. This is in contrast to a modiﬁcation made to the conductivity within the clouds in other models [ Slyunyaev et al. , 2015]. The conductivity is calculated in the same manner as Baumgaertner et al. [2013, 2014]. This includes calculating the ion pair concentration and the mobility of the ions , such that, (10) where is the elementary charge. To create the ion pairs, ionizing sources are incorporated into WACCM-GEC which includes galactic cosmic rays (GCRs), radon emission from the ground, and solar proton events. Ion-ion recombination is also considered within the model as a loss mechanism. The conductivity can also be modiﬁed by adjusting the mobility of the particles as well; this includes accounting for ion attachment to clouds and aerosols. To characterize small-scale (not resolvable within the climate model grid size) conductivity perturbations within the circuit, a ﬁnite element method (FEM) was used in Baumgaertner et al. [2014]. This allowed for a parameterization of small-scale cloud eﬀects on conductivity that are not resolvable on global climate model scales, to account for their inﬂuence on the downward return currents. This approach is implemented in the conductivity module of WACCM-GEC to account for the converging and diverging currents around small-scale clouds in the fair-weather return path of the GEC. As shown by Baumgaertner et al. [2014], neglect of such an eﬀect can overestimate global resistance by 20%. Incorporating these physical mechanisms to determine the conductivity in the domain allows one to calculate the full 3-D spatial and temporal distributions of conductivity utilizing the Community Earth System Model framework with the Whole Atmosphere Community Climate Model, CESM1(WACCM). Calculating conductivity in a physics-based framework allows for the coupling of many diﬀerent physical and chemical mechanisms and the investigation of new parameterizations and couplings within the same model. Thunderstorms and electriﬁed shower clouds are the sources of current to the GEC that maintain a potential diﬀerence between the ground and ionosphere [ Wilson , 1921]. Through various electriﬁcation processes such as precipitation-based charging, clouds can become electriﬁed. In particular, the noninductive charging mechanism that involves ice-ice collisions in the presence of supercooled liquid water is thought to contribute signiﬁcantly to cloud electriﬁcation [ Takahashi and Miyawaki , 2002; Saunders , 2008]. Storm kinematics as well as gravitational size sorting invoke charge separation that leads to the development of larger-scale charge regions inside these clouds. Herein it is assumed that this charge separation results in a current dipole. This dipole current source (that is described by a model parameter associated with cloud dynamics and microphysics) is what drives the current in the model domain. Kalb et al. [2014] derived storm currents of electriﬁed oceanic and continental storms identiﬁed by Liu et al. [2010a] based on Tropical Rainfall Mission Measurement (TRMM) satellite precipitation radar measurements and assigned respective mean currents from Mach et al. [2010, 2011] to these storms. This produced a global current map between 35 latitude (the observational domain of the TRMM satellite). They then compared this total current map with model-based cloud parameters and found good correlations between some model parameters and global conduction currents. Herein, we use the model parameterized convective mass ﬂux [ Zhang and McFarlane , 1995] to conduction current relationship. This relationship has shown good statistical LUCAS ET AL. CESM1(WACCM) GEC MODEL correlation at estimating the total current produced from storms and to represent the conduction current sources in WACCM-GEC. The following equation describes the relationship used in this study CMF (11) where is the source conduction current, is a constant relating the convective mass ﬂux to current contribution determined from regressions to the TRMM satellite, and aircraft data ( [A (kg/m /s) ), the summation is from the 500 mb pressure level to the top boundary, is an integrated height weighting factor, and CMF is the convective mass ﬂux (kg/m /s) at that pressure level. Starting the summation at the 500 mb pressure level excludes warm rain components in clouds that likely do not contribute to cloud electriﬁcation directly. The weighting factor is utilized to represent the depth of the storm and therefore its strength. Figure 1 shows the mean global current production output from the model utilizing the parameterization in equation (11). This illustrates that the source currents within the model are strongly produced over land masses while also accounting for the convection over oceans. The simulation was run during Southern Hemisphere summer months which accounts for the preferential current production in the south. Within climate models, there is a well-known tendency to produce convection too early in time of day [ Folkins et al. , 2014; Yuan et al. , 2013; Demott et al. , 2007]. This tendency results in the source currents in WACCM-GEC to occur at earlier times than observed. As this is a known artifact of the scheme, the microphysics parameterization and the resultant current production within the model occur earlier than observed. The convective mass ﬂux and subsequently derived currents are computed within the atmospheric component of CESM, which utilizes the Community Atmosphere Model (CAM5). A description of the model physics is given in Park et al. [2014]. The cumulus parameterization for updraft mass ﬂux used within CESM is the Zhang-McFarlane scheme [ Zhang and McFarlane , 1995]. In their paper they describe the generation of updrafts within a global climate modeling framework, which depends on the moisture and convective available potential energy within the model column. They also complete a sensitivity analysis of this new scheme to determine the improvement of the model-produced updrafts throughout the globe. The ability to use the GEC parameters as a means to evaluate atmospheric convective drivers is a by-product of this development. Consequently, this will allow new convection schemes to be evaluated based on the expected UT dependence of the GEC. Previously, we have described the equations underlying WACCM-GEC and discussed how the currents and electric ﬁelds within the model are calculated. Now we will demonstrate the capabilities of WACCM-GEC by allowing the model to run for 30 days, during which observational data in the Antarctic were collected. This run allows the conductivity and sources to be generated in a free-running simulation within a consistent model framework. The magnetospheric contribution seen at high latitudes will be analyzed in detail in section 4.1, followed by a comparison of WACCM-GEC electric ﬁelds to observational electric ﬁelds in Antarctica in section 4.2. This new model formulation opens up many opportunities to explore various inﬂuences on the GEC. As a demonstration, this section elucidates the connection between the GEC current system and external current systems ﬂowing in the ionosphere. The upper boundary conditions implemented within WACCM-GEC enable the combined inﬂuences of the GEC and magnetosphere currents on electric potential distributions to be investigated. The imposed potential due to solar wind-magnetosphere interactions is best described in Earth’s geomagnetic coordinates, while the GEC source contribution to the ionosphere potential is driven by solar heating and best described in Earth’s geographic coordinates. The geomagnetic coordinate system used in WACCM to describe the magnetospheric potential is the magnetic apex coordinates as described in Richmond [1995] and then converted to geographic coordinates. These two potential patterns are summed at each time step to produce the total potential pattern for the GEC. With these two potential patterns rotating diﬀerently within the Earth-ﬁxed frame, there are times and locations on the globe where these potentials are in-phase and out of phase with each other, which can lead to an interesting dynamic response in the polar regions. Both the magnetospheric perturbation and GEC sources have dominant 24 h modes. Because the net potential in the model is determined based on equation (9), these two contributions can be decomposed into an amplitude and phase to elucidate their relative contribution to the net potential. For illustration purposes, LUCAS ET AL. CESM1(WACCM) GEC MODEL a sinusoidal function with a 24 h period plus a constant oﬀset is ﬁt to the two potentials and summed, which is represented by the following formula. PD (12) and The variables represent the magnetospheric amplitude and phase, respectively, while and are the amplitude and phase contribution from the GEC, respectively, is the constant oﬀset for the column, and the 24 h angular frequency of interest. is stronger in the polar regions due to the magnetospheric current systems at high latitudes, whereas , without a column subscript, is the same globally and independent of location. For equatorial locations is negligible, and therefore, the leads to the variations detected at ground level, which allows for comparisons to the diurnal variation of the electric ﬁeld when viewed in UT. Consequently, the neutral wind dynamo in the ionosphere at middle and low latitudes has little inﬂuence on the local GEC potential. When conducting measurements at high latitudes, one must also take into account the perturbation due to the solar wind-magnetosphere dynamo [ Burns , 2005]. To illustrate the relative contribucomputed with the following equation. %Change (13) Calculating the amplitude and phase at every model point allows one to determine the relative inﬂuence of the magnetospheric potential globally. Figure 3 shows that there are regions where the amplitude of the magnetospheric perturbation is up to 50% that of the GEC and that there are regions where these amplitudes will constructively and destructively interfere. The red shading indicates constructive interference with the diurnal variation of the electric ﬁeld, while the blue shading indicates areas that destructively interfere. The 50% perturbation is during quiet geomagnetic activity. This eﬀect could be much larger and compete with the GEC variations for certain locations in more geomagnetically active situations. Section 4.1 provided an illustrative means to demonstrate the global inﬂuence of the magnetosphere current system on GEC properties. Of course, the model is able to provide a more quantitative assessment for any given location on the globe. To analyze the eﬀect of magnetospheric perturbations and compare with high-latitude observations, we utilized data from two Antarctic stations, Vostok (106.8 E, 78.5 S) (green dot) LUCAS ET AL. CESM1(WACCM) GEC MODEL and Concordia (123.3 E, 75.1 S) (blue dot). Vostok and Concordia, while not ideal locations for detecting large magnetospheric inﬂuences, are the only long-term data sets available in the polar regions. Observations of this kind in the polar regions are sparse and the data sets from these Antarctic sites have been investigated and published by G. B. Burns in several papers, e.g., Burns et al. [2012] and Burns [2005]. These stations are at similar latitudes but diﬀerent longitudes, which will generate diﬀerent phase relationships between the GEC and external ionospheric contributions to the potential, and consequently the vertical electric ﬁeld. This can be seen in Figure 4, which shows the relative electric ﬁeld variation from WACCM-GEC over Vostok and Concordia for 1 day. Analyzing the model output, one can tell that the potential pattern over Vostok (green curve) rises and falls sooner than the model output for Concordia (blue curve). Thus, Concordia measurements would more closely resemble the typical diurnal variation near equatorial sites as it experiences little inﬂuence from UT variations in the cross-cap potential because it is more in-phase with the GEC current sources. Utilizing WACCM-GEC to analyze these results, one can separate out the inﬂuences in the data from magnetospheric contributions and GEC current contributions. The black dashed line in Figure 4 shows the eﬀective GEC source contribution to the local measurements at Vostok, which we have calculated by removing the magnetospheric component. With this decoupling of the magnetospheric system and GEC system, the inﬂuence of the magnetosphere contribution tends to shift the phase of the diurnal variation of the electric ﬁeld to earlier times. Other high-latitude locations will experience diﬀerent inﬂuences depending on their location relative to the geomagnetic pole and the magnetospheric potential pattern, a fact recognized but not fully described in previous publications. Thus far, we have analyzed stations where data sets are also concurrently available. To determine the largest inﬂuence the magnetosphere can have during a solar quiet day, we analyzed Figure 3 to ﬁnd an area that is in-phase (197.5 E, 80.5 N) and also one that is out of phase (77.5 E, 80.5 S) with the GEC current sources. Figure 5 demonstrates the diﬀerent readings one could get at diﬀerent areas around the globe, simply based on measuring ground level electric ﬁelds. The baseline electric ﬁeld variation in Figure 5 is the daily mean diurnal variation determined from WACCM-GEC at a low-latitude location (0 E, 0 N). However, at the high-latitude locations, the electric ﬁeld perturbation with UT can be signiﬁcantly accentuated or suppressed due to the inﬂuence of the magnetospheric potential [ Burns , 2005; Reddell et al. , 2004; Corney et al. , 2003]. The mapping of this horizontal potential to the surface has been discussed by Park [1976] where it was demonstrated that horizontal potential structure greater than about 200 km will experience little attenuation in reaching the surface. LUCAS ET AL. CESM1(WACCM) GEC MODEL Thus, the magnetosphere potential serves as a source of variability in the surface electric ﬁelds independent of thunderstorm activity. To display the relative inﬂuence in more absolute terms, Figure 6 shows the separate upper boundary potential values due to the GEC and magnetospheric sources for the two regions identiﬁed in Figure 5. This ﬁgure demonstrates the phase relationship of the magnetosphere to the GEC for these speciﬁc locations. The red and blue curves constructively and destructively contribute to the GEC potential, respectively. The GEC potential varies throughout the 2 days due to day-to-day variability in the model’s convective activity. The magnetospheric potential is also varying over the 2 day period as it is a function of the geomagnetic indices throughout the 2 days. The geomagnetic activity conditions imposed in this simulation are considered to be quiet with a total horizontal cross-cap potential diﬀerence of about 60 kV. Under more active geomagnetic conditions, the cross-cap potential could exceed 200 kV and rival the GEC potential in certain locations at high latitudes. Combined with dynamic conductivity behavior in the polar regions, unique conditions could setup that result in very strong or very weak regional currents. To determine the consistency and accuracy of WACCM-GEC, observational electric ﬁeld data sets for Vostok and Concordia were obtained during common observing periods. WACCM-GEC was then run for this same observing period to evaluate the results under similar conditions. Within WACCM-GEC, the electric ﬁelds are represented by grid sizes that are much larger than the observations. Also, local disturbances that inﬂuence the electric ﬁeld measurements such as wind speed, clouds, temperature, and humidity are not able to be resolved in the model due to the large grid sizes. However, general trends and correlations can be investigated to evaluate the model. Data sets for each location were collected over the 3 month span of January–March for three overlapping years of 2009–2011 to obtain enough fair-weather days for analysis. In the data sets obtained from Vostok and Concordia, the electric ﬁeld was sampled at 10 s intervals. Occasionally, the data would have large ﬂuctuations due to local disturbances, and these ﬂuctuations were ﬁltered out to only leave fair-weather times for the analysis, as described in Burns [2005]. The data at each site were averaged over 30 min time intervals, and a 24 h mean was determined and centered on the time calculated. The value divided by the 24 h mean then gave the electric ﬁeld deviations for that period. WACCM-GEC was run for 30 days beginning 1 January 2010 to produce the output electric ﬁelds and currents which were then divided by the model daily mean to obtain LUCAS ET AL. CESM1(WACCM) GEC MODEL the deviations. The mean perturbation for each 30 min time interval was then determined and is presented in Figure 7. Comparing the diﬀerences between the model output and data in Figure 7, one can see that the phase relationship of Vostok to Concordia is similar between the model and the data. This indicates that the magnetospheric potential imposed within the model agrees well with the data at those locations. One noticeable diﬀerence between the model and the data is the relative amplitude of the peaks. The model predicts a maximum of about 10–13% while the data suggest that this value is closer to 20–23%. This deviation from the LUCAS ET AL. CESM1(WACCM) GEC MODEL data suggests that the source term within the model requires further reﬁnements, as that is the major diurnal driver for variation of the ground level electric ﬁelds. Developing a better model for source term strength from electriﬁed clouds that include a more detailed analysis of the ice and water pathways and other parameters within the clouds would improve the WACCM-GEC simulation and be of great value to the community. The lack of detailed meteorological and electrical measurements of clouds makes global source quantities diﬃcult to obtain. However, the results presented are very encouraging and the broad range of capability of WACCM-GEC opens a new way to study the GEC by allowing new atmospheric and electric parameterizations to be incorporated within the same consistent modeling framework. In this paper, we have developed a new physics-based model for the global electric circuit (WACCM-GEC) which is incorporated into the model framework of the CESM. This model computes the 3-D global distribution of electric ﬁelds and currents at each model time step of 30 min, at a grid resolution of 2.5 in longitude by 1.9 in latitude, with 70 vertical levels distributed in modiﬁed pressure coordinates. To do so, WACCM-GEC calculates the evolution of global conductivity at all grid points, including the inﬂuence of aerosols and clouds produced in the model. A dynamic global source current is determined in WACCM-GEC by relating convective mass ﬂux to current generation. To account for inﬂuences on the GEC potential by external current systems occurring in the magnetosphere, potential distributions due to the neutral wind dynamo and the solar wind-magnetosphere dynamo were included in WACCM-GEC as a time-varying and horizontally structured boundary condition of the top boundary potential. WACCM-GEC reproduced the expected behavior in potential and electric ﬁeld with UT, as described by the diurnal variation of electric ﬁeld around the globe. Some discrepancies exist between the relative amplitude of the model’s electric ﬁeld to observations, but this is expected to improve as the source current parameterization improves over time. At high latitudes, the inﬂuence of the external current systems was demonstrated and signiﬁcant regional perturbations can be introduced to the GEC potential distribution depending on the magnitude of the geomagnetic activity and the relative phase of the externally and internally generated potentials with UT. The high-latitude inﬂuence of magnetospheric potentials was evaluated against two separate Antarctic sites (Vostok and Concordia) where electric ﬁeld mills have been deployed and extensively utilized and scrutinized. WACCM-GEC was able to generate a diurnal curve of the relative electric ﬁeld variation at these locations that was in good qualitative agreement with the data. To determine the validity of the magnetospheric potential pattern, electric ﬁeld data from Vostok were shown to have a phase shift relative to Concordia, and the model was able to reproduce this phase shift. More data sets at high-latitude locations are needed to discern the inﬂuence of the magnetospheric potential on the GEC potential. Geomagnetic storms, conductivity variations due to clouds, aerosols, galactic cosmic rays, and source current changes with season and year will also introduce signiﬁcant variability to the GEC vertical electric ﬁelds and currents. This integrated model formulation allows such inﬂuences to be fully investigated. Another major utility of this work is the ability to evaluate the performance of new atmospheric physics schemes by contrasting the model outcomes of GEC properties with expected GEC behavior. This was elucidated when investigating the convective mass ﬂux parameterization for source currents and observing the diurnal variation in the GEC electric ﬁeld were peaking too early. This is attributed to a known limitation in many climate models where convection starts too early. To determine whether a new convection scheme is an improvement, one could compare the GEC electric ﬁeld UT response of the two diﬀerent schemes. There are presently no feedback mechanisms implemented in WACCM-GEC to determine how the GEC could impact climate variables. Many feedback mechanisms between the electrical properties of the atmosphere and cloud microphysics have been proposed, and this model could be used to investigate some of these relationships self consistently. STOP CONTENT EXTRACTION HERE IN THE NAME OF GOD
test_jgra.pickle ---------- ['A simulation study on the electric ﬁeld spectral dependence of thunderstorm ground enhancements and gamma ray glows']
10.1002/2016JD026422 We have done a thorough simulation analysis on the variability of the photon spectra produced with (due to Relativistic Runaway Electron Avalanche—RREA) and without (Modiﬁcation of Spectra) the avalanche multiplication process. Despite some measurements obviously showing a variability of the spectra, numerous theoretical studies consider RREA spectrum independent on the electric ﬁeld. However, analytical calculations by Cramer et al. (2014) have shown that RREA spectrum under low electric ﬁelds is not constant and stops being exponential. Using the Relativistic Electron Avalanche Model code, we model various layouts of the electric ﬁeld conﬁguration and study the predicted photon spectra. The primary focus of the present paper is to study the photon energy spectra, as gamma rays are more often observed by ground-based detectors. The simulation analysis of photon spectra potentially can help to deduce electric ﬁelds in thunderclouds. The energetic radiation from thunderstorms is currently being measured by ground-based particle detectors worldwide [ Torii et al. , 2002; Khaerdinov et al. , 2005; Chilingarian et al. , 2010; Tsuchiya et al. , 2011], by means of aircraft [ Kelley et al. , 2015] and balloon measurements [ Eack et al. , 2000]. These phenomena can last for tens of minutes and are much longer than submillisecond Terrestrial Gamma-ray Flashes (TGFs) typically observed by spaceborne instruments [ Fishman et al. , 1994]. The long-lasting ﬂuxes are usually referred as Thunderstorm Ground Enhancements (TGEs) when observed from ground-based detectors or gamma ray glows when observed from airborne detectors. The understanding of processes leading to the observed particle ﬂuxes was signiﬁcantly improved during the electric ﬁelds lower than conventional breakdown ﬁeld. The idea was that the atmospheric electric ﬁelds accelerate ambient electrons, which produce secondary knock-on electrons and consequently bremsstrahlung photons. Dwyer [2003] studied these eﬀects by means of Monte Carlo simulations focusing on the high-energy radiation named Relativistic Runaway Electron Avalanches (RREAs) rather than lightning initiation. The good agreement between the simulations and measurements of TGFs and gamma ray glows suggests that RREA is the probable mechanism of the observed electron and gamma ray production in thunderclouds. In this study, we will focus on ground-based measurements as they provide an opportunity of constant monitoring of the high-energy atmospheric phenomena in highly active thunderstorm regions, for example, Tampa Bay or Lake Maracaibo in Venezuela [ Albrecht et al. , 2016]. As electrons rapidly attenuate in the atmosphere, most of the information comes from gamma rays [ Torii et al. , 2002; Chilingarian et al. , 2014; Tsuchiya et al. , 2011]. In fact, Chilingarian et al. [2014] was the ﬁrst to suggest that the intracloud electric ﬁeld during TGEs can be measured based on observing the gamma ray spectrum on the ground. There are only few cases where electrons were measured at the ground level. Chilingarian et al. [2012, 2013] were able to estimate the energy spectra of TGE electrons along with gamma ray spectra for the ﬁrst time. In general, the measurements are in a good agreement with the large-scale RREA model. However, as it was stated in several papers [see, e.g., Dwyer , 2004; Dwyer and Babich , 2011], the energy spectrum of RREA electrons is expected to have an exponential cutoﬀ at 7 MeV. Unlike this model prediction, when measuring TGEs, the electron spectra CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS diﬀer from event to event with mean energies that are less than 7 MeV. At the same time, the analytical calculations by Cramer et al. [2014] showed that RREA energy spectra at low electric ﬁelds ( kV/m) stop being exponential with 7 MeV cutoﬀ and can be described by a convolution of exponential and power law functions. Most interestingly, a dependence of the RREA energy spectra on the atmospheric electric ﬁeld was found, which explains the measured diversity of the TGEs presented by Chilingarian et al. [2012, 2013]. For most of the TGE glows, only gamma ray spectra are possible to estimate. At the same time, the estimations of Chilingarian et al. [2014] showed that some of the events correspond to cases where the electric ﬁelds are lower than the critical ﬁeld necessary for the RREA initiation. This process is termed Modiﬁcation of Spectra (MOS), when secondary cosmic ray electron spectra are modiﬁed without an avalanche multiplication process earlier suggested by Chilingarian et al. [2012]. In this paper, we will focus on the electric ﬁelds below and slightly above RREA threshold to study the variability of the spectra and their dependence on the electric ﬁeld layout. As there are experimental indications and analytical estimations that RREA electron and gamma ray spectra are varying with the electric ﬁeld, the RREA particle measurements give a unique possibility to probe atmospheric electric ﬁelds. We will discuss the possibilities of the deduction of electric ﬁeld parameters based on the Monte Carlo simulations by Relativistic Electron Avalanche Model (REAM) [ Dwyer , 2003, 2004, 2005, 2007, 2008; Coleman and Dwyer , 2006]. In addition, we make comparisons with a Monte Carlo code developed by Celestin and Pasko [2011]. In this work, we use the runaway electron avalanche model (REAM) to simulate the production and propagation of high-energy electrons inside thunderstorms. REAM is a Monte Carlo code that includes the relevant cross sections for the interactions of electrons, photons, and positrons with air [ Dwyer , 2003]. These processes include atomic excitation, Møller scattering, bremsstrahlung emission, pair production, and annihilation. We then study the transport of the resulting X-rays and gamma rays to the observation level. We use an initial population of 10,000 runaway electrons as seeds to the avalanche. The electrons are injected with energies following a secondary cosmic ray power law spectrum. The spectrum is estimated by using the Excel-based Program for calculating Atmospheric Cosmic-ray Spectrum (EXPACS) [ Sato , 2015]. EXPACS was also used to estimate the seed electron spectrum in Chilingarian et al. [2012, 2014]. The power law index of 1.13 was calculated for 5000 m corresponding to typical thundercloud altitudes at Mount Aragats [ Chilingarian et al. , 2014]. We run several diﬀerent electric ﬁeld strengths and acceleration lengths of 500, 1000, and 1500 m. It is worth mentioning that for the sake of future comparisons, these distances were used under sea level density. For instance, because of the similarity of the system under diﬀerent air densities, at 12 km altitude, 1500 m at sea level corresponds to 6.3 km. This acceleration length is the most extreme case to consider, as we think that larger values are improbable to observe. The electric ﬁelds used in the simulation were normalized by the threshold value for which electrons run away, = 286 kV/m. This value is higher than the break even ﬁeld ( = 215 kV/m), which is the strength where minimum ionizing electrons lose energy [ Cramer et al. , 2016]. Note that the calculations to obtain these values are done for an atomic number density of air equal to atoms/m . Values at diﬀerent altitudes and conditions may be found by scaling these results with the atomic number density. The diﬀerence between and is due to Coulomb scattering, which increases the path length of the electrons [ Dwyer , 2004]. Hence, we use the quantity , where is the local electric ﬁeld, to characterize the external ﬁeld conditions. We speciﬁcally study ﬁeld values slightly above and below (i.e., is close to 1) in order to compare modeling results with the experimental results of Chilingarian et al. [2014] and the theoretical predictions made by Cramer et al. [2014]. Using the model described above, we calculate the resulting photon energy spectrum at the end of the electric ﬁeld region using diﬀerent scenarios, dependent on the ﬁeld length and strength. The hardness ratio of the spectra were calculated to quantify the variability of the photon energy distribution. In Figures 1–3, the spectra (per 10,000 seed electrons) are shown for the electric ﬁelds with delta = 1, 1.05, and 1.1, respectively. The blue, black, and red colors are to display the 500 m, 1000 m, and 1500 m ﬁeld length cases, respectively. For the = 1 and length of 500 m case, we obtain a good ﬁt from 2 to 50 MeV by a power law with an index 1.6, displayed as a green line in Figure 1. With the increase of the ﬁeld length (potential diﬀerence) the spectrum becomes softer as the RREA population grows and starts to dominate the gamma ray emission, but CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS still can be approximated by a power law function in the conﬁgurations studied in the present paper. However, the pattern changes for the higher ﬁeld strength and lengths. In the case of an electron propagation length of 500 m, the power law index decreases from 1.6 to 1.8 for a ﬁt between 2 and 50 MeV when increasing the ﬁeld from = 1.0 to = 1.05 (Figure 2). For the = 1.1, the gamma ray distribution cannot be well approximated by a power law function and turns to exponential regime as can be seen in Figure 3. For the intermediate potential diﬀerences and ﬁeld strengths the spectra at energies above 1 MeV become a mixture of both power law and exponential distributions. Cramer et al. [2014] found that as the electric ﬁeld approaches the runaway electron threshold value, the solution to the electron energy spectrum is a convolution between a power law function and a Gaussian distribution [see Cramer et al. , 2014, equation (39)]. At the same time, it is worth mentioning that even if the power law ﬁts seem not to be correct at relatively high ﬁelds above = 1.05, as it was shown by Chilingarian et al. [2012, 2014], most of the measured TGEs correspond to lower ﬁeld cases, where power law still applies. Moreover, it was shown that most of the TGEs or glows occur under ﬁelds below the runaway threshold, so called Modiﬁcation of Spectra (MOS) process [ Chilingarian et al. , 2012]. Without avalanche multiplication, secondary cosmic ray electrons get extra energy from the electric ﬁeld and due to the increased path lengths emit more gamma rays than without the presence of the electric ﬁeld in a thundercloud. In Figures 4 and 5, the gamma ray distributions are displayed for the case where the electric ﬁeld is below the runaway threshold, for = 0.5 and = 0.75, respectively. Unlike above the RREA threshold cases, when the ﬁeld length is increased for a certain value of the electric ﬁeld strength, we have fewer gamma rays reaching the boundary of the region where the electric ﬁeld is applied in comparison to the shorter ﬁeld lengths for the same value of the electric ﬁeld. The attenuation dominates the multiplication in this regime. The situation was opposite for above the RREA threshold cases. At the same time, again, there CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS is a trend of softening of spectra with the increase of the electric ﬁeld strength. In particular, for an electron propagation length of 500 m, the power law ﬁt between 2 and 50 MeV gives an index of 1.2 and 1.3 when increasing the ﬁeld from = 0.5 to = 0.75. One can also note that the shape of the spectrum does not change signiﬁcantly with the electron propagation length for ﬁelds . The next step in our analysis was to propagate the resulting bremsstrahlung photons from the source region to the observation point. Compared to space based observations of TGFs, these ground enhancements experience much less signiﬁcant atmospheric attenuation. For instance, high-altitude mountainous laboratories such as Aragats allow measurements to be made tens of meters away from the source, which is practically within the thundercloud. Typical thundercloud altitudes from these observation points range from 100 to 200 m. In Figure 6 we present the cases for which = 0.5 (below the runaway threshold) and 1.1 (slightly above the runaway threshold). The electric ﬁeld length for these cases was 1000 m. For the source distances of 100 and 200 m, a decrease of total number of photons can be seen; however, the spectral shape changes are not as signiﬁcant. Notice that the number of photons below 1 MeV increases between the initial population (RREA) and after the propagation of 100 m through the atmosphere. At this energy range, Compton scattering is the most dominant energy loss process for photons. Due to this scattering process, high-energy photons losing their energy are observed as lower energy particles. However, as the attenuation eﬀect is not as signiﬁcant than for TGFs, often corrections for propagation are not done assuming the measured spectral shape is the CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS It is important to note that for sea level stations, e.g., lightning and thunderstorm active regions such as the Florida or Louisiana coast lines, the corrections for propagation from the source to the observational point are vital as the distances can be as long as several kilometers. These locations are important as they already contain signiﬁcant scientiﬁc infrastructure to study lightning-related phenomena [e.g., Dwyer et al. , 2012a; Ringuette et al. , 2013]. The runaway electron avalanche length is a parameter that represents the average distance an electron travels before the number of runaway electrons is increased by a factor of ( ) [ Dwyer , 2003]. This parameter depends on the electric ﬁeld, as higher strengths will pull more low-energy electrons to the runaway regime, thus decreasing the distance for which more particles are created and/or attenuated. At high electric ﬁeld values, Coleman and Dwyer [2006] showed that the avalanche length can be calculated by the following analytical ﬁt kV kV/m (1) However, at lower ﬁelds just above the runaway threshold value ( ), the following relationship applies kV kV/m (2) We compare the current simulation results for = 1.0, 1.05, and 1.1 to this analytical equation in Figure 7. As we can see from the ﬁgure, there is a large discrepancy between our RREA simulation results and those of Coleman and Dwyer [2006] at = 1.0, near the threshold ﬁeld value. Note that equation (2) is not valid for electric ﬁelds 285 kV/m and = 1.0 corresponds to a ﬁeld of 286 kV/m. The diﬀerent avalanche lengths corresponding to diﬀerent propagation lengths are obtained in the simulation results and can be explained by the fact that in the ﬁeld range close to threshold, the avalanche length is on the order of several kilometers. Hence, even for the longest propagation distance used in the present study, the electron distribution does not reach steady state. At the same time, it is important to note that in this work we use a diﬀerent input energy spectrum from that of Coleman and Dwyer [2006] (exponential with an average energy of 7.3 MeV). Therefore, even typical thundercloud ﬁeld lengths would not be able to produce RREA reaching steady state in this regime. Concurrently, particle ﬂuxes can be observed by ground-based particle detectors even without reaching a steady state, and even below the runaway electron threshold [ Chilingarian et al. , 2012]. For relatively higher ﬁeld values, we get agreement with Coleman and Dwyer [2006], suggesting the steady state regime CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS has been reached. This is not surprising taking into account the avalanche length for = 1.05 and 1.1 is 313 and 186 m, respectively. This means that for the propagation distances we consider here, we are modeling runaway electron propagation through a few avalanche lengths. We have done a Monte Carlo simulation study of electron propagation in air under a homogeneous electric ﬁeld with or without RREA ampliﬁcation that results in particle enhancements named TGEs or gamma ray glows. Despite the widely discussed 7 MeV cutoﬀ and independence of the RREA spectrum on the electric ﬁeld that is usually assumed [see, e.g., Dwyer , 2004; Dwyer and Babich , 2011], there are some experimental evidences that actually the spectrum is not constant. For example, the measured TGE electron spectra have smaller than predicted 7 MeV average energy [ Chilingarian et al. , 2012, 2013]. It should be noted, however, that the 7 MeV cutoﬀ assumption is valid if the RREA reaches a steady state; i.e., the acceleration region is large ( ). Besides experimental results, there are also analytical calculations indicating the RREA spectrum variability with electric ﬁeld [ Cramer et al. , 2014]. Cramer et al. [2014] studied the eﬀect of the electric ﬁeld on the energy spectra of electrons, and the same procedure can be used here to determine the photon spectrum. At electric ﬁelds close to threshold, the bremsstrahlung energy losses are signiﬁcant and the spectrum becomes a convolution of a power law and exponential function [ Cramer et al. , 2014]. It was found that the spectrum was sensitive to the value of , which is the uppermost energy an electron can have for a certain electric ﬁeld value before a balance is reached between the energy gained from the electric ﬁeld and that lost due to ionization and bremsstrahlung. In Cramer et al. [2014], the analysis was done for the runaway electron spectra and the corresponding photon spectrum can be deduced by assuming the bremsstrahlung power law dependence. In this paper, we have additionally studied the spectral dependence on the electric ﬁeld length and the eﬀect of the particle passage from source to the detector. A typical distance from the acceleration region to the observational level is on the order of 200 m for most of the observations made at Mount Aragats [ Chilingarian et al. , 2012]. Torii et al. [2004] made Monte Carlo simulations of the particle ﬂuxes from winter thunderstorms in Japan. In Figure 4 of Torii et al. [2004], it is shown that the total photon ﬂux near the Lower Positive Charge Region (LPCR) is dominant compared to the ﬁeld regions above. This is the case of measurements performed at Mount Aragats, and therefore, as a ﬁrst approximation, only considering the lower charge region is reasonable. As we can see from Figure 6, there are no signiﬁcant diﬀerences in the energy spectra between the acceleration region and the point of observation. Thus, the measured spectrum contains valuable information about the acceleration electric ﬁelds. In Figure 8, we present the dependence of a hardness ratio, deﬁned as the number of photons with energy 10 MeV divided by the number of photons 1 MeV and 10 MeV, on the electric ﬁeld strength. As we mentioned above, the spectrum softens as a result of increased electric ﬁeld length for . For the lower values of the electric ﬁeld strength, the spectrum becomes harder as low-energy photons attenuate in air. We can see from the plot that the hardness ratio is diﬀerent for various electric ﬁeld strengths; however, for diﬀerent potential diﬀerences (ﬁeld lengths), we cannot distinguish the electric ﬁelds by measuring only the hardness ratios. For example, the case for which = 1.05 and m gives near the same hardness ratio as the case of = 1.0 and m. This means to probe the atmospheric electric ﬁelds at the time of the gamma ray event, more parameters need to be measured. The degeneracy on ﬁeld length (total potential diﬀerence) should be solved by the observed intensity (see Figure 9), if the distance to the cloud is known. However, in some cases, we can infer the electric ﬁeld based on the hardness ratio. For example, if a hardness ratio of 0.4 is measured, this should correspond to an electric ﬁeld close to . In Figure 9, the number of photons per 10,000 seed electrons is displayed. As expected, the intensity increases with increasing ﬁeld strength. Also, it is not surprising that there is an enhancement of the number of particles as the ﬁeld length increases for . The eﬀect is opposite and the number of photons decreases for . This indicates that the true threshold is slightly below the used value for the runaway electron threshold ﬁeld ( kV/m), shown in Figure 9 as an intersection of three curves where the number of seed particles equal the number of relativistic electrons at the end of the acceleration region. We possibly can attribute this diﬀerence in the simulation to small variations in the multiple scattering cross section, as care should be taken in comparing multiple Monte Carlo codes as discussed in the RREA Simulation Techniques section of Dwyer et al. [2012b]. CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS We present the dependence of the hardness ratio of the photon distribution with photon ﬂux intensity in Figure 10. The hardness ratio for this plot is calculated the same as in Figure 8. The colors of the plot are to indicate the diﬀerent electric ﬁeld lengths used in the simulation of 500, 1000, and 1500 m, respectively. The diﬀerent symbols are to display the various electric ﬁeld values that were used in the Monte Carlo code. Following the work by Chilingarian et al. [2014], we suggest using hardness ratios along with the measured total ﬂux for the recovery of the atmospheric electric ﬁelds in thunderclouds. It should be noted that care should be taken when considering lower electric ﬁelds ( ) since slight variations of spectra are possible due to the initial electron angular distribution. For higher electric ﬁelds ( ), energetic electrons will tend to be aligned with the electric ﬁeld and the initial cosmic ray angular distribution will not be as essential. As we already mentioned above, the RREA photon spectra are not power law but products of electrons which are distributed by the convolution function of a Gaussian and power law. As we can see from Figure 10, the photon intensity can be a good indicator of the magnitude of the electric ﬁeld in thundercloud as the hardness ratio alone does not vary much at = 1.0 to 1.1. However, for the below threshold electric ﬁelds, the hardness CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS ratio is very sensitive to changes in the ﬁeld value and has a broader distribution. It is worth mentioning that the intensity spans several orders of magnitudes and the hardness ratio varies between 0.03 and 0.6, which is beneﬁcial for remote sensing the atmospheric electric ﬁeld. The combination between ﬁeld length and ﬁeld strength complicates the estimation of the electric ﬁeld in the thundercloud, for instance, the case of = 1.05 and ﬁeld length equal to 1500 m can imitate the case of = 1.1 and ﬁeld length of 1000 m. However, within some errors, it is possible to distinguish between cases. Also, care should be taken as our method should be model independent. Currently, there are many other simulation tools used for high-energy atmospheric physics, e.g., GEANT4 and CORSIKA [ Skeltved et al. , 2014; Köhn and Ebert , 2015]. In Figure 11, we have compared the code from Celestin and Pasko [2011] and the REAM Monte Carlo code used in this work. As shown, there is good agreement between the resulting photon energy spectra, which is another step in validating the spectral results obtained by the REAM code. CRAMER ET AL. ELECTRIC FIELD ESTIMATIONS Based on the above estimations, we conclude that particle measurements can give us valuable information about the conditions inside thunderstorm regions. The electric ﬁeld predictions reported in this work could be tested experimentally if concurrent gamma ray and intracloud measurements were made available. However, for the high-precision quantitative estimates of the electric ﬁelds to be deduced from the measured photon spectra, the contributions of other species of secondary cosmic rays should be considered. In addition to lightning detectors that are designed to measure currents and ﬁelds on the ground, radiation detectors will signiﬁcantly improve our understanding of atmospheric physics in lightning active regions. STOP CONTENT EXTRACTION HERE IN THE NAME OF GOD
test_jgra.pickle ---------- ['Quasi-10-day wave in the atmosphere']
10.1002/2015JD023327 In the classical theory of oscillations on a spherical-rotating Earth, the quasi-10-day wave (Q10DW) exists as a westward propagating “free” or “unforced” normal mode oscillation with zonal wave number . In the present study, we employ Thermosphere Ionosphere Mesosphere Energetics and Dynamics/Sounding of the Atmosphere using Broadband Emission Radiometry temperature measurements between 20 and 100 km and 50 latitude, and extending from 2002 to 2013, to provide a comprehensive perspective on the Q10DW as it actually exists in the atmosphere. Climatological seasonal-latitudinal structures are presented which demonstrate that the Q10DW is weakest during summer months and equatorward of 50 latitude but otherwise has amplitudes ranging from 1.0 K at 45 km to 5 K at 100 km. Seasonal asymmetries and signiﬁcant interannual variability also exist. The mean period of the Q10DW is 9.8 days with a standard deviation of about 0.4 day. On average the Q10DW conforms reasonably well with theoretical expectations for a normal mode subject to the eﬀects of dissipation and mean winds, at least below 80 km. Above 80 km this conformity often breaks down. Several factors potentially contributing to this nonconformity are discussed. The atmosphere supports a wide range of wave motions at various spatial and temporal scales and forced by a variety of mechanisms. In this paper we are concerned with a special class of planetary-scale oscillation that, at least theoretically, exists in the absence of a coherent forcing distribution. If we consider the linearized equations of momentum, continuity, and thermal energy with respect to a windless background state without dissipation and assume solutions periodic in time and longitude, then a single equation that is separable in height and latitude can be obtained [see, for instance, Chapman and Lindzen , 1970]. The latitudinal equation (Laplace’s tidal equation) and height equation (“vertical structure equation”) are linked through a separation constant which is often cast in terms of an “equivalent depth” ( ) following Laplace’s initial consideration of the problem for an ocean of depth . In Chapman and Lindzen ’s [1970] application to atmospheric solar tides, the relevant zonal wave numbers ( ), wave frequencies ( ), and equivalent depths are determined by the distribution of tidal heating, and the vertical structure equation (a second-order ordinary diﬀerential equation) is solved for each and s with the corresponding component of the heating distribution speciﬁed. The vertical structure of each oscillation is determined by the equivalent depth of that oscillation as well as the vertical temperature structure. As it turns out, if the forcing in the vertical structure equation is set equal to zero and an isothermal atmosphere is assumed, a single equivalent depth emerges if the vertical velocity is set equal to zero at the lower boundary. The value of this equivalent depth is , where is the scale height for an isothermal atmosphere and is the ratio of speciﬁc heats . For = 7.5 km, = 10.5 km. In turn there is a whole series of oscillations with speciﬁc periods and zonal wave numbers that represent solutions to Laplace’s tidal equation for this particular value of . These solutions are variously referred to as free oscillations, normal modes, or sometimes Lamb waves; in this paper we will use the term “normal mode (NM)” when referring to this particular type of mathematical solution. Well-known manifestations in the actual atmosphere include westward propagating waves with periods (zonal wave numbers) near 2 ( ), 5 ( ), 10 ( ), and 16 ( ) days. In recognition of the observed variability of these wave periods in the atmosphere, they are often referred to, respectively, as the quasi-2-day wave (Q2DW), quasi-5-day wave (Q5DW), quasi-10-day wave (Q10DW), and quasi-16-day wave (Q16DW), and these designations are used to distinguish these atmospheric manifestations from NM. The latitude structures of the 5, 10, and 16 day NM obtained from solving Laplace’s tidal equation are provided in Figure 1. The 5 day and 16 day NM are symmetric about the equator, whereas the 10 day wave is antisymmetric about the equator; it has maxima at 55 latitude which are 180 out of phase. FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE The amplitudes of each of these NM all have the same vertical dependence, given by , where = and z is altitude. This simple theory predicts no phase change with height of the oscillation. As shown by Lindzen and Blake [1972] and Salby [1979], addition of dissipation to the problem introduces an energy sink that leads to vertical propagation characteristics, i.e., phase progression with height. In the actual atmosphere, the main deviations from the above picture include the presence of mean winds, meridional temperature gradients, and dissipation; the governing equations are then far from separable, and global numerical simulations must be employed. Salby [1981] forced a global linear model over a range of frequencies and with latitudinally constant symmetric and antisymmetric forcing, taking into account dissipation and realistic distributions of mean winds. He found that (1) ampliﬁed or “resonant” responses indeed occurred near the expected wave periods and zonal wave numbers; (2) some Doppler shifting of the wave periods from those based on simple theory occurred; (3) latitudinal structures often looked similar to those expected based on solutions to Laplace’s tidal equation, except in the middle atmosphere where zonal mean winds caused signiﬁcant distortion of the response and sometimes complete blocking of the oscillation. Among the notable atmospheric manifestations of NM mentioned previously, the Q2DW has been particularly well studied in the mesosphere and lower thermosphere [see, e.g., Moudden and Forbes , 2014; Yue et al. , 2012; Tunbridge et al. , 2011; Wu et al. , 1993, 1995, and references therein]. The Q5DW and Q16DW have also received some degree of attention over the same height region [ Day and Mitchell , 2010a, 2010b; Day et al. , 2011; Forbes et al. , 1995; Luo et al. , 2000, 2002a, 2002b; McDonald et al. , 2011; Miyoshi , 1999; Riggin et al. , 2006; Wu et al. , 1994]. The Q10DW wave, on the other hand, is less well studied in terms of its manifestations as a normal mode in a realistic atmosphere. Hirooka [2000] does provide some insight into the Q10DW in the stratosphere the month-to-month climatology of the Q10DW extending from the stratosphere to the lower thermosphere? To what altitudes does the Q10DW penetrate? What is the range of wave periods? What is the year-to-year variability? What are the similarities and diﬀerences with respect to NM behavior? In this paper our main objective is to characterize the westward propagating Q10DW with (hereafter just “Q10DW”) from a global perspective and to address the questions raised above. We do this by analyzing Thermosphere Ionosphere Mesosphere Energetics and Dynamics/Sounding of the Atmosphere using Broadband Emission Radiometry (TIMED/SABER) temperature measurements between 50 latitude and 20–100 km altitude during 2002–2013. Except for some relatively minor gaps, the SABER data are for all practical purposes continuous from orbit to orbit and from day to day within these intervals. These data enable us to reveal the latitude versus height structure of the Q10DW between 50 during every month of the year during 2002–2013, to ascertain the exact period of the oscillation and to reveal its interannual variability. The main shortcoming of this data set is the fact that the Q10DW possesses signiﬁcant amplitudes poleward of 50 , a latitude region not continuously measured by SABER. The following section 2 brieﬂy describes the SABER data and how we process the measurements to reveal the Q10DW and its characteristics. Section 3 concentrates on delineating climatological characteristics of the Q10DW and to what degree these conform to expectations in terms of a NM interpretation. FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE The interannual variability of the Q10DW is also revealed here. Section 4 provides a discussion of results, and a brief summary and conclusions constitute section 5. The basic data employed in this study are SABER version 2.0 temperature measurements covering 2002–2013. Since we consider SABER data equatorward of 50 latitude where sampling is uninterrupted by yaw maneuvers and relatively few data gaps exist, we have almost continuous (but asynoptic) coverage in UT and longitude. Taking measurements from ascending and descending parts of the orbit together, SABER provides measurements covering 24 h of local time within 60 day periods. Following the procedure in Forbes et al. [2008], 60 day mean migrating and nonmigrating tides are removed from the raw data by taking residuals from a 60 day running mean and then ﬁtting these residuals with various tidal periods and zonal wave numbers using a 60 day window that moves forward 1 day at a time. The 60 day mean removes most aliasing into the Sun-synchronous tides by the time-varying zonal mean [ Forbes et al. , 1997]. A second set of residuals is formed after removing the tides; amplitudes and phases of the Q10DW with are determined from ﬁts to 5 latitude averages of these secondary temperature residuals within sliding windows and extending from 50 to +50 latitude. Within each window ﬁts are performed with periods ranging from 8.0 to 12.0 days in increments of 0.125 days; the window lengths are 3 times the wave period. At any given height and latitude the Q10DW corresponds to the one ﬁt among these that has the largest amplitude, and it is assigned the corresponding wave period. In the following we will also have occasion to refer to the “10 day wave” as the oscillation with exactly 10 day period, to distinguish it from the Q10DW. The derived Q10DW amplitudes in the present study need to be evaluated in light of potential errors in the temperature measurements and the inﬂuences of these errors on the amplitudes and phases of the sinusoidal ﬁts described above. The relevant errors are the systematic and random errors of the individual temperature measurements, the random error associated with the bin-averaged temperatures being ﬁt, and the amplitude and phase uncertainties with respect to a given sinusoidal ﬁt. We address each of these sequentially in the following. Since we remove zonal means on a day-by-day basis within the data analysis, systematic errors (biases) in the temperature retrieval are removed and random errors represent the primary contributor to temperature measurement uncertainties. Remsberg et al. [2008] provide a detailed error analysis for V1.07 SABER temperatures. For the V2.0 data utilized here, there are no changes relative to V1.07 that would impact precision (random errors). The corresponding random errors in individual temperature measurements for typical midlatitude conditions are 0.3 K, 0.3 K, 0.6 K, 0.6 K, 0.7 K, 1.0 K, 1.8 K, 3.6 K, and 6.7 K at heights ranging from 20 km to 100 km in steps of 10 km. Since the temperature values that are actually ﬁt for the Q10DW are averages within 5 latitude bins, the appropriate measure of uncertainty in the ﬁtted temperatures is given by , where is the number of randomly distributed temperature measurements in a given latitude bin. The average number number at low latitudes and the highest at 50 . Taking 12 points per bin as a representative number, the 1 sigma uncertainties in the temperature values that are ﬁt to extract the Q10DW are about or 0.3 times those quoted above or 0.09 K, 0.09 K, 0.18 K, 0.18 K, 0.21 K, 0.30 K, 0.54 K, 1.1 K, and 2.0 K at heights ranging from 20 km to 100 km in steps of 10 km. The latter values listed above represent the eﬀective random errors of the temperature values being ﬁt, that is, the mean temperatures within 5 latitude bins. The 1 uncertainties in the amplitudes and phases associated with a given sinusoidal ﬁt are aﬀected by these errors if the ﬁt weights the data points according to these errors, if the errors are suﬃciently diverse, and if the number of data points being ﬁt is not too large. Accordingly, we do not ﬁnd the uncertainties in our ﬁts to be inﬂuenced very much by the above temperature errors. Instead, the primary contributor to amplitude and phase uncertainty in the present application is the variance of the data points about the least squares ﬁt (due mainly to other geophysical variability). These uncertainties are now described. The 1 uncertainties in the amplitude and phase for each ﬁt, associated with the scatter of points about the ﬁt, are standard products of any least squares ﬁtting algorithm. For the Q10DW amplitudes presented here, the corresponding 1 uncertainties increase from 0.1–0.2 K between 20 and 40 km to 0.2–0.4 K between 60 and 80 km, the larger (smaller) quoted values being more typical of local winter (summer). Between 80 FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE and 100 km amplitude uncertainties are typically 0.3–0.4 K at 80 km and 0.5–0.7 K at 100 km during all months. The amplitude uncertainties for our Q10DW ﬁts are thus appreciably less than the amplitudes shown in the following section, which tend to range from 0.5 K to 3.0 K from 20 km to 100 km for 12 year means at 50 latitude and 1.0–6.0 K during individual years under the same conditions, for example. The 1 phase uncertainties are always less than 1 day and less than 0.5 day over 80% of the domain. These represent the levels of uncertainty that should be considered when evaluating the ﬁdelity of the amplitudes and phases of the Q10DW displayed in the present work. Figure 2 illustrates the multiyear mean amplitude structure of the Q10DW temperature ﬁeld. Figure 2 (left column) provides latitudinal structures as a function of day of year for altitudes 44 km, 70 km, 86 km, and 100 km. Figure 2 (right column) provides height versus latitude structures for the ﬁtting windows centered FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE on 15 December, 15 September, 15 June, and 15 March. The dashed lines in each panel indicate the latitudinal shape of the Q10DW based on Laplace’s tidal equation (cf. Figure 1) and the amplitudes are only displayed between 50 latitude as discussed previously. In general, at least below 60 km altitude, the Q10DW is mostly active at middle latitudes during winter and around the equinoxes, irrespective of hemisphere. The winter maxima (summer minima) are consistent with the presence of primarily eastward (westward) prevailing winds in the middle atmosphere which tend to enhance (block) vertical penetration of this long-period westward propagating wave. Around equinoxes, the relatively weak prevailing eastward winds do not appreciably inhibit vertical penetration. The illustrated amplitude distributions are consistent with the horizontal shape of the Hough mode (dashed lines), taking into account the aforementioned modiﬁcations due to the prevailing winds. Some hemispheric asymmetry is seen, with larger amplitudes favoring the Northern Hemisphere. Figure 3 reinforces some of the above assertions and makes clear other features as well. Shown here are the multiyear average (2002–2013) Q10DW amplitudes as a function of height and day of year for +50 , 0 , and 50 latitude. Conﬁnement of the Q10DW to equinoctial and winter months below 60 km altitude is particularly evident at +50 latitude where the variation is more or less annual. At 50 latitude, however, there are three broad maxima around days 360–080, 120–180, 210–270, with counterparts above 70–80 km that suggest a connection with those in the stratosphere. At +50 latitude there is an upper level maximum during summer (days 180–240) that does not have a clear counterpart at lower altitudes. At least below 70 km, and consistent with Figure 2 (right column), the weak amplitudes at the equator (Figure 3, middle) comply with the antisymmetric nature of the Q10DW normal mode. FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE As noted previously, the Q10DW is determined through least squares ﬁtting of the residual data for wave periods ranging from 8.0 to 12.0 days, and from among these the amplitude and period of the Q10DW are taken to be the values from the ﬁt yielding the largest amplitude (e.g., see, for example, Tunbridge et al. [2011], who employ this technique to determine the period of the Q2DW]. Figure 4 illustrates some representative samples of the wave periods for December and March at +50 and June and March at 50 latitude. The periods range between about 9.7 and 9.9 days with a standard deviation of about 0.4 days. This result is typical of other latitudes and months. Figure 5 provides some insight into the behavior of the observed Q10DW in terms of its expected behavior as a resonant oscillation mode of the atmosphere. Results are shown for the ﬁtting window centered on 15 September (day 258) when middle atmosphere amplitudes have a maximum and the mean winds are less inﬂuential. Figure 5a illustrates the mean amplitudes over 2002–2013 at +50 and 50 latitude along with standard deviations for 50 N and the theoretical height dependence for a normal mode, namely, , where = altitude and = 0.29. (Standard deviations for 50 S are very similar and are not included for clarity purposes.) We note that the mean amplitudes in opposite hemispheres can be considered equal given the inherent variability and correspond reasonably well with the expected height dependence (as opposed, e.g., to that the amplitudes correspond solely to wave ﬁts with a 10.0 day period. As expected, this leads to somewhat reduced average amplitudes but which are more nearly equal between hemispheres above 60 km. The diﬀerence between Figures 5a and 5b reﬂects the fact that the maximum ﬁtting amplitudes occur over a range of wave periods between roughly 9.25 and 10.5 days (cf. Figure 4). However, deriving amplitudes at exactly 10.0 day period enables us to compare phases (e.g., between heights and latitudes) for a single-period wave, which leads us to Figures 5c and 5d. Figures 5c and 5d provide some information on the phase behavior of the 10 day wave (N.B. as distinct from the Q10DW). Expressing the 10 day wave in the form , we can express phase in two ways: either the time of maximum at 0 longitude or the longitude of maximum at 0 UT. Using the former deﬁnition, Figure 5c shows the mean phase diﬀerences between +50 and 50 latitude between 2002 and 2013 during September, corresponding to the mean amplitudes of the 10 day wave in Figure 5b. The expected behavior for a purely antisymmetric oscillation is a phase diﬀerence of +5 days or 5 days depending on whether 50 N is leading or lagging 50 S. Except for the region between about 30 and 40 km, phases at 50 N are (on average) sometimes in antiphase with those at 50 S (i.e., 60–90 km and 20–30 km) but between 40 and 60 km the two hemispheres are more nearly in quadrature with one another. It is important to note, however, that the standard deviations of these phases are quite large, indicating signiﬁcant interannual variability. FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE Using the second deﬁnition of phase described above, Figure 5d shows the mean phase diﬀerences for the 10-day wave at all heights from that at 40 km altitude in each respective hemisphere, again at +50 and 50 latitude. As noted previously, while a normal mode in a dissipation-less atmosphere would be expected to possess no phase variation with height, the westward tilt with height seen from about 40 km to 100 km in Figure 5 is consistent with an upward and westward propagating wave. Below 40 km altitude the phase behaviors are somewhat diﬀerent between the hemispheres but both being more evanescent-like (i.e., lacking vertical phase progression) below 35 km. Figure 6, which provides height versus time Q10DW amplitude distributions from 20 to 100 km altitude for +50 latitude (top), the equator (middle) and 50 latitude (bottom) provides some insight into the interannual variability of the Q10DW. The larger stratospheric maxima at +50 in comparison to 50 are clearly seen. Also, there is some hint of a biennial modulation of these wintertime maxima, and the equatorial penetration of these maxima is more readily seen than those originating from Southern Hemisphere winter at high latitudes. At higher altitudes, however, equatorial amplitudes are more uniform throughout the year and may not totally reﬂect presence of the Q10DW (see below). It may seem contradictory to refer to nonzero equatorial values for an antisymmetric normal mode (referred to as equatorial penetration above), but in the actual atmosphere and especially during nonequinox conditions the Q10DW does not solely consist of a normal mode. Any asymmetry in amplitude structure about the equator implies the additional existence of at least the symmetric mode with period near 10 days, which is also a solution to Laplace’s tidal equation and thereby an eigenfunction orthogonal to the normal mode. Although this mode lies on the same manifold as the 5 day wave whose latitude structure is depicted in Figure 1 and is also westward propagating with , it is an internal (Class II) wave with vertical wavelength in excess of 100 km [see Figure 9 in Forbes , 1995]. Essentially, this additional mode (plus others to a lesser degree) must exist to accommodate (in the sense of a mathematical decomposition in terms of orthogonal functions) the distortion of the Q10DW imposed by the mean wind ﬁeld. Another viewpoint is that the mean wind ﬁeld acts to couple the antisymmetric mode (see Lindzen and Hong [1974] and Walterscheid and Venkateswaran [1979a, 1979b], for demonstrations and discussions of mode coupling due to mean winds in the context of atmospheric solar tides). mode into the symmetric FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE As noted above, there are some diﬀerences between the observed behavior of the Q10DW and that expected for a theoretical NM, even under the optimal conditions corresponding to Figure 5. To be sure, the inﬂuences of zonal mean, zonal winds, and meridional temperature gradients are having some inﬂuence in this regard; for instance, the temporary interruption of amplitude growth just above 40 km in Figures 5a and 5b can be interpreted in terms of a reduction in wave index of refraction due to background atmospheric wind and temperature distributions that are broadly typical of equinox conditions [ Salby , 1981]. Hemispheric diﬀerences in phase between 50 N and 50 S in Figure 5 are furthermore not entirely consistent with an antisymmetric NM or are the phase changes with height at each of these locations. Based on theory and modeling, phase gradients with height are expected both as the result of dissipation [ Lindzen and Blake , 1972; Salby , 1979] and the presence of mean winds [ Salby , 1981]. Phase diﬀerences from NM behavior are expected when the mean gradient winds calculated from SABER temperatures [see Figure 5 in Zhang et al. , 2010, for example] and ﬁnd this to be the case even for September conditions. Therefore, we attribute much of the phase behavior in Figure 5 that is diﬀerent from that of a NM to the eﬀects of dissipation and mean winds. There are additional and more subtle factors that can possibly aﬀect determination of the Q10DW from SABER temperature measurements as well as interpretation of the derived Q10DW characteristics, especially above 80 km; in the interest of completeness, these are brieﬂy described below. The ﬁrst of these factors is imposed by the way that the TIMED/SABER instrument samples the atmosphere, which opens the possibility for aliasing by other waves. In the present analysis, we remove 60 day mean tidal components and analyze the residuals in 24 to 36 day windows to extract the Q10DW. It is therefore not possible to explicitly ascertain the presence of Q10DW modulation of solar tides, although we know from ground-based observations that such modulations exist in the 80–100 km height region [ Forbes , 1995; Pancheva et al. , 2000, 2003; Pancheva and Mukhtarov , 2000; Pancheva and Mitchell , 2004]. Nevertheless, as demonstrated by Moudden and Forbes [2010] for Mars’ atmosphere [see Forbes and Moudden , 2012, for a terrestrial application], it is possible to gain insights into planetary wave-tide interactions in satellite measurements through examination of spectra with respect to pseudolongitude , that is, longitude incremented by each day and used instead of time to create the spectra. These authors, in fact, demonstrate that the spectral peak corresponding to a planetary wave is indistinguishable from that associated with secondary FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE waves [ Teitelbaum and Vial , 1991] generated by modulation of that same planetary wave with any migrating (Sun-synchronous) solar tide. In the present context this is equivalent to saying that such secondary waves can alias into determination of the Q10DW. Applying this theory further, it is simple to show that modulation of the westward propagating diurnal tides with and and westward propagating semidiurnal tides with and by the Q10DW produce secondary waves that also alias into determination of the Q10DW. All of the aforementioned tides and the Q10DW have been identiﬁed in satellite measurements in the 80–100 km height region [see, e.g., Forbes and Wu , 2006, and Pancheva et al. , 2007, respectively]. Since tides grow exponentially with height and become especially prominent above about 80 km, we must admit the possibility that the Q10DW presented here may be contaminated to some degree by the above aliasing contributions and could account for some nonconformity with expected NM behavior above about 80 km. A second factor that could aﬀect behavior of our derived Q10DW, again above roughly 80 km, is the possible secondary generation of the Q10DW by momentum deposition due to dissipating gravity waves ﬁltered by the Q10DW wind ﬁeld at lower heights. This mechanism seems to be rather well established in the context of much larger amplitude stationary planetary waves [ Holton , 1984; Miyahara , 1985; Schoeberl and Strobel , 1984; McLandress and McFarlane , 1993; Smith , 1996, 1997] but has also been demonstrated in numerical simulations for the Q16DW and Q2DW [ Meyer , 1999]. A suﬃciently large “pseudo Q10DW” at upper levels could interfere with the primary Q10DW, leading to departures from NM behavior in the total observed Q10DW. However, the magnitude of this eﬀect would depend upon the amplitude of the Q10DW wind ﬁeld at lower altitudes. In this paper the height, seasonal-latitudinal, and interannual character of the quasi-10-day normal mode is presented for the 2002–2013 decade using TIMED/SABER temperature measurements. The overall conclusions to emerge from this study are as follows: 1. Q10DW periods generally occur between 9.7 and 9.9 days with a standard deviation of about 0.4 day. 2. The Q10DW is most active at middle latitudes during winter and around the equinoxes, irrespective of hemisphere. 3. The seasonal-latitudinal structure of the Q10DW is consistent with the expected eﬀects of mean winds on this oscillation, particularly away from equinoctial periods. 4. There is a hemispheric asymmetry: The Q10DW is generally more intense in Northern Hemisphere winter than Southern Hemisphere winter, with much reduced amplitudes in local summer due to the blocking eﬀects of zonal mean winds. There is some evidence for a biennial modulation of the Northern Hemisphere winter amplitudes in the stratosphere. 5. Equatorial penetration is more conspicuous in the stratosphere for Northern Hemisphere winter as opposed to Southern Hemisphere winter. 6. Between 80 and 100 km, temporal variability of the Q10DW throughout the year is less well correlated with that at, e.g., 44 km, than between 70 km and 44 km. This suggests that the derived Q10DW above 80 km may be inﬂuenced by other processes in additional to vertical propagation of the Q10DW and also leading to nonconformity with NM behavior. 7. Above 80 km the secondary waves due to Q10DW modulation of migrating tides, and modulation of some nonmigrating tides by the Q10DW with , can alias into determination of the Q10DW as observed from the TIMED/SABER instrument. This can perhaps account in part for some of the reported lack of correlation and nonconformity to NM behavior above 80 km altitude noted above. 8. Another possibly relevant inﬂuence above 80 km altitude is that of momentum deposition near 10 day period by gravity waves ﬁltered by the Q10DW oscillation in the wind ﬁeld at lower altitudes. In principle this is a possible contributor to nonconformity of the observed Q10DW to expected NM behavior in this altitude regime, but its relevance depends on the magnitude of the Q10DW ﬁeld at lower heights as well as properties of the gravity wave spectrum. It is noted that some of the observed Q10DW characteristics are consistent with the previous work of Hirooka [2000], who examined the Q10DW in geopotential heights in UKMO data and those derived from UARS/ISAMS (Upper Atmosphere Research Satellite/Improved Stratosphere and Mesospheric Sounder) temperature measurements up to about 80 km. For instance, Hirooka found similar departures from classical NM behavior in amplitude and phase structures with respect to height and latitude and interpreted these in terms of wave damping and index of refraction of the background atmospheric state. He also noted a cessation FORBES AND ZHANG QUASI-10-DAY ATMOSPHERE WAVE of exponential growth in the vicinity of 80 km. The UARS/ISAMS data also provided a view of the Q10DW up to about 80 latitude. The Hirooka [2000] depictions of the Q10DW amplitude and phase behavior were, however, restricted to 7–14 April and 14–21 May 1992. The present work complements that of Hirooka [2000] by providing climatological perspectives on the Q10DW covering every month of the year for over a decade extending up to 100 km, as well as interannual variability, albeit conﬁned to the 50 latitude region. STOP CONTENT EXTRACTION HERE IN THE NAME OF GOD
test_jgra.pickle ---------- ['Characteristics of stratospheric warming events during Northern winter']
10.1002/2015JD024226 The strong interest in Sudden Stratospheric Warmings (SSWs) is motivated by their role in the two-way stratospheric-tropospheric dynamical coupling. While most studies only investigate major SSWs (vortex breakdown), the minor ones (strong vortex deceleration) are overlooked. This work aims at overcoming this gap by providing a comprehensive description of stratospheric warming events without a priori distinctions between major and minor SSWs, leading to a more complete estimate of the stratospheric variability. Warming events are extracted from reanalysis data sets by means of a midstratospheric polar cap temperature daily index. Events are characterized by a bimodal distribution in amplitude, with a broad peak at small amplitudes (inferior to ) and a sharp peak at around . Due to the intrinsic polar vortex dynamics, the warming amplitude presents a distinct seasonal distribution. Small amplitude warmings mainly occur during early and late wintertime by contrast with the larger-amplitude ones occurring during midwintertime. From mid-November to mid-March, the large-amplitude warmings (i.e., strong warming events, SWEs) include both major and minor SSWs, as well as Canadian and Final warmings. Although major SSWs belong to the tail of the SWEs distribution, there is no clear distinction between the major and minor SSWs according to the considered properties of the events. Such result brings out the idea of “warming continuum.” Furthermore, diagnostics of heat ﬂux reveal that there is no statistical diﬀerence between SWEs with regard to their feedbacks on the planetary waves and hence on their potential inﬂuence into the troposphere. Due to the polar night in wintertime, the high-latitude midstratosphere is characterized by westerly winds around the pole: the so-called polar vortex. The polar vortex is one of the most variable features of the zonal mean circulation of the Earth’s atmosphere, which results from a nonlinear interaction between planetary-scale Rossby waves and the zonal ﬂow [ Charney and Drazin , 1961; Matsuno , 1971]. In a span of a few days, this wave mean-ﬂow interaction leads to a zonal ﬂow weakening and a temperature rising over the polar cap by more than in extreme cases [ Scherhag , 1952; Labitzke , 1977]. Such phenomena are known as Sudden Stratospheric Warmings (SSWs) and constitute, since their discovery in 1952 [ Scherhag , 1952], the most impressive dynamical event in the physical climate system. SSWs are commonly deﬁned by the reversal of the meridional temperature gradient, and the diﬀerentiation between major and minor SSWs is made according to the reversal of the westerly stratospheric polar ﬂow at 60 N and 10 hPa ( McInturﬀ [1978], Andrews et al. [1987], and Butler et al. [2015], for a recent discussion on SSW deﬁnitions). Because major SSWs play an important role in the two-way stratospheric-tropospheric dynamical coupling, many studies have focused almost exclusively on them [e.g., Charlton and Polvani , 2007; Gerber et al. , 2009; Cohen and Jones , 2011]. However, to understand the response of the stratosphere to external tropospheric forcing and to better characterize the role of the stratosphere in pathways of climate variability, focusing solely on the extreme SSWs may be insuﬃcient. Indeed, the mean stratospheric response during Northern wintertime to global warming is not necessarily directly related to changes in major SSW frequency [ Karpechko and Manzini , 2012]. A comprehensive estimate of the variability of the wintertime stratosphere, including nonextreme cases, is needed to understand such mean stratospheric changes. Few studies ( Limpasuvan et al. [2004], among others) suggest that minor SSWs can also have a tropospheric signature, justifying the examination of minor SSWs MAURY ET AL. STRATOSPHERIC WARMING EVENTS as well. Moreover, Coughlin and Gray [2009] have shown that minor and major SSWs belong to a continuum of stratospheric warmings, without a well-deﬁned threshold between both SSW types. Such studies raise the question whether considering major and minor SSWs as distinct events makes sense. In this context, this work aims at (i) reducing the gap in the knowledge of nonextreme stratospheric variability, by using less restrictive event deﬁnitions and (ii) addressing the question of how distinct are major and minor SSWs. To achieve these aims, we provide a comprehensive description of the stratospheric warming events occurring during 54 Northern Hemisphere consecutive winters from 1959 to 2013 without any distinction between major and minor SSWs. The stratospheric temperature anomalies tend to propagate downward, and it has been shown that an empirical orthogonal function (EOF) analysis of the polar cap-averaged temperature is well adapted to capture the variability of the stratospheric polar vortex and to study its vertical structure [ Kodera et al. , 2000; Kuroda and Kodera , 2004; Zhou et al. , 2002; Hitchcock et al. , 2013; Hitchcock and Shepherd , 2013]. The originality of the present study lies in considering only positive anomalies of a daily polar cap vertically (50–10 hPa) averaged temperature greater than 1 standard deviation from smoothed climatological mean. By construction our method allows to select events corresponding to a warm middle stratosphere, corresponding to the second temperature EOF in the study of Hitchcock et al. [2013] [see Hitchcock et al. , 2013, Figures 2 and 3]. This paper thoroughly documents and examines the global statistics of the warm events in terms of amplitude and duration and discuss their associated dynamical properties. The paper is organized as follows: The data set and method used are introduced in section 2. Section 3 presents general statistics of stratospheric warm events. It will be shown that stratospheric warm anomalies occurring during the winter can be divided into two populations with regard to their amplitude. Thus, section 4 focuses on the stronger warm anomalies and gives a comprehensive comparison between the aforementioned warm anomalies and well-known climatologies of SSWs. Finally, a summary and a conclusion are provided in section 5. We evaluate the properties of stratospheric warmings for the period from the beginning of October to the end of April, hereafter deﬁned as “winter.” To extend the range of years investigated, two reanalysis products from the European Centre for Medium-Range Weather Forecasts (ECMWF), have been used. The ﬁrst set considers daily data over 20 years from ERA-40 [ Uppala et al. , 2005], from 1 October 1959 to 30 April 1979. The second one considers daily data over 34 years from ERA-Interim (ERA-I) [ Dee et al. , 2011], from 1 October 1979 to 30 April 2013. Considering that ERA-40 data sets are available until 2002, a Student’s test has been used to check that both reanalysis products do not statistically diﬀer in terms of mean and variability during the wintertime for the 20 overlapping years. In this way, 54 consecutive winters are used, spanning from 1959 to 2013, and the resulting merged product is noted ERA in the following. Stratospheric warming events are extracted from the ERA temperature daily time series by means of a midstratospheric polar cap temperature anomaly index. 1. For each year, a stratospheric polar cap temperature is computed from the daily zonal mean temperature by averaging (i) latitudinally, the cosine-weighted temperature between 70 N and 90 N, and (ii) vertically, the pressure-weighted mean between 50 hPa and 10 hPa. This daily ﬁeld is noted , where refers to the temperature and to the time with the subscripts and denoting the day and the year, respectively. 2. For each year, a 21 day running window is applied on the daily values to remove high-frequency variis represented in ations. From the resulting ﬁltered ﬁeld (hereafter, low-frequency)—noted —the mean and the standard deviation Figure 1a, together with its deviation by are calculated. The low-frequency mean 3. The index of midstratospheric polar cap temperature anomalies are eventually deﬁned as the unﬁltered daily temperature deviation from the low-frequency mean, normalized by the low-frequency standard deviation: . MAURY ET AL. STRATOSPHERIC WARMING EVENTS (1) Stratospheric warmings are extracted by selecting only the days for which 1. Thereafter, a stratoremains spheric warming event is deﬁned by a set of consecutive days for which the criterion satisﬁed, allowing to select 188 warming events over the 54 winters. Each stratospheric warming event is characterized by (i) a duration, (ii) an amplitude, (iii) a date of temperature maximum, , and (iv) the 5 day zonal mean zonal wind (60 N,10 hPa) minimum, . The event duration (in days) corresponds to the time remains satisﬁed. The event amplitude (in Kelvin) is calculated during which the criterion from the integral of the daily temperature deviation from the low-frequency mean, divided by the duration. For instance, considering a warming , is evaluated following (2) and ,respectively, denote the ﬁrst and the last days of the warming . Over the duration of each where event, corresponds to the day of the largest daily temperature and corresponds to a 5 day average of the zonal mean zonal wind at 60 N and 10 hPa around the date of zonal wind minimum. The eﬀectiveness of our approach is demonstrated by comparing the low-frequency standard deviation from the mean with the percentile values— —evaluated from the daily temperature time series (Figure 1a, see legend for details). Note that the low-frequency standard deviation approximates the and percentile values (Figure 1a). Therefore, our stratospheric warming events comprise the upper MAURY ET AL. STRATOSPHERIC WARMING EVENTS 20th percentile of the temperatures. We thus selected large anomaly events, while not restricting our selection to the sole extreme events that are conﬁned to the upper 5th or 10th percentile [ Stephenson et al. , 2008]. A selection based on lower thresholds (0.5 and 0 ) would include additional ﬂuctuations. Such ﬂuctuations would either increase the number of small amplitude and short events or extend the duration and lower the amplitude of the events (not shown). The latter eﬀect is caused by an addition of days with small ﬂuctuations before and after the events selected with 1 threshold. The dependence reported in section 3.2 would therefore be blurred. The 1 threshold appears to be the best compromise between maximizing the ensemble size and the rejection of small ﬂuctuations. Figure 1a also indicates that the temperature range between and is largest from December to February, minimal in October–November, and still relatively substantial in March–April, and evidences the well-known subseasonal variations in interannual variability. In addition, the larger temperature range between the high percentile and in comparison with the temperature range between the low percentile and indicates that over the 54 considered winters, strong temperature variability is dominated by strong warmings. To illustrate this point, the midstratospheric polar cap average temperature for three speciﬁc winters is added in Figure 1a. Independently of the winter considered, there is a large day-to-day variability, highlighted by sudden temperature rises, which occur more than twice a winter and exceed the value. Finally, the zonal mean zonal wind at 60 N and 10 hPa for the three previous winters (Figure 1b) illustrates the strong anticorrelation between the wind and the temperature, conﬁrming the using of as an indicator of the perturbation stage of the polar vortex. To assess the characteristics of the warmings, the event amplitude is represented as a function of the date at which the warming maximum occurs (Figure 2a), together with the box-and-whisker plots to quantify the spread of the amplitude values for each month from October to April (Figure 2b). The amplitude of the warm events presents a seasonal dependence. All the October events and 75% of the November ones have amplitudes which never exceed , whereas about 80% of the warmings occurring between December and February (DJF) have an amplitude larger than , extending up to around . During March, the mean and median of the event amplitudes are smaller than during January and February, and are similar to the ones in December, but the probability to have larger amplitude events in December is higher than in March. MAURY ET AL. STRATOSPHERIC WARMING EVENTS In April, around 75% of the warmings have an amplitude less than , like in November. The box size is larger for DJF than for the other months, indicating a larger spread of the amplitude values for the DFJ warmings than the October–November or March–April warmings. When the amplitude is reported as a function of the duration, a large correlation is observed between both (Figure 3a). Overall, the duration of the warmings increases with the amplitude, but this correlation is dependent on season. For instance, warmings with amplitudes tend to be longer in November, March, and April compared to those occurring in DJF. For November this can be explained by a longer radiative damping time than in DJF [ Newman and Rosenﬁeld , 1997], but this does not apply for March–April. Compared to midwinter period, amplitude warmings may be large enough to disturb durably the late-winter vortex. Indeed, due to the strong midwinter vortex, the stratospheric circulation may return faster to its climatological state than during late winter. Figure 4 shows the probability density function (PDF) of the event amplitude (i.e., the axis in Figure 2a) and duration (i.e., the axis in Figure 3a). The PDF of the amplitudes reveals a bimodal distribution with two relative maxima. The ﬁrst relative maximum is a broad peak at low amplitudes ( ), approaching the amplitude median value, and the second one is at around and delimits the upper 20% of the larger-amplitude warm events. When the early wintertime (October to mid-November), the midwintertime (mid-November to mid-March), and the late wintertime (mid-March to April) are considered separately, Figure 4a reveals a subseasonal dependence of the frequency in amplitude values. The ﬁrst warming set ( ) mainly consists of (i) early-winter warmings and (ii) around the half of late-winter warmings. Conversely, the second warming set ( ) mainly consists of midwinter warmings and the other half of late-winter warmings. Note that the secondary peak is almost exclusively explained by midwinter events. The PDF of the event duration (Figure 4b) is rather sharply decreasing for small-duration values, given that 50% of the selected events last less than 10 days (Figure 3a, and see also the positive skewness seen in Figure 3b). Although less pronounced than for the amplitude values, the PDF of event duration also hints at bimodality. This possibility is more apparent for the midwinter PDF (break point around 20 day duration and a second maximum at around 30 day duration). In this section, the temporal distribution of warm events is analyzed together with the stage of the polar vortex during the events. Figure 5 reports the warm events as a function of the date with their amplitude and duration, stratiﬁed according to their amplitude ( , , and , see legend for details). The daily values of the zonal mean zonal wind at 60 N and 10 hPa are also superimposed in Figure 5 for the 54 winters. The total frequency of the event occurrence by winter (3.8) is quasi uniformly distributed over the 54 winters (not shown). Main diﬀerences between winters come from the numbers of small amplitude ( ) warmings MAURY ET AL. STRATOSPHERIC WARMING EVENTS (see, for instance, winters 1971–1972 and those from 1990 to 1994). As already noticed in Figure 2, these small amplitude events ( ) mainly occur during October, November, and April, and they tend to happen twice or more in a short time period. For larger amplitude events ( ) there are two distinct distributions of events according to their duration. Short-time events are essentially occurring closely to other events (e.g., December/January 1975/1976 to January/February 1991), whereas long-time ones are rather “isolated” MAURY ET AL. STRATOSPHERIC WARMING EVENTS (e.g., February 1963 to January 1985). Note that during the second part of November, warm events with last more than 10 days and are isolated like in DJF (see, for instance, in November 1968 or 1996). Because the time between two closely occurring consecutive warmings is generally less than 20 days (not shown), it is natural to interpret such a group of events as a response to pulses of planetary wave activity [ Zhou et al. , 2002]. Such successive warm events are thus not independent from each other and belong to the same perturbation stage of the polar vortex, and we label them “clustered events.” This interpretation is supported by the zonal wind value associated to each clustered events (e.g., December/January 1976–1977 or January/February 1991). Figure 5 suggests that a distinct seasonal dependence between the amplitude of the events and the strength of the polar vortex tend to be related to a weak vortex during November (around 10 m s ) but to a total wind reversal at the end of the winter in March and April due to the vortex decay. In the same way, events with are associated with zonal wind values of 15–20 m s during October and the ﬁrst part of November, MAURY ET AL. STRATOSPHERIC WARMING EVENTS but with negative wind values during the second part of March and April. These small events are indicative of some ﬂuctuations of the vortex intensity during the polar vortex strengthening (early winter) or decay (late winter) but do not lead to dramatic vortex perturbations. On the opposite, during midwinter the warmings with are generally accompanied with dramatic vortex perturbations. The majority of the warmings having are associated with a total vortex breakdown, whereas events with (medium circles) are mainly associated to a weak polar vortex, with zonal mean zonal wind around 10 m s . However, the amplitude value of is not a well-deﬁned threshold to separate the events into two diﬀerent vortex states. Indeed, large warming amplitudes can also be associated with a weak vortex (i.e., in February 1981 or during January–February 1989–1994). Conversely, medium-amplitude events can be associated with a total wind reversal (i.e., February 1966 to November 1968 to February 2007). To clarify the linkage between the event amplitude/duration and zonal wind by season, in Figure 6 the events are grouped according to the three winter periods: early, mid, and late winter. Figures 6a and 6b show a strong correlation between the 5 day zonal wind minimum and both amplitude and duration for the midwinter events. Both ﬁgures conﬁrm that earlyand late-wintertime events do not show the same relationship between amplitude or duration and the wind than for the midwintertime events. Thus, only midwintertime events are considered to build the PDF of the amplitude and duration, stratiﬁed according to the value of (Figures 6c and 6d). Figure 6c shows that the median value tends to separate the midm s , winter events according to the wind value m s . Considering only the events with a bell-shaped “continuum” of stratospheric warming emerges, instead of two distinct stratospheric winter states where minor and major SSWs are separated. This result corroborates the idea of warming continuum outlined in Coughlin and Gray [2009], expanding their results to a larger sample of events. Concerning duration, Figure 6d shows that the warm events associated to a total vortex breakdown tend to have longer duration than events associated to a weak vortex, 70% of the latter persisting less than 10 days. The warming duration could therefore be a condition to discriminate most of the minor SSWs from the major ones. This result is possibly consistent with the correlation between the depth and the duration of the warmings found by Hitchcock et al. [2013]. Interestingly, when considering wind anomalies instead of absolute wind values, a correlation with the warming amplitude is observed, independently of the winter season (Figure 6e). On the contrary, the correlation between the warming duration and the wind anomalies remains seasonal dependent (Figure 6f ). The analysis of the previous section has demonstrated that the median amplitude value divides the events into two groups that present both distinct seasonal and dynamical properties. We therefore chose as our threshold for large-amplitude events in the following. In addition, closely occurring events with an interwarming time lower than 20 days have been merged together. After this selection and merging, the number of stratospheric warming events is reduced to about 40%. We call this new set of events the strong (stratospheric) warming events (SWE). The meridional heat ﬂux is a fundamental quantity for understanding the Northern Hemisphere stratosphere behavior [ Newman and Nash , 2000]. The heat ﬂux at 100 hPa averaged between 55 N and 80 N [see Andrews et al. , 1987] is presented in Figure 7. Superimposed to the heat ﬂux, the SWEs are depicted in terms of their amplitude, duration, and sign of . The meridional heat ﬂux is larger from December to March, mainly positive, indicating an upward wave propagation from the troposphere, and presents interannual variability correlated with the occurrence of SWEs, coherently with Polvani and Waugh [2004]. Visual inspection of Figure 7 shows that, independently of the event amplitude, the heat ﬂux tends to be large before the date of maximum temperature of SWEs and drastically decreases thereafter. In a number of cases, the heat ﬂux actually becomes negative after the day . The meridional heat ﬂux, being directly proportional to the vertical component of the Eliassen Palm ﬂux [ Andrews et al. , 1987], informs of the planetary wave propagation through the atmosphere [ Pawson and Kubitz , 1996; Newman et al. , 2001]. In this way, a positive eddy heat ﬂux indicates that waves propagate vertically from the troposphere to the stratosphere, and conversely, a negative eddy heat ﬂux indicates a downward propagation of planetary waves to the troposphere [ Perlwitz and Harnik , 2003]. As outlined by Kodera et al. [2013, 2016], a negative meridional heat ﬂux after a major SSWs can therefore indicate reﬂection of planetary waves by the perturbed polar vortex. Such a wave reﬂection leads to an MAURY ET AL. STRATOSPHERIC WARMING EVENTS ampliﬁcation of the tropospheric planetary wave structure inducing strong westerlies over the North Atlantic and blocking over the North Paciﬁc sector and thus impact tropospheric weather [ Kodera et al. , 2016]. Interestingly, Figure 7 demonstrates that a negative meridional heat ﬂux can also appear thereafter; SWEs without a wind reversal (see, for instance, March 1972 or February 1990). This observation suggests that some minor SSWs could also lead to tropospheric impacts. Composites of heat ﬂux anomalies have been evaluated for the midwinter SWEs with and separately, centered at the date corresponding to the lag day. Composites show a signiﬁcant diﬀerence about 10 days before lag where a larger forcing is observed for events with compared with events with (Figure 8, red and orange curves). However, surprisingly, there is no signiﬁcant difference between the two composites from lag day to lag . In the case of a vortex breakdown, waves MAURY ET AL. STRATOSPHERIC WARMING EVENTS anomaly for events with , given that they are mostly made of major SSWs. But the composite for events with is not statistically diﬀerent from the one with , whereas this population of events is mainly associated with minor SSWs. To demonstrate the insensitivity to the sign of the zonal wind in the heat ﬂux evolution for the SWEs, two additional composites are shown, for which the SWEs are stratiﬁed according to the sign of (black and grey lines in Figure 8). Although the forcing and the degree of vortex perturbation Indeed, after the lag and on the entire period (up to lag ) the heat ﬂux drops below the climatology for all cases. This result suggests that a total wind reversal is not a requirement for the wave activity to drop signiﬁcantly. Therefore, the dynamics of a perturbed vortex cannot be distinguished by the sign of the zonal wind, corroborating the idea of a “continuum” of SSWs. This part intends to compare the SWEs with published lists of SSWs. Such lists have been presented by Charlton and Polvani [2007] (CP07), Mitchell et al. [2012] (Mi12), Hu et al. [2014] (Hu14), and Labitzke and Naujokat [2000] (LN00). CP07 identify SSWs following the zonal mean zonal wind reversal at 60 N and 10 hPa, whereas Mi12 use a method based on a vortex moment analysis. Both studies use the ERA-40 reanalysis from winter 1957–1958 to 2000–2001. Hu14 identify major SSWs by looking for positive meridional temperature gradient northward to 60 N at 10 hPa and a zonal mean zonal wind reversal at 65 N, with NCEP-NCAR reanalysis from winter 1957–1958 to 2011–2012 [ Kalnay et al. , 1996]. As we use the extended wintertime season from October to April, the occurrence of our earlyand late-winter SWEs can be compared to the Canadian warming (CW) and Final warming (SFW) listed in LN00 and Hu14, respectively. Note that for the CW list, only the months when the warmings occur are available. The comparison between the early-winter SWEs and CWs is justiﬁed because many of them are considered as CW [ Labitzke , 1977]. MAURY ET AL. STRATOSPHERIC WARMING EVENTS The frequency of occurrence of the SWEs is around 1.8 events a year, against 0.6/0.65 in CP07/Hu14, and close to one event a year in Mi12. Clearly, these diﬀerences are related to the inclusion of the events usually termed as minor SSW (here and in Mi12) by a textbook deﬁnition [ Andrews et al. , 1987]. Also, we consider earlyand late-winter SWEs without distinction neither between midwinter SSWs and SFWs nor between early/midwinter and CWs, whereas CP07, Hu14, and Mi12 make this distinction between their events. To contrast the SWEs presented here with other climatologies of SSWs, our selected events are represented in Figure 9 as a function of the day and the year, together with events listed in CP07, Hu14, Mi12, and LN00. Canadian warmings. Among the 18 CWs listed by LN00, about 65% (11 CWs) are indeed selected. Note that, because LN00 only report the month where the CWs happened and not the date, the SWE occurring in November 1966 is considered as the CW occurring in December 1966. The 35% missing are likely due to the fact that CWs are mainly associated with small anomalous temperatures in the lower levels of the stratosphere [ Manney et al. , 2001]. For instance, CWs in November 1962 and December 1978 are associated with a warm anomaly that occurs below 50 hPa (not shown), while our selection is based on a (pressure-weighted) temperature average between 50 and 10 hPa. Midwinter events. Most of the major SSWs identiﬁed by CP07 (red stars) and Hu14 (dark blue stars) coincide with the SWEs, except for the case of 20 March 2000 (only selected by CP07). This particular SSW has a short time period of zonal wind reversal and a positive temperature anomaly conﬁned above 20 hPa (not shown), precluding its selection by our method. It is important to note that the trend toward a diminution of SSW activity during the 1990s [ Pawson and Naukojat , 1999, CP07] is not clearly observed in Figure 9. In agreement with Mi12, SWEs are indeed observed during this decade, even though most of them are considered as minor warmings. Moreover, this observation remains consistent with Butler et al. [2015], reporting warm events during the 1990s for the methods used in Gerber et al. [2010] and Limpasuvan et al. [2004]. Final warmings. It is important to recall that SFWs happen at the end of the winter during the transition between winter (westerly winds) and summer (easterly winds) circulation. However, only about 30% of the SFWs listed in Hu14 are identiﬁed in our analysis. According to Figure 5, the selected late-winter SWEs are accompanied by a drastic wind deceleration whereas SFWs identiﬁed by Hu14 are not systematically associated with such a wind deceleration but rather to a smooth transition to easterly winds. Also, Figure 7 shows an enhanced heat ﬂux as precursor for most of the late-winter SWEs identiﬁed here, whereas the heat ﬂux is weak for most of the unselected SFWs listed in Hu14. This indicates that our method seems to discriminate SFWs due to a dynamical forcing, which can be considered as “sudden” SFWs and prevent the vortex recovery before the spring, from those—unselected—due to radiative processes [ Sun and Robinson , 2009]. This work investigated the occurrence of stratospheric warming events, from the beginning of October to the end of April, in an extended reanalysis data set based on the merging of ERA-40 and ERA-I. Two selection criteria have been used to select the stratospheric warming events. The ﬁrst one provides a general description of temperature variability in the stratosphere, including nonextreme events (section 3). The second one, a more restrictive criterion, is based on the statistical properties of the warming set and on dynamical considerations associated with them, and aims at investigating whether there is a clear separation between major SSWs and minor SSWs (section 4). The ﬁrst selection criterion was used to characterize stratospheric warming events in terms of amplitude, duration, and occurrence. A bimodality in the distribution is found for the event amplitude, with each subdistribution amounting to about half of the total events. The amplitude distribution with mostly consists of earlyand late-winter events, whereas the distribution with mostly consists of midwinter events and has a sharper amplitude maximum at . Diagnostics of the zonal mean zonal wind reveal that both amplitude and duration of the warmings correlate with the zonal wind, for events occurring from mid-November to mid-March. During this winter period, the majority of events associated with a weak zonal wind (minor SSWs) and the totality of events with negative zonal winds (major SSWs) have also an amplitude . Within our statistics, the threshold of therefore separates warm events with distinct dynamical properties. We attribute the seasonal dependence of the warming amplitude to the climatological vortex dynamics that evolves during the wintertime due to the polar night. This seasonal dependence is not as clear in the case of the warming duration. However, our analysis reveals that major SSWs tend to be longer-lived events than minor SSWs. MAURY ET AL. STRATOSPHERIC WARMING EVENTS The second selection criterion allows for selecting the “strong (stratospheric) warming events (SWEs)”, including both major and minor SSWs, and also Canadian warmings (CWs, LN00) and a subsection of Final warmings (SFWs, Hu14). Our method therefore succeeds in a broad characterization of stratospheric variability that is not only restricted to the extreme variability. Moreover, our method allows the selection of SFWs that are likely dynamically driven rather than resulting from radiative processes [ Sun and Robinson , 2009]. Among the m s —can be described as a “warming conselected SWEs, the midwinter ones—associated with a tinuum,” without distinction between the diﬀerent SSW types. This result conﬁrms the conclusion of Coughlin and Gray [2009] who introduced the existence of a warming continuum and extends it to a wider range of events. Diagnostics of heat ﬂux anomalies demonstrate that for both major and minor SSWs the heat ﬂux drops below the climatology after the warmings peak. This result suggests that a total wind reversal is not a strict prerequisite for the wave activity to drop signiﬁcantly. This drop can not be explained by a simple application of the theory of Charney and Drazin [1961], as observed by Hitchcock et al. [2013]. The warming continuum observed here explains both (i) the diﬃculties in developing a standard deﬁnition for SSWs [ Butler et al. , 2015] and (ii) the discrepancies between the SSWs selected by diﬀerent protocols [ Palmeiro et al. , 2015]. Because we demonstrate that minor SSWs are not fundamentally diﬀerent from the major ones, classiﬁcations of SSWs based on the wind reversal become questionable. Thereafter, minor SSWs may be as important as major SSWs in terms of dynamical coupling perspectives between stratosphere and troposphere, for instance, via stratospheric waves reﬂection [ Kodera et al. , 2016]. Finally, as our method is an easily derived diagnostic, based on only one variable (the temperature), the statistics presented here can be very useful in the context of evaluating atmospheric models. Previous model evaluations only focused on major SSWs and revealed large discrepancies in the occurrence of major stratospheric warmings [ SPARC , 2010; Charlton-Perez et al. , 2013]. This new diagnostic and a more extensive analysis of the stratospheric warmings may help to reduce and/or understand model biases in variability and their consequences. In a more general view, it is expected that the present contribution should help both to evaluate the simulation of the dynamical interaction between SSWs and the background ﬂow in models and to study the eﬀect of changes in both extreme and nonextreme variabilities and SSWs on the stratospheric response to global warming. STOP CONTENT EXTRACTION HERE IN THE NAME OF GOD
test_jgra.pickle ---------- ['Diurnal variation in Sahara desert sand emissivity during the dry season from IASI observations']
10.1002/jgrd.50863 The problem of diurnal variation in surface emissivity over the Sahara Desert during non-raining days is studied and assessed with observations from the Infrared Atmospheric Sounding Interferometer (IASI). The analysis has been performed over a Sahara Desert dune target area during July 2010. Spinning Enhanced Visible and Infrared Imager observations from the European geostationary platform Meteosat-9 (Meteorological Satellite 9) have been also used to characterize the target area. Although the amplitude of this daily cycle has been shown to be very small, we argue that suitable nighttime meteorological conditions and the strong contrast of the reststrahlen absorption bands of quartz (8–14 m) can amplify its eﬀect over the surface spectral emissivity. The retrieval of atmospheric parameters show that, at nighttime, an atmospheric temperature inversion occurs close to the surface yielding a thin boundary layer which acts like a lid, keeping normal convective overturning of the atmosphere from penetrating through the inversion. This mechanism traps water vapor close to the land and drives the direct adsorption of water vapor at the surface during the night. The diurnal variation in emissivity at 8.7 m has been found to be as large as 0.03 with high values at night and low values during the day. At 10.8 m and 12 m, the variation has the same sign as that at 8.7 m, but with a smaller amplitude, 0.019 and 0.014, respectively. The impact of these diurnal variations on the retrieval of surface temperature and atmospheric parameters has been analyzed. Diurnal variations in desert sand emissivity during the dry season have been brought to the public’s attention recently by Li et al. [2012] who performed an analysis with SEVIRI (Spinning Enhanced Visible and Infrared Imager) observations from the European geostationary platform Meteosat (Meteorological Satellite). A recent analysis [ Masiello et al. , 2013b] performed by some of the authors of this paper with SEVIRI data conﬁrms this eﬀect and also shows that the time variation of emissivity closely follows the daily cycle for temperature. Diurnal variation in surface emissivity is very likely to occur in the natural environment because emissivity ( ) is inﬂuenced by soil water content ( ), which even in nonrainfall seasons, can change due to dew condensation at night, for example. However, the emissivity variation we are investigating occurs in desert areas, during non-raining days when the surface temperature does not necessarily drop below the dew point temperature at night. There are a series of basic studies, which can help to explain the phenomenon of diurnal emissivity variations during non-raining days in the dry season and in environmental conditions that do not favor the occurrence of dew formation on a bare sand dune. Agam and Berliner [2004, 2006] brought evidence of a new mechanism of direct water vapor adsorption on land surface. They also showed that the resulting soil moisture variations (with the soil moisture expressed by weight as the ratio of the mass of water present to the dry weight of the soil sample, units of kg kg ) follow the daily cycle [ Agam and Berliner , 2004] and the uppermost soil layer (0–1 cm) can change its water content from below kg kg (around midday) to above kg kg before sunrise. Mira et al. [2007a, 2007b] showed that the thermal infrared emissivity of rich-quartz sand strongly depends on soil moisture content. For low values of soil water content (around 0.02 kg kg ), the incremental ratio, , at wave numbers of reststrahlen absorption, is very large: per kg kg [ Mira et al. , 2007a, 2007b]. MASIELLO ET AL. 1626 The present study is devoted to complement the analysis by Li et al. [2012] and to provide further evidence that the mechanisms outlined in Agam and Berliner [2004, 2006] and Mira et al. [2007a, 2007b] are those responsible for the satellite-based emissivity diurnal variations observed in arid regions. Toward this objective we have analyzed IASI (Infrared Atmospheric Sounding Interferometer) spectra recorded over a Sahara desert area during the dry season (July 2010). Both descending (daytime) and ascending (nighttime) orbits have been considered, and the surface emissivity spectrum has been retrieved simultaneously with skin temperature and atmospheric parameters, namely temperature, water vapor, and ozone proﬁles, from IASI radiances. Space colocated day and night IASI observations have been used to assess diurnal emissivity variations. A quantitative analysis of the impact of these variations on the retrieval of surface temperature and atmospheric parameters is also carried out. We stress that the eﬀect of soil moisture over thermal infrared emissivity has been assessed both with laboratory measurements and satellite observations [e.g., Ogawa et al. , 2006; Mira et al. , 2010; Hulley et al. , 2010]. However, the present study focuses on the phenomenon of diurnal variation in emissivity of desert sand in situations in which soil moisture does not change because of rain or dew condensation. Diurnal variation in emissivity has also been evidenced with IASI observations by Zhou et al. [2011], who performed a retrieval of emissivity on a global scale. However, no attempt was made to assess the driving mechanism of these variations for desert regions. IASI was developed in France by the Centre National d’Etudes Spatiales (CNES) and is ﬂying on board the Metop-A (Meteorological Operational Satellite) platform, the ﬁrst of three satellites of the European Organization for the Exploitation of Meteorological Satellite (EUMETSAT) European Polar System (EPS). IASI has been primarily put in orbit for a meteorological mission; hence, its main objective is to provide suitable information on temperature and water vapor proﬁles. The instrument has a spectral coverage extending from 645 to 2760 cm , which with a sampling interval cm gives 8461 data points or channels for each single spectrum. Data samples are taken at intervals of 25 km along and across track, each sample having a minimum diameter of about 12 km. With a swath width on Earth’s surface of about 2000 km, global coverage is achieved in 12 h, during which the instrument records about 650,000 spectra. Further details on IASI and its mission objectives can be found in Hilton et al. [2012]. Regarding the assessment of the origin and mechanism of diurnal variation in emissivity, the complementary role of IASI stands out in its atmospheric sounding capability, which provides information about the thermodynamical state of the atmosphere together with surface parameters. The retrieval of surface and atmospheric parameters from IASI spectral radiances is carried out with a package that we call -IASI, the methodological aspects and validation of which have been described in many papers [ Amato et al. , 1995, 1999; Lubrano et al. , 2000; Masiello et al. , 2003; Masiello and Serio , 2004; Grieco et al. , 2007; Amato et al. , 2009; Masiello et al. , 2009; Grieco et al. , 2010; Masiello et al. , 2011, 2012a, 2012b]. The reader is referred to these papers for further details. For our analysis, it was important to identify a target area with surface features characterized as much as possible by sand rich in quartz and without vegetation. In addition, it was important to identify a series of IASI observations over a relatively long sequence of clear sky days in order to perform the analysis in non-raining meteorological conditions. To this end, together with IASI (level 1C) observations, we have also used high rate level 1.5 image data from SEVIRI on board Meteosat-9. SEVIRI channel emissivity maps over the North-West Sahara [ Masiello et al. , 2013b] helped to identify a target area characterized by sand dunes, whereas time sequences of SEVIRI radiances were used to identify long periods of clear skies. The present study is organized as follows. Section 2 shows the data used in the analysis, whereas section 3 describes the methodology. Section 4 is devoted to the results. Conclusions are summarized in section 5. The selected study area is located over the Sahara Desert, Ouargla Province, Algeria (see Figure 1). The area extends from to of East longitude and 29 to 33 North latitude, at an average altitude of about 200 m. Sand dunes prevail with a low vegetative cover. IASI data have been acquired for the month of July 2010, that is, in the middle of the dry season. Observed spectra correspond to the descending (day) orbits and ascending (night) orbits. The IASI scan pattern of footprints for a typical day (ascending and descending MASIELLO ET AL. 1627 orbits) is shown in Figure 1. Normally, we have approximately 400 spectra per day, of which half are in the morning (around 9 to 10 UTC) and the remaining half in the evening (around 20 to 21 UTC). The spectra were qualiﬁed as clear sky using the stand alone IASI cloud detection scheme developed by Serio et al. [2000]; Masiello et al. [2002, 2003, 2004] and Grieco et al. [2007]. A select few day-night spectra are shown in Figure 2 for the IASI band 1. The daytime IASI spectrum shows the characteristic peak at 8.7 m (1149.40 cm ), which corresponds to the center of the reststrahlen doublet of quartz. The nighttime spectrum clearly shows H O lines in emission in the atmospheric window around 1100 cm (9 m), which signals a temperature inversion at the surface. It has to be stressed here that ascending/descending IASI footprints (see also Figure 1a) are not perfectly overlapped. Therefore, the surface seen in the morning orbit could be diﬀerent from that seen during the night. To limit as much as possible any bias due to spatial collocation, we have considered day-night footprints with an overlap greater than 40% (see, e.g., Figure 1b). Another source of possible emissivity variation is the zenith angle. According to García-Santos et al. [2012], desert sand emissivity has an angular behavior, which becomes important for zenith angles . For this reason we have considered IASI pairs with a ﬁeld of view angle lower than . Based on the two selection rules above, the number of day-night month are shown in Figure 3. Meteosat 9 high rate SEVIRI level 1.5 image data in the infrared for the same target area and time period were also extensively used to characterize the surface emissivity [ Masiello et al. , 2013b]. The SEVIRI instrument has eight infrared channels with peaks at 13.4 (746.30), 12.0 (833.33), 10.8 (925.90), 9.7 (1030.9), 8.7 (1149.40), 7.3 (1369.9), 6.2 (1612.9), and 3.9 (2564.10) m (cm ), respectively. The time resolution of the data is 15 min, whereas each pixel has a size of km . Particularly interesting for the present analysis is the SEVIRI channel at 8.7 m (1149.40 cm ). In fact, this channel is MASIELLO ET AL. 1628 located just in the quartz doublet peak of the reststrahlen band, which has a very high contrast within the atmospheric window. Using SEVIRI observations for July 2010 [ Masiello et al. , 2013b], it was possible to check that the selected study area shows emissivity features common to desert sand rich of quartz. In addition, SEVIRI data (colocated with IASI footprints) have been also used to identify clear sky through a direct inspection of the time sequence at SEVIRI window channels, such as that at 12 m (833.33 cm ). An example is shown in Figure 4, where the temporal evolution of SEVIRI radiances at 12 m is plotted for the month of July. The ﬁgure corresponds to SEVIRI pixels at 30.66 North latitude and 5.56 East longitude. The radiance sequence follows exactly the daily cycle. Deviations (even small) from the smooth signal expected for clear sky allow us to detect the presence of clouds. From this plot we see that the ﬁrst 10 days of the month were characterized as clear sky, whereas clouds were present at the end of the month (around 25 July). IASI spectra have been inverted for emissivity, skin temperature, and atmospheric parameters using the -IASI package. As mentioned in section 1, the details of the package have been described at length in a series of papers. Here we limit ourselves to describe the methodology we use for emissivity, which is a relatively new aspect of the scheme. We use the optimal estimation [ Rodgers , 2000] with the emissivity spectrum represented with a truncated Fourier transform series [ Masiello and Serio , 2013a]. Emissivity Fourier coeﬃcients, skin temperature ( ), and atmospheric parameters, temperature ( ), water vapor mixing ratio , and ozone mixing ratio proﬁles, are simultaneously retrieved. For the forward model, we use -IASI [ Amato et al. , 2002], which can handle the radiance term reﬂected from the surface either with a specular or Lambertian model. For the analysis shown in this paper, we use the Lambertian model. Within the inverse scheme, an important issue is the background vector and covariance matrix for emissivity. For the purpose of developing a suitable background for emissivity, we have used the University of Wisconsin (UW) Baseline Fit (BF) Emissivity database (UW/BFEMIS database, e.g., http://cimss.ssec.wisc. edu/iremis/ [ Seemann et al. , 2008]). The UW/BFEMIS database is derived from the monthly mean operational Aqua/MODIS (Moderate Resolution Imaging Spectroradiometer) products (called MYD11C3) using a conceptual model called the MASIELLO ET AL. 1629 Baseline Fit method developed from laboratory measurements of surface emissivity. This method is applied to ﬁll in the spectral gaps between the six emissivity wavelengths available in MYD11C3 products. The UW/BFEMIS database is available from the year 2003 to 2012 globally with 0.05 spatial resolution at 10 wavelengths (3.6, 4.3, 5.0, 5.8, 7.6, 8.3, 9.3, 10.8, 12.1, and 14.3) m. Those wavelengths were chosen as hinge points to capture as much of the shape of the higher resolution emissivity spectra as possible between 3.6 and 14.3 m. The available band emissivities cannot be straightly interpolated to the IASI spectral bands, because this would be too crude an approximation. This problem has been addressed in Borbas and Ruston [2010] where an Empirical Orthogonal Function (EOF) regression was applied between the UW/BFEMIS database and the ﬁrst ﬁve eigenvectors at high spectral resolution of a representative set of laboratory measurements of surface emissivity. In this study a similar algorithm has been developed to interpolate a low spectral resolution emissivity spectrum to the IASI wave number range. As in Borbas and Ruston [2010], the interpolation is based on the EOF decomposition of a suitable training data set of high spectral resolution emissivity spectra from laboratory measurements. For the present study, we used a total of 134 emissivity spectra from the ASTER (Advanced Spaceborne Thermal Emission Reﬂection Radiometer) Spectral Library version 2.0 [ Baldridge et al. , 2009] and the MODIS UCSB (Moderate Resolution Imaging Spectrometer, University of California, Santa Barbara) Emissivity Library (http://www. icess.ucsb.edu/modis/EMIS/html/em.html). An example of the interpolation from UW/BFEMIS to IASI is presented in Figure 5. Derived from the UW/BFEMIS database, these IASI spectral resolution emissivity spectra have been used to build up an appropriate a priori or background (mean and covariance) for the optimal estimation retrieval. For the emissivity-covariance matrix, we only considered the diagonal elements (variances). As noted, in our retrieval procedure, the emissivity spectrum is represented through decomposition in a truncated Fourier cosine series. The truncation point can depend on the surface type. For desert sand, we need to resolve the reststrahlen absorption band at 8.7 m. For this reason, we have used 400 Fourier coeﬃcients, which correspond to render the emissivity spectrum with a spectral resolution of cm . Comparison with laboratory measurements shows that this spectral resolution is enough to resolve the spectral structures present within desert sand emissivity [ Masiello and Serio , 2013a]. Further details on how we handle the retrieval of surface emissivity can be found in Masiello and Serio [2013a]. Here we limit to show a retrieval example from one IASI spectrum recorded over desert sand. The example (see Figure 6) is shown here also to exemplify the precision of the retrieval. The precision is computed as the square root of the diagonal of the a posteriori covariance matrix. An additional important aspect of the methodology is that we can retrieve the emissivity spectrum over the entire IASI spectral coverage, even though we only used a limited number of IASI channels (see Figure 6). At wave numbers not used for the mathematical inversion of IASI radiances, the retrieved emissivity spectrum is just an interpolation of the Fourier cosine series. It is also important to stress that as the IASI spectrum is mostly sensitive to surface emission in atmospheric window spectral regions, the emissivity retrieval is most signiﬁcant in those regions. MASIELLO ET AL. 1630 where As described earlier, we use the optimal estimation [ Rodgers , 2000] to retrieve the state vector. Within the context of optimal estimation theory we can also address the issue of the sensitivity of the retrieval to the variation by a model parameter, which, e.g., is not included in the state vector. The general problem of sensitivity to a given interfering parameter can be handled by considering the derivative of the retrieved vector, with respect to the perturbation introduced by the interfering parameter, e.g., spectral emissivity. According to Carissimo et al. [2005], this derivative can be written as (1) 1. is the retrieved state vector, 2. denotes the generic interfering parameter-vector, 3. 4. 5. is the Jacobian matrix of the state vector, 6. is the Jacobian matrix of the emissivity vector. is the state vector background matrix, is the observational covariance matrix, (e.g., IASI radiometric noise), The sensitivity of the state vector, to a given perturbation, is obtained as (2) As already mentioned, the way we handle the various Jacobian terms and covariance matrix has been detailed at a length in previous papers. In particular, the reader interested in the details of in our retrieval scheme, is referred to Masiello et al. [2012a]. , which we use If we identify with the diurnal variation in emissivity, the methodology above can be used to assess the impact over the estimated state vector of this variation in case the emissivity is not retrieved and its value is taken, e.g., from a suitable atlas, such as the UW/BFEMIS database. Finally, we recall that the soil moisture ( ) is deﬁned according to its gravimetric method of measurement, (3) where is the mass of wet soil and that of the dry soil. The IASI spectra corresponding to day-night pairs identiﬁed in Figure 3 have been inverted for the simultaneous retrieval of , , , , and , according to the methodology outlined in section 3. The number of IASI channels considered for the retrieval are those shown in Figure 6. To make a proper comparison, e.g., with the results shown in Li et al. [2012] and also to capture salient characteristics in the diurnal emissivity variation, the IASI emissivity retrieval has been transformed to the SEVIRI channel emissivity at 12, 10.8, and 8.7 m, by convolving the IASI spectrum emissivity with the SEVIRI instrument response at 12, 10.8, and 8.7 m, respectively. The results for the days for which we had available MASIELLO ET AL. 1631 pairs to allow computation are shown in Figure 7. Averaging the results over the whole month, we found an average diurnal emissivity variation of 0.029 at 8.7 m, 0.019 at 10.8 m, and 0.014 at 12 m. From Figure 7, we see that the largest diurnal variations are seen around periods with heavy cloudiness (compare with Figure 4). If we focus on the most stable, non-raining period, that is, the ﬁrst 10 days of the month, we see that the diurnal variation is conﬁned below 0.04 at 8.7 m and, normally, well below 0.02 at 10.8 and 12.8 m. According to Li et al. [2012], we also see that the diurnal variation is larger at 8.7 m than at 10.8 m, which, in turn, is larger than that at 12 m. Details of the diurnal variation in spectral emissivity for 6 and 20 July, which correspond to two clear sky days with the larger number of couples of IASI day-night spectra and in the middle of two long periods of clear skies are shown in Figures 8 (left) and 8 (middle), respectively. A direct computation of the dew point temperature, derived from the IASI retrieval, shows that the diurnal variation we see in Figure 8 cannot be due to the formation of dew, because the dew point temperature is found well below the surface temperature. An example is shown in Figure 9 for 20 July 2010. A similar behavior was also found by Li et al. [2012]. As a consequence, on the assumption that the observed diurnal emissivity variation seen in Figures 8 (left) and 8 (middle) is due to soil moisture, according to Agam and Berliner [2004, 2006], the only mechanism responsible for the change is that of direct water vapor adsorption at the surface. To support this conclusion, we have analyzed the thermodynamical state of the atmosphere close to the surface. For 6 and 20 July 2010, this analysis is shown again in Figures 8 (left) and 8 (middle). The daytime retrieval does not show any inversion close to the surface and has a normal shape that favors evaporation. Conversely, the nighttime temperature proﬁles show an evident inversion, which traps water vapor close to the surface. This temperature inversion is consistent with the mechanism for H O adsorption and drives the day-night emissivity variation. In the same ﬁgures, the water vapor proﬁle is also shown. It is possible to see O is very low. For 6 and 20 July, the diurnal variation in water vapor column amount (day-night) is of 0.23 cm and 0.16 cm, respectively. This very small variation leads us to conclude that the atmosphere was very stable, and the presence of moisture by large scale atmospheric circulation was likely absent. To further support the above conclusion, Figure 8 (right) also shows the results for 26 July 2010. On this day, the diurnal variation was very low (below 0.005 at 8.7 m) and the emissivity retrieval at 9 UTC was almost identical to that at 20 UTC. However, for this day, the nighttime temperature proﬁles do not show any evident inversion in the boundary layer (see again Figure 9, right). This result conﬁrms that the mechanism which causes the diurnal emissivity variation is governed by a boundary layer temperature inversion. Also, a strong diurnal temperature diﬀerence seems to be important for the emissivity variation. This diﬀerence was 12 K for 26 July, whereas for 6 and 20 July, this was 19 K and 20 K, respectively. The temperature proﬁles shown in Figure 8 have been averaged over the number of soundings available for the given days. This averaging operation tends to smooth the inversion in the lower troposphere. However, the inversion is very well seen in each single retrieval and takes place very close to the surface. This is exempliﬁed for one single temperature retrieval in Figure 10a, which also compares the IASI retrieved temperature with the time-space colocated ECMWF analysis. The ECMWF analysis at the canonical hours of 00, 06, 12, 18, 24 UTC were used for the time interpolation. It is seen that the ECMWF model greatly MASIELLO ET AL. 1632 MASIELLO ET AL. 1633 smoothes the temperature day-night dynamic in the lower troposphere, which, conversely, appears much more pronounced in the IASI retrieval. From Figure 10, we see that an inversion occurs in between 975 and 925 hPa, which corresponds to a boundary layer altitude of m. It could be questionable whether or not IASI has this high vertical spatial resolution close to the surface. To demonstrate that in fact IASI does have this high spatial vertical resolution, Figures 10b and 10c show the averaging kernels for the two IASI temperature retrievals shown in Figure 10a. The very highly resolved averaging kernels close to the surface, as already mentioned, are a result of the desert sand emissivity, which yields a strong contrast throughout most of the IASI bands 1 and 3. What is important to capture in Figures 10b and 10c is the fact that the averaging kernels peak almost exactly at the corresponding layer pressure. This behavior shows that the retrieval is spatially resolved in the vertical at those layers in the lower troposphere. The results we have shown have been obtained over a target area, whose surface consists of bare sand dunes. In these conditions, the emissivity is largely determined by a mixture of two components: soil water content and sand. According to Hillel [1998], the process responsible for water vapor adsorption by soils is a reversible physical adsorption, which allows us to deal with moist soil as if it were mainly a mixture of water and sand. Chemical processes do not play an important role in this adsorption mechanism [ Hillel , 1998]. In this respect, if these two components are additively combined, according to their abundance in the mixture, we obtain a composite emissivity, given by (4) where is the emissivity of sand and that of water. MASIELLO ET AL. 1634 Under a variation of soil moisture, a variation is given by (5) in the whole infrared range, Since the diﬀerence has a very large amplitude (contrast) at the reststrahlen doublet of quartz, where can be as low as 0.6 [ Baldridge et al. , 2009]. This is why we see that the eﬀect of diurnal variation is larger at 8.7 m than at 10.8 and 12.0 m. In addition, the above model states that a reverse sign in the diurnal variation is possible in spectral regions where the diﬀerence changes its signs. For the type of surface we have analyzed, we expect that, within the atmospheric window, water has the larger emissivity. Therefore, the sign of the diurnal variation (nighttime-daytime) should normally be positive at window channels such as 8.7, 10.8, and 12 m. However, especially at 12 m, we may have land features with emissivities larger than that of water and a reverse sign could be possible. This reverse sign has been observed by Li et al. [2012], who examined a much larger area than that analyzed in this paper. According to Agam and Berliner [2004, 2006], diurnal variations in the uppermost 1 cm soil layer moisture due to the direct H O adsorption have amplitudes of approximately 2%. This variation might be not enough to explain the diurnal variation we have observed in the atmospheric window. However, thermal infrared measurements from satellite are sensitive to the top few micrometers. Thus, a 2% amplitude below the surface could not be representative of what is occurring in the topmost layer, where the eﬀect could be larger, and therefore explains the magnitude of diurnal variation we see at 8.7 m. It is also fair to say that a non-Lambertian behavior has been evidenced in quartz powder [ Wald and Salisbury , 1992], which at large angles ( ) has the eﬀect of decreasing the emissivity. A similar behavior has been evidenced in a recent paper by García-Santos et al. [2012], who also claimed that a non-Lambertian behavior begins to be evident at zenith angle larger than 40 . However, as already discussed, to limit possible angular dependence of the sand emissivity, the IASI day-night couples we have analyzed in this paper refer to zenith angles below 40 . In addition, the relative zenith angle, that is, the day-night diﬀerence of the ﬁeld of view angle does not exceed for any single day-night pair analyzed in this paper. In other words, the two IASI spectra of any single pair are observed with almost the same ﬁeld of view angle. This is exempliﬁed for 6 July 2010 in Figure 11. How signiﬁcant are these diurnal variations and what impact do they have on the retrieval of skin temperature, and MASIELLO ET AL. 1635 atmospheric parameters, temperature, water vapor, and ozone, ( , , and )? These issues have been addressed by applying the sensitivity analysis illustrated in section 3 to the retrieval obtained for 6 July 2010. This day is in the middle of a non-raining period with an average diurnal variation in emissivity at 8.7 m of 0.04. We have 28 day-night IASI soundings for 6 July 2010, the day and night average emissivity for which is shown in Figure 12. For each single daytime sounding, we have computed corresponding to the perturbation , (6) In this way, we mimic the eﬀect of using the nighttime emissivity to invert daytime IASI soundings. The results have been averaged over the 28 daytime IASI soundings and are shown in Figure 13. For the case of , we ﬁnd that this parameter would be negatively biased, because we use an emissivity, which is larger than the (supposedly) correct one, obtained within the simultaneous retrieval (section 4). The average negative bias for the surface temperature is equal to K. For the atmospheric parameters we also see a consistent bias, which means that the diurnal variation has a large impact over the retrieval of these parameters. The bias for temperature has a peak value of 8 K in the lower troposphere, whereas for water vapor we observe a diﬀerence of g/kg. For ozone we also observe a consistent bias of 1 ppmv. A second example is obtained by considering a variation with respect to the emissivity obtained by the UW/BFEMIS database. Derived from MODIS day-night products, the UW/BFEMIS database emissivity assumes a constant emissivity between day and night in the retrieval. Thus, it does not represent an average of diurnal variations, but it is simply one emissivity per day and, therefore, the present sensitivity exercise is also important to check the quality of satellite products, where emissivity is assumed to be diurnally invariant. In performing the sensitivity exercise, the UW/BFEMIS emissivity is imposed on the retrieval and the diﬀerence is considered for the case in which emissivity is itself retrieved along with , , , and . This latter For the 28 day-night IASI soundings, the average UW/BFEMIS emissivity is compared to the retrieved emissivity in Figure 12. In the case of the daytime IASI soundings, the emissivity perturbation is computed according to In the same way for the nighttime soundings, we have (7) (8) The results of the sensitivity analysis are summarized in Figure 14. For the case of skin temperature, we have that the assumption of imposing on the retrieval the UW/BFEMIS emissivity instead of simultaneously retrieving it with the other parameters, would result in a downward bias in during the day and, the reverse, an upward bias in would result at night. However, on average, the degree of this bias is conﬁned to within K ( K in the daytime and K at nighttime). The impact on atmospheric parameters appears to be much larger. The temperature can be aﬀected by K in the lower troposphere, the water vapor mixing ratio by g/kg and ozone by up to 2 ppmv in the stratosphere. MASIELLO ET AL. 1636 We have addressed the issue of diurnal variation in the emissivity spectrum of desert sand with a series of day-night IASI soundings recorded over the Sahara Desert during July 2010. In our analysis, great care has been taken to ensure that (a) the target area included only bare sand dunes, (b) there was a long sequence of clear sky with no rain, and (c) the IASI angle of views were below to minimize other possible sources of emissivity variation. In agreement with Li et al. [2012], our analysis does ﬁnd evidence of diurnal variations in the emissivity spectrum. Nighttime emissivity is found to be systematically larger than that retrieved during the daytime, which leads us to conclude that the soil moisture undergoes a daily cycle with a dip around midday and a peak at night. This conclusion is consistent with previous results by Agam and Berliner [2004, 2006], who showed that H O can be directly adsorbed at the surface without the formation of dew. During the dry season, the amplitude of the soil moisture cycle is normally 1–2%. These values refer to the top few centimeters of soil moisture, while thermal infrared measurements represent the top few micrometers. Accounting also for nonlinear volume scattering eﬀects and further experimental evidence [ Mira et al. , 2007a, 2007b] about the eﬀect of soil moisture on rich-quartz sand, we conclude that this amplitude is enough to yield diurnal variations in emissivity at 8.7 m as large as 0.04. The question of how common this phenomenon is can be raised. Direct adsorption of water vapor has been shown for arid and semiarid regions [ Agam and Berliner , 2006]. However, the phenomenon depends on the thermal and hydraulic properties of the surface and these properties can vary signiﬁcantly for diﬀerent soil types. Normally, the presence of clay improves the adsorption mechanism [ Agam and Berliner , 2006]. If we limit to stable, dry meteorological conditions, the transport of water vapor is driven by moisture and temperature gradients. Thus, a temperature inversion close to the surface is important to transport moisture toward the surface, as well, it is necessary that relative humidity of the soils pores is lower than the relative humidity of the air. As far as the transport of atmospheric water vapor toward the surface is concerned, IASI retrieval of the thermodynamic state of the atmosphere has shown that at nighttime an atmospheric temperature inversion occurs close to surface and creates a thin boundary layer which acts like a lid, trapping water vapor close to land and supposedly driving the direct adsorption of H O at the surface during the night. The results we have found lead us to conclude that the common belief that the desert sand emissivity is stable during the year is not correct and that diurnal variations have to be properly taken into account for a correct retrieval of surface and atmospheric parameters. In this respect, our ﬁndings speciﬁcally point out the importance of using physically based algorithms to retrieve surface temperature and emissivity. Split-window type algorithms, which are commonly used to retrieve surface parameters from satellite imaging radiometer instruments, such as MODIS and SEVIRI do not take these diurnal emissivity variations into account, and neither does the MODIS/Terra Land Surface Temperature and Emissivity Daily Level 3 Global 5 km Grid (short name MOD11B1) day-night approach, which could result in large surface and lower troposphere temperature errors. STOP CONTENT EXTRACTION HERE IN THE NAME OF GOD
test_jgra.pickle ---------- ['Effects of desert dust and ozone on the ultraviolet irradiance at the Mediterranean island of Lampedusa during PAUR II']
JOURNAL OF GEOPHYSICAL RESEARCH, VOL. 107, NO. D18, 8135, doi:10.1029/2000JD000139, 2002 [ ] The progressive decrease of the total atmospheric ozone amount observed at mid and high latitudes during the last few decades is expected to produce an enhancement of the ultraviolet irradiance at the surface [e.g., Madronich , 1992]. The ﬁrst analyses of the long-term behavior of the UV-B irradiance, based on the measurements of the United States network of Robertson-Berger UV-B radiometers over the period 1974 –1985, showed an unexpected decrease of the erythemal dose [ Scotto et al. , 1988]. These results pointed out the need to maintain well calibrated instruments and with continuous oversight [e.g., Kennedy and Sharp , 1992; Weatherhead et al. , 1997], and have led scientists to speculate causes due to other atmo1 2 spheric parameters, such as clouds [e.g., Frederick and Weatherhead , 1992], tropospheric ozone [ Grant , 1988; Bru¨hl and Crutzen , 1989], and aerosols [e.g., Grant , 1988; Liu et al. , 1991; Justus and Murphey , 1994], that may inﬂuence the UV-B irradiance. There is, however, now enough evidence that an increase of the UV irradiance occurs corresponding to periods characterized by low total ozone amounts [see, e.g., Seckmeyer et al. , 1994; Mims et al. , 1995; Zerefos et al. , 1995]. The evidence is particularly clear at high latitudes, mainly in the southern hemisphere [ Frederick and Alberts , 1991; Lubin et al. , 1992; Stamnes et al. , 1992; Frederick et al. , 1993; Bojkov et al. , 1995; Bais et al. , 1997; Frederick et al. , 1998; Gurney , 1998]. [ ] One of the main results of these investigations is the characterization of the dependence of the UV irradiance on the total ozone behavior. This dependence is generally expressed as a radiation ampliﬁcation factor (RAF) that gives the change (increase) of the UV irradiance (at a speciﬁc wavelength or integrated over a spectral range, weighted by a speciﬁc action spectrum) for a 1% variation (decrease) of total ozone. The value of the RAF strongly depends on wavelength, and is about 4 – 6 at 300 nm, and about 1 at 310 nm, for solar zenith angles, , around 45 [ Bais et al. , 1993; Bodhaine et al. , 1996; Fioletov et al. , 1997]. The RAF for the irradiance weighted for the erythema action spectrum is somewhat larger than 1 for near 45 [ McKenzie et al. , 1991; Kerr and McElroy , 1993; Basher et al. , 1994; Krzys´cin , 1996; Bodhaine et al. , 1996; Minschwaner , 1999; Dubrovsky´ , 2000.]. [ ] Several recent studies provide indications of a longterm increase of the UV-B radiation, related to the total ozone decrease [ Blumthaler and Ambach , 1990; Correll et al. , 1992; Kerr ans McElroy , 1993; Basher et al. , 1994; Herman et al. , 1996; McKenzie et al. , 1999; Borkowski , 2000]. [ ] However, Liu et al. [1991] show, with radiative transfer calculations, that the increase of tropospheric aerosols occurring over continental areas of the northern hemisphere as a consequence of SO emission may produce a signiﬁcant decrease of the UV-B radiation at the surface. They point out that the aerosol increase may partly offset the UV-B increase due to the ozone decline. Several experimental studies show that atmospheric aerosols may affect the ultraviolet irradiance. These investigations have been carried out in different conditions. Studies have been conducted at continental sites in Europe [ Krzys´cin and Puchalski , 1998; Can ˜ ada et al. , 2000], and in North America [ DeLuisi , 1997; Kerr , 1997; Wenny et al. , 1998]. coastal [ Kylling et al. , 1998; Can ˜ ada et al. , 2000], rural [ Meleti and Cappellani , 2000], and urban sites [ Lorente et al. , 1994; Repapis et al. , 1998]. Attenuating effects on UV by a large smoke aerosol load, as a consequence of biomass burning in Brazil, have been also reported [ Mims , 1996]. [ ] However, little is known concerning the effects of mineral aerosols on the UV irradiance. Mineral aerosol are expected to increase in the atmosphere, as a consequence of human activity: it has been estimated that a fraction ranging between 30 and 50% of the total mineral aerosols are produced in soils that have been disturbed by the human activity [ Tegen and Fung , 1995; Sokolik and Toon , 1996]. Mineral aerosol mobilization and transport is affected by large-scale phenomena, like the North Atlantic oscillation [ Moulin et al. , 1997], and El Nin˜o [ Prospero and Nees , 1986]. The dust transport is moreover characterized by intense events, with a duration generally of a few days. Thus these particles may affect the UV-B behavior on different timescales. [ ] The Photochemical Activity and Ultraviolet Radiation modulating factors II (PAUR II) campaign took place in the Mediterranean [ Zerefos et al ., 2002] during May and June 1999. An aim of the campaign was to study the combined effects of ozone and aerosol in a region characterized by large aerosol variability that is mostly due to the strong inﬂuence of dust transport events originating from the Sahara. [ ] As described by Zerefos et al. [2002], the campaign was based at the islands of Crete, Greece, and Lampedusa, Italy. In this paper, ultraviolet irradiance, ozone, and aerosol measurements collected at Lampedusa during the campaign are used to identify the interactions among these quantities. Lampedusa is a small island, 10 km long, approximately 2 km wide, in the southern Mediterranean (35.5 N, 12.6 E). During the campaign the instrumentation was based at the Station for Climate Observations of the Ente per le Nuove Tecnologie, l’Energia e l’Ambiente (ENEA) of Italy. A brief description of the site, the deployed instruments, and the results of aerosol proﬁle measurements by lidar is given by di Sarra et al. [2001a, 2001b]. [ ] An array of instruments dedicated to atmospheric observations was installed at Lampedusa during PAUR II [ di Sarra et al. , 2001b]. In this paper, data obtained from the UV spectrophotometer, the Sun photometer, and the aerosol lidar, are used. [ ] The operational UV spectrometer at Lampedusa is Brewer MK III 123. The Brewer spectrophotometer has been designed for total ozone measurements [ Brewer , 1973]. A description of the instrument and of its routine mode of operation is given by Kerr et al. [1985]. The Brewer MK III is a double monochromator spectrometer: a substantial improvement in the quality of UV measurements below 305 nm with respect to the single-monochromator measurements, due to the better stray light suppression, has been achieved with this spectrometer [ Bais et al. , 1996]. The instrument measures hemispheric UV irradiances betwen 286 and 363 nm through the teﬂon diffuser collector; spectral resolution is around 0.55 nm, and measurements are recorded at every 0.5 nm interval. During the PAUR II campaign, frequent measurements of the UV spectrum were performed (at least twice per hour) throughout the day. Up to 20 measurements of total ozone per day for 60 were also performed by the Brewer. July 1998, through a comparison with the traveling Brewer 17. A calibration of the ultraviolet irradiance scale was performed 10 days before the campaign, by means of the National Oceanic and Atmospheric Administration (NOAA) ﬁeld calibrator [ Early et al. , 1998], that uses a US National Institute of Standards and Technology (NIST) traceable 1000 W FEL lamp. The stability of the spectrometer during the campaign was monitored by using 50 W external lamps, as recommended in the Brewer operation manual. [ ] For the purpose of this analysis, the UV spectra measured by the Brewer have been interpolated at ﬁxed solar zenith angles, and corrected for changes of the Sun-Earth distance. The interpolation is performed by taking the three spectra closest-in-time to the time t corresponding to the selected value of ; a second-degree polynomial is ﬁt to the three irradiance measurements at each wavelength , and the irradiance at t is calculated. As explained below, only spectra measured in cloud-free conditions are used for the interpola3 tion. Thus we obtain simultaneous spectra for a cloud-free sky at 20, 30, 40, 50, 60, and 70 , at the mean Sun-Earth distance. The variation of and of the Sun-Earth distance has been calculated according to Spencer [1971]. The uncertainty on the observed irradiance is estimated to be around 4 –5%. The erythemally weighted irradiance at 20, 30, 40, 50, 60, and 70 at the mean Sun-Earth distance, E , is calculated by the convolution of the UV spectra interpolated at times t with the erythema action spectrum [ McKinlay and Diffey , 1987]. [ ] The values of the total ozone at times t were derived by linear interpolation between the closest measurements. The uncertainty on , for cloud-free conditions, is around 1%. [ ] A multiﬁlter rotating shadow-band radiometer (MFRSR) was operated at Lampedusa during the campaign. The MFRSR is a seven-band Sun photometer that collects sky radiation through a horizontal diffuser, and uses a rotating shadow band to separately measure the global and diffuse components of the radiative ﬁeld; the direct component is derived as the difference between the two measurements [ Harrison et al. , 1994]. The instrument installed at Lampedusa, model MFR-7, has a channel for the total shortwave radiation, and six channels centered respectively at 415, 500, 615, 671, 868, and 937 nm. The bandwidth of the last six channels is around 10 nm. The calibration of the MFRSR is obtained with the Langley plot method, after correcting the signals for changes of the Sun-Earth distance. The Langley plot has been applied to the channels centered at 415 and 868 nm, in 5 cloud-free mornings characterized by relatively low aerosol content and variability; these mornings were identiﬁed also on the results of the lidar observations. The standard deviation of the extraterrestrial constants is 2% for the 868 nm channel, and 5% for the 415 nm channel. The atmospheric optical depth is calculated by applying the Beer-Lambert law, S S e , (1) where S is the extraterrestrial constant, determined by the Langley method calibration. S is the MFRSR output signal corrected for changes of the Sun-Earth distance, is the sum of the molecular and aerosol optical depths at the selected wavelength, and m is 1/ cos . It must be mentioned that this equation is valid for a plane-parallel atmosphere, and a more complex expression for m is needed for 60 , and for Kasten and Young , 1989]. The aerosol optical depth is derived by subtracting the molecular optical depth [ Bucholtz , 1995] from . The obtained values are then averaged over 18 min intervals, and linear interpolation is used to derive the estimates of at the times t . Values of the diffuse-to-direct ratio for the observed radiation are also derived. [ ] A recent study has shown that, as a result of an intercomparison among four Sun photometers, aerosol optical depths from a well calibrated MFRSR can be retrieved with an absolute accuracy of 0.026 [ Schmid et al. , 1999]. The absolute error on , , includes the contributions of the uncertainties in the estimate of the molecular optical depth, in the signal S (the difference between the total and diffuse radiation for the MFRSR), in the air mass m , and in the extraterrestrial constant S . To emphasize the importance of the determination of the extraterrestrial constant on the obtained results, we assume that the ﬁrst three uncertainties contribute negligibly; in this case, if we deﬁne the uncertainty on S , S , (2) 1 m that is, for a ﬁxed the absolute error on is proportional to the relative uncertainty of S . Thus, for a 2% error on S , we have an uncertainty on due to S of approximately 0.02 (at small solar zenith angles). The error due to the calibration does not depend on the value of , and becomes smaller as the solar zenith angle increases. Thus the relative error on due to the calibration uncertainty may become large for small values of the optical depth, and for small solar zenith angles. In general, the various uncertainties that contribute to the error on are not negligible. In particular, for large values of solar zenith angle, the error on S may become relevant due to the reduction of the measured irradiances. Owing to the limited number of days when the Langley plot calibration was performed at Lampedusa, a relatively large systematic error could affect in low turbidity cases. This error may be as large as 30% at 868 nm (the channel with the best results of the Langley plot calibration), for 45 , and 0.05 (the smallest value of the measured optical depth throughout the campaign). For 0.2, the error becomes 7% in similar conditions. [ ] The aerosol lidar is able to measure the atmospheric backscattering proﬁles at 532 nm in the height region between 0.4 and 10 km in daylight conditions. A description of the instrumental setup and of the data retrieval procedure is given by di Sarra et al. [2001a]. In this paper the integrated backscattering IB , i.e., the integral of the backscattering coefﬁcient over height, is used as an indicator of the aerosol content of the atmosphere. [ ] During the campaign, cloudiness conditions were regularly noted. The cloudless periods identiﬁed on the basis of visual observations were later checked against the pyranometer signal: clouds are generally well identiﬁable in the pyranometer record, since the continuous signal shows a large shortterm variability. Aerosol layers vary at a slower rate, and have a smaller impact than clouds on the visible irradiance. After the comparison of the visual observation notes and of the pyranometer signals, only periods classiﬁed as cloud-free (i.e., with cloud-cover lower than 2/8, and no clouds close to the ing the lidar proﬁles. The lidar can detect optically thin clouds by generally showing a backscatter ratio larger than aerosol particles. All periods were discarded when signatures from clouds were present in the lidar proﬁles (also identiﬁed on the basis of the temporal variability and of depolarization ratio). In other words, only data collected in cloud-free intervals were retained and used in the following analyses. [ ] Figure 1 shows the time series of total ozone, aerosol integrated backscattering, aerosol optical depth at 415 and 868 nm, aerosol A˚ ngstro¨m exponent, and erythemal irradiance measured in cloud-free conditions at solar zenith angles of 20 and 40 . The total ozone daily averages are obtained from the Brewer observations; the daily total ozone measurement from the Total Ozone Mapping Spectrometer aboard the Earth Probe satellite, interpolated at 35.5 N, 12.5 E, is also shown for comparison. The average difference between the two total ozone measurements is smaller than 3 DU (about 1%). The integrated backscattering is obtained from the 30-min average 4 Evolution of (a) daily average total ozone from the Brewer spectrometer (open diamonds), daily total ozone from TOMS (pluses), and aerosol integrated backscattering (IB), calculated over the height region above 1 km (solid circles); (b) aerosol optical depth at 415 nm (open circles) and at 868 nm (solid circles), and aerosol A˚ ngstro¨m exponent (pluses); and (c) erythemally weighted irradiance at solar zenith angles of 20 (solid squares) and 40 (open squares). The data are relative to the period 6 May to 18 June 1999. Data for cloudy periods have been removed. lidar signals, and is calculated for the height region above 1 km; the contribution of clouds has been removed as described by di Sarra et al. [2001a]. The optical depths and the A ˚ ngstro¨m exponent are derived from the MFRSR observations and are the result of 18-minute averages. The erythemal irradiance is calculated from the Brewer spectra as previously described. [ ] Total ozone varies by about 40 DU around a mean value of approximately 330 DU, and the interval of variability is around 12%. IB varies between 0.0013 and 0.018 sr, at 415 nm between 0.14 and 0.97, and at 868 nm is between 0.05 and 0.86. The interval of variability is 90%, indicating that extremely different atmospheric aerosol conditions may occur. This extreme variability can be expected to produce signiﬁcant effects on the measured UV irradiances. [ ] Relatively large values of the A˚ ngstro¨m exponent, between 1 and 2, are derived for the low values of the aerosol optical depth; when large aerosol loads are detected, the A˚ ngstro¨m exponent is close to 0.5, as expected for relatively large 5 Range of Variability of the Ozone Optical Depth at Different Wavelengths particles. It is interesting to note the relationship between the IB and series. [ ] The behavior of the erythemal irradiance is mostly determined by the inﬂuence of total ozone. Large values of E generally occur at low total ozone amounts. However, signiﬁcant anomalies are present: the largest E is observed on 12–13 May, when the total ozone is around 315 DU. Lower values of the erythemal irradiance are found for 315 DU on 14 and 31 May, 1–3 June, and 6 –14 June. These anomalies are most likely due to changes of the aerosol content that contribute to the modulation of the erythemal irradiance. [ ] By using the values of the ozone absorption cross section measured by Molina and Molina [1986] and by Cacciani et al. [1989], the ozone optical depth may be estimated. The calculated values for the minimum and maximum total ozone ( , respectively) throughout the campaign are reported in Table 1. The aerosol optical depth at 415 and nm (sufﬁciently close to the ultraviolet spectral interval) is frequently larger than 0.3, i.e., aerosols are expected to play a role on the radiative transfer comparable or larger than that played by ozone for 320 nm. [ ] Figure 2 shows, for a selection of wavelengths, the behavior of the measured UV irradiance E versus total ozone for different values of . The irradiance progressively increases with wavelength, and decreases with . As expected, the effect of the ozone absorption appears at the short wavelengths. Linear ﬁts to the data have also been drawn, to illustrate the dependence of the irradiance on ozone. From these linear ﬁts, the RAF, deﬁned as RAF E E , (3) where E is the change of E , and is the total ozone change, has been calculated at 5 nm intervals. Madronich [1993] has proposed the use of a power law relationship for the deﬁnition of the RAF. By using the power law relationship very similar results are obtained from these data, as will be shown below, and we assume that the linear expression provides a satisfactory representation. [ ] In Figure 3 the behavior of RAF for different wavelengths and values of is shown. Surprisingly, a change of the sign of RAF appears at 315 nm, i.e., an increase of E Behavior of the UV irradiance at selected wavelengths and at different values of the solar zenith angle for cloud-free conditions versus total ozone. The solid and dashed curves are linear ﬁts to the data. Note the change of the vertical scale in the different graphs. 6 [ ] Where the ozone absorption is small, the RAF is expected to be close to or equal to zero. Thus it appears that the effect of the ozone, which is dominant for 315 nm, is overcome by the inﬂuence of other atmospheric parameters at longer wavelengths. This inﬂuence is also evident in the graphs of Figure 2. [ ] The data of Figure 1 show that large values of the optical depth and of the integrated backscattering occur when low total ozone is measured, and small values of and IB are recorded at high total ozone amounts. It has been shown by di Sarra et al. [2001a] that the aerosol transport from Africa to Lampedusa during PAUR II was dominated by the presence of a high-pressure system close to the island and generally centered over northern Libya. Obviously, large aerosol loads are measured in this case, due to the presence of large amounts of desert dust transported from the Sahara. The dust layer often reaches an altitude of 8 km. When the high pressure is located over western Algeria, the air reaching Lampedusa originates from the North Atlantic and Europe, and a much smaller aerosol load is observed. In these cases, aerosol is not detected at altitudes above 3 km. [ ] It is well known that a relationship between total ozone and weather exists: early ozone measurements showed that maximum ozone daily deviations occur over surface lowpressure systems, while maximum negative deviations are associated with surface high-pressure areas [ Dobson et al. , 1946]. Reed [1950] showed that this relationship is due to the effects of horizontal advection and to large-scale vertical motions. In particular, southward/northward transport of stratospheric air, from the polar ozone-rich region or the subtropical ozone-poor region, plays an important role. [ ] In this perspective, the variations of the total ozone over Lampedusa may be explained in terms of the wandering of the anticyclone over north Africa, that is associated with changes of the vertical structure of the stratosphere and transport of airmasses of different origin and ozone content. As previously explained, tropospheric aerosol transport also depends on surface pressure, and total ozone and tropospheric aerosol amounts are negatively correlated. The correlated behavior is evident in Figure 1, where large values of and IB occur only when is low, i.e., in mid May and during most of June. Around 10 May, and in the period 20 –29 May, large values of and small values of and IB are measured. [ ] Thus, tropospheric aerosols are very likely to affect the pendence of E on . In Figure 4 the observed values of E are plotted versus the aerosol optical depth at 415 nm, for various solar zenith angles. The lines in Figure 4 represent linear ﬁts to the data. Owing to the covariance of and , and to the dominating effect of the ozone at short wavelengths, an increase of E with appears for 315 nm. At 315 nm and at longer wavelengths the expected dependence of E on emerges. Since the inﬂuence of ozone decreases toward longer wavelengths, the spread of the data points with respect to the linear curves reduces for 310 nm. A similar picture is obtained when E is related to the aerosol optical depth at 868 nm. The slope at 315 nm is similar to that found by Wenny et al. [1998]. Their analysis indicated strong absorption by aerosols in central North Carolina. [ ] A simple analysis has been implemented to separate the effects of aerosols and ozone on E . A more general expression describing the dependence of the UV irradiance variability on both ozone and aerosol variability has been adopted: Behavior of the radiation ampliﬁcation factor (a) versus wavelength at different values of the solar zenith angle and (b) versus solar zenith angle, for 300, 305, and 310 nm. In Figure 3b the radiation ampliﬁcation factor has been calculated for a linear (solid lines) and a power law relationship (dashed lines). occurs for an increase of . At longer wavelengths a value of RAF smaller than 1 is derived for 60 . The values of RAF are moreover consistently lower than expected: Bais et al. [1993] obtained a linear radiation ampliﬁcation factor at difference of 40 DU. Bodhaine et al. [1996], using a power law relationship, calculated a RAF of about 4 at 300 nm, and somewhat larger than 1 at 310 nm. Fioletov et al. [1997] derived estimates of the irradiance increase associated with a 1% ozone increase from Brewer observations at seven stations for the period 1989 –1995; the increase at 300 nm is around 4% for 47.5 and 4.5% for 57.5 ; at 310 nm, the increase is 1% for 47.5 and 1.3% for 57.5 . Values of RAF , the radiation ampliﬁcation factor for the power law relationship between E and [ Madronich , 1993], have been calculated at 300, 305, and 310 nm. The obtained values are shown in Figure 3b, together with the linear RAF, as a function of . RAF is larger than RAF for all values of at 300 and 305 nm. However, signiﬁcant differences, up to 10%, are derived only for very large values of the radiation ampliﬁcation factor. RAF is generally increasing with , except at 300 nm; the behavior at this wavelength for large solar zenith angles is due to the Umkehr effect. 7 Behavior of the UV irradiance at selected wavelengths and at different values of the solar zenith angle, for cloud-free conditions, versus aerosol optical depth at 415 nm. The solid and dashed curves are linear ﬁts to the data. Note the change of the vertical scale in the different graphs. E E RAF S , (4) where S is deﬁned as the sensitivity of the irradiance on the aerosol optical depth, is the aerosol optical depth change, and RAF is the radiation ampliﬁcation factor for ozone taking into account the aerosol effects. Expression (4) is valid if ozone and aerosol act on the UV irradiance independently, and if linear relationships are assumed between E and and E [ ] In reality, the enhancement of the scattering of UV radiation due to the presence of aerosols, by increasing the length of the photon paths through the atmosphere, is expected to produce additional absorption by ozone. This effect is believed to be small, because of the relatively low concentration of tropospheric ozone; it might become signiﬁcant for large solar zenith angles when a large fraction of the measured irradiance is due to diffuse radiation, and the photon path lengths become larger. [ ] As previously discussed, similar values of the radiation ampliﬁcation factor are obtained by using a linear and a power relationship, and we assume that the linear dependence provides a satisfactory description. At wavelengths where the 0, the ﬁrst term ozone absorption is negligibly small RAF on the right side of the equation may be neglected. The variations of E may be consequently explained in terms of changes of only. As it appears in Figure 4, a linear relationship seems to describe dependence of E on reasonably well at these wavelengths ( 320 nm). The linear correlation coefﬁcients r between E and are reported in Table 2 for a selection of wavelengths, together with the number of data points for each solar zenith angle. At these wavelengths the values of r are always much larger than the squared linear correlation coefﬁcients achievable with a level of conﬁdence of 0.001 from a noncorrelated dataset. Thus we assume that the linear relationship provides a sufﬁciently good description of the dependence of E on , even though the interval of variability of is expressing the relative changes of E and in terms of a linear sensitivity, as in expression (4). [ ] Where RAF 0, S has been derived from expression (4). The values of are calculated with respect to the average optical depth calculated for the set of values observed at each solar zenith angle. We have calculated S at 5 nm steps, for 340 nm; at 340 nm the estimated optical depth of ozone is around 0.015, and the effect of its variations on the UV irradiance is considered negligible with respect to the aerosol (see Table 1). At longer wavelengths the ozone optical depth is progressively smaller, and its effect may also be neglected. In Figure 5 the average S , obtained by averaging the results at each , is depicted as a function of . The standard deviation of the average is also shown. The average S progressively increases with from 20 to 60 , and decreases from 60 to 70 ; its value is 0.1, i.e. much smaller than the estimates of RAF for 310 nm. By calculating the S from the linear ﬁts 8 Correlation Coefﬁcients r Between the Irradiance and the Optical Depth at 415 nm for the Indicated Values of the Wavelength and of the Solar Zenith Angle between E and the aerosol optical depth at 868 nm, smaller values than those derived for at 415 nm are obtained. These values are also shown in Figure 5. [ ] From the values of S it is possible to estimate the percent reduction of irradiance per unit aerosol optical depth at 415 nm. In Table 3 the average percent reduction for the wavelength interval 340 –360 nm, and the standard deviation of the average, is reported for different solar zenith angles. The reduction increases with , reaching values larger than 50% at 70 . For 20 , the reduction is about 30%. Since the linear relationship gives a good description of the dependence of the UV irradiance on , the percent reduction may be scaled to different values of the optical depth. [ ] In the previous analyses we have not attempted to identify different aerosol types, and all the cloud-free data have been considered. A main distinction between the two aerosol types is proposed: during the desert dust events, Saharan aerosol is largely dominant over the different particle types. In other periods a mixture of marine and continental aerosols is normally expected over Lampedusa. The continental aerosol particles mainly originate from Europe, and their properties are modiﬁed while traveling over the sea. [ ] With the aim of characterizing the effects of the Saharan dust aerosols, a reduced set of cases has been selected. The selection has been based on the isentropic backward trajectories, as outlined in di Sarra et al. [2001a]. The trajectories ending at Lampedusa on the days of the campaign are grouped in four separate classes, depending on the path followed by the air parcels. [ ] We have included in class a all the trajectories that do not pass over Africa; in these cases, the air masses generally originate in the North Atlantic, and travel over western Europe. Class b contains the trajectories that marginally overpass Africa. The trajectories that spend the last few days over northwestern Africa, over the Atlas Mountains and Morocco, Algeria, Tunisia, are included in class c. The trajectories that originate in central Sahara, and have spent a consistent fraction of the last 10 days over the desert are classiﬁed as class d. For the following analyses, only the days when the trajectories ending at Lampedusa between 3 and 4 km belonging to classes c and Average S , the sensitivity of the irradiance on the aerosol optical depth (see text), versus solar zenith angle. The standard deviation of the average is also indicated. S has been estimated from all the cloud-free measurements, and from the aerosol optical depth at 868 nm (solid circles), and at 415 nm (open squares), and from the desert dust cases only, for aerosol optical depth at 868 (solid triangles) and at 415 nm (open triangles). 9 Percent Reduction R (Average Over the 340-360 nm Spectral Interval) of the Ultraviolet Irradiance per Unit Increment of the Aerosol Optical Depth at 415 nm d, have been selected. In these cases the desert dust is the dominant component of the atmospheric aerosols. The lidar observations have shown that the aerosol distribution strongly depends on the origin of the airmasses: the aerosol is generally conﬁned below an altitude of 3 km for the class a proﬁles, while it reaches 7– 8 km for the conditions of classes b, c, and d. The different aerosol proﬁles are shown by di Sarra et al. [2001a]. [ ] The values of S have been also calculated for the Saharan dust subset, for the optical depth at 415 and 868 nm. The averages of S for the desert aerosol subset are also reported in Figure 5. The values of S for the reduced data set are signiﬁcantly larger, by 0.05– 0.1, than those previously obtained. The desert dust subset comprises only large values of the optical depth. As will be discussed below, the differences between the values of S for the two classes of particles may be partly due to the non homogeneity of the optical depth values in the different datasets, as well as to differences in the microphysical properties, composition, and vertical distribution of the aerosols. [ ] The average value of S (calculated over the entire data set), not dependent on wavelength, has been used to derive an estimate of RAF , by ﬁtting equation (4) to the data shown in Figures 2 and 4. The use of a S that does not depend on wavelength introduces a systematic error in the calculations. However, the wavelength dependence of is not large compared to the dependence of ozone absorption; as shown in Figure 1, the A˚ ngstro¨m exponent is smaller than 1 for most of the observations, and is smaller than 0.5 for the large values of that correspond to desert dust events. Consequently, we assume that the wavelength variability of S may be neglected [ ] In Figure 6 the obtained values of RAF are plotted vs. wavelength and solar zenith angle. The values of RAF are substantially larger than RAF, the radiation ampliﬁcation factor for ozone estimated without aerosol correction (see by comparison Figure 3). The differences between RAF and RAF are smallest, around 0.5, for low values of ; differences up to 1 are found at large solar zenith angles. The peak of the radiation ampliﬁcation factor at 300 nm is now found at 60 , instead of 50 . Values of RAF are in good agreement with the radiation ampliﬁcation factors reported in the literature [ Bais et al. , 1993; Bodhaine et al. , 1996; Fioletov et al. , 1997]. It is interesting to note that RAF is close to zero for 330 nm, as expected, for all solar zenith angles. The bias on RAF due to the assumption of a S which is not dependent on appears negligible for 330 nm and could produce an underestimate of the real radiation ampliﬁcation factor at short wavelengths. [ ] To highlight the role of the different aerosol types, the behavior of the UV irradiance at 360 nm, for different values of , versus the aerosol optical depth at 415 nm for the desert dust cases, is shown in Figure 7. These cases correspond to large values of , generally 0.2. As in Figure 4, linear curves have been ﬁtted to the data. The solid lines represent linear ﬁts for the dataset that includes only the desert dust cases; the dashed lines are the linear ﬁts derived for the whole data set, and previously shown in Figure 4. A change of the slope appears for the desert dust case, mostly for solar zenith angles between 30 and 50 . The general case groups together continental/marine aerosols and desert dust. These two aerosol classes are characterized by signiﬁcant differences in the aerosol properties: the optical depth is generally smaller for the continental/marine aerosols than for the desert dust, the particle dimensions are different, as shown by the changes of the A˚ ngstro¨m exponent (see Figure 1), and their compositions (and refractive indices) are expected to differ. It appears from Figure 7 that, for low values of the optical depth, continental/ marine aerosols produce a larger attenuation on the global irradiance than desert dust. [ ] This effect may be due to differences in the wavelength dependence of . For a given value of at 415 nm the optical depth at 360 nm is 1.24 times larger for aerosols characterized by an A˚ ngstro¨m exponent of 2, than for aerosols whose A˚ ngstro¨m exponent is 0.5. As results from Figure 1, low values of are generally associated with high values of the A˚ ngstro¨m exponent, and the enhancement of from 415 to 360 nm is comparatively larger. [ ] The behavior of the A˚ ngstro¨m exponent however does not explain the dependence on the solar zenith angle. This dependence may be attributed to the role of direct and diffuse irradiance and to the scattering geometry, under the assumption that the different slopes of the ﬁtting lines are due to differences in the single scattering albedo, and/or in the scattering phase function between the two classes of particles. At low solar zenith angles the irradiance is mostly dominated by the direct component, and the attenuation of the irradiance depends mainly on the value of the vertically integrated : in this case, a small change of the slope of the linear ﬁt is expected, as it appears in Figure 7. At high the diffuse radiation is dominant and the solar radiation is essentially scattered downward by an atmospheric layer that is above the aerosol cloud. Consequently, the measured irradiance becomes less sensitive to changes in the aerosol distribution and properties, and depends mainly on . Conversely, in the 30 –50 range of sol vertical distribution and properties, producing a different behavior for different classes of particles. [ ] To investigate the inﬂuence of aerosols on the erythemally weighted irradiance E , the following analysis has been carried out. By using the estimates of E derived from the Brewer observations and the measurements of , the erythemal radiation ampliﬁcation factor, RAF , has been derived without considering the effect of the aerosols. Then, a radiation ampliﬁcation factor for the case in which the aerosol effect has been taken into account by means of expression (4), RAF , has been calculated. The same values of S used previously have been assumed. In Figure 8 the behavior of the RAF (dashed curve) and of different estimates of RAF (solid curves) are shown. The solid circles identify the estimate of RAF obtained by using the aerosol optical depth at 868 nm, and the whole data set (all aerosol types). The squares are derived by using at 415 nm, and the the whole data set. The solid triangles and the open triangles are relative to the re10 Behavior of RAF , the ozone radiation ampliﬁcation factor, corrected for the inﬂuence of the aerosols, (a) versus wavelength at different values of the solar zenith angle and (b) versus solar zenith angle. duced dataset (desert dust cases), for at 868 and 415 nm, respectively. The values of S shown in Figure 5 for the different cases have been accordingly used in expression (4). It must be mentioned that the estimates of RAF for the desert dust cases are obtained from a dataset that is comprised of limited ozone variability, 20 –30 DU; as it appears in Figure 1, is generally about 300 DU during the dust events. As expected, the aerosol produces a considerable effect on the estimates of the erythemal radiation ampliﬁcation factor. RAF is larger than RAF by 0.4 –1, the difference increasing with . The obtained values of RAF are consistent with the erythemal radiation ampliﬁcation factors reported in the literature: DeLuisi and Harris [1983] derived values in the range 1.24 –1.26 from observations at 60 ; McKenzie et al. [1991] found a linear radiation ampliﬁcation factor around 1.25; Kerr and McElroy [1993] derived values between 1.1 and 1.3, depending on the season; Bodhaine et al. [1996], by using the power law relationship, obtained radiation ampliﬁcation factors between 1.25 and 1.44 at 45 . Somewhat smaller values, between 0.7 and 1.2 depending on , have been derived by Dubrovsky´ [2000]. Radiation ampliﬁcation factor for erythema derived by means of radiative transfer modeling are in the same range of values [e.g., Madronich and Flocke , 1997]. [ ] The erythemal radiation ampliﬁcation factor has been also derived from radiative transfer model [ Mayer et al. , 1997] estimates of the surface spectral irradiance at 30 and 60 solar zenith angle, by varying the total ozone between 300 and 380 DU. The aerosol optical depth and the atmospheric pressure have been kept constant. An aerosol layer of marine aerosols below 2 km, with a visibility of 23 km, has been assumed. The values of the erythemal radiation ampliﬁcation factor estimated from the model by means of a linear relationship and of a power law agree within less than 0.01. [ ] The erythemal RAF calculated from the model is 11 Behavior of the irradiance at 360 nm for different values of the solar zenith angle, against the aerosol optical depth at 415 nm. Only the data points which correspond to cases dominated by the desert dust are plotted. The solid curves are linear ﬁts to the data. The dashed curves are the linear ﬁts obtained by including all the data set. slightly larger than the RAFs derived by means of expression (4). This effect may be attributed to a wavelength dependence of the aerosol sensitivity, that has been neglected in the previous analyses, and to a interdependence between ozone and aerosol, possibly through increased ozone absorption following enhanced scattering by aerosols. However, the erythemal RAF depends also on the ozone vertical proﬁle (tropospheric and stratospheric ozone affect the UV irradiance differently, due to different scattering regimes and to the temperature dependence of the ozone absorption cross section). In the analysis leading to the determination of the radiation ampliﬁcation factor we have grouped together measurements carried out in very different atmospheric conditions (aerosol, total ozone, ozone vertical distribution). Consequently, we cannot expect a close correspondence between the values derived from the observations and those calculated by the model. In the followErythemal radiation ampliﬁcation factor for ozone changes, not corrected (dashed line) and corrected (solid lines) for the inﬂuence of the aerosols, versus solar zenith angle. The line identiﬁed with the solid circles is derived from all the measurements, and the aerosol correction is made with respect to the optical depth at 868 nm. The curve with the open squares is corrected for the optical depth at 415 nm, and all the measurements are included. The other two solid curves are obtained considering only the cases dominated by the desert dust, with corrections for the optical depth at 868 (solid triangles) and 415 nm (open triangles). The stars indicate the radiation ampliﬁcation factors calculated by means of a radiative transfer model. 12 Behavior of the erythemal irradiance, corrected for total ozone changes (see text), at 30 and 60 solar zenith angle, against the aerosol optical depth at 415 nm. The solid curves are linear ﬁts to the data. ing analysis aimed at estimating the role played by aerosols on the attenuation of the erythemal irradiance, we assume that the ozone effect on the erythemal UV is well represented by the results of the model. By using the model-derived erythemal RAF we have corrected the measured values of E for the ozone changes only by estimating the erythemal irradiance at 340 DU, E . In this way we have removed the ozone dependence of E , and may attribute its residual variability to the aerosols. In Figure 9, E is plotted against the aerosol optical depth at 415 nm, for solar zenith angles of 30 and 60 . A linear curve has been ﬁt to the data. As expected, aerosols signiﬁcantly affect the erythemal irradiance: the reduction of erythemal irradiance per unit optical depth at 415 nm is about 50% at 30 , and about 55% at 60 solar zenith angle. [ ] To investigate the role played by the aerosol vertical distribution on the surface UV irradiance, we have studied the dependence of E at 330 nm on the lidar-derived backscattering, integrated over different vertical intervals, and on the average altitude of the aerosol cloud, weighted by the backscattering coefﬁcient, z . The value of z provides an indication di Sarra et al. [2001a], z is always above 2.5 km during the desert dust transport events. [ ] In Table 4 the correlation coefﬁcients r of the linear regression between these quantities are reported. Largest values of r are obtained for IB integrated over the whole aerosol cloud (above 1 km) and, surprisingly, for the integrated backscattering over the altitude interval between 5 and 6 km. A weak correlation is found with IB over the 1–2 km region, and with z . The weak dependence on z seems to suggest that changes of the vertical distribution of the aerosol cloud produce a relatively small impact on the surface irradiance. However, z does not depend on the value of the aerosol optical depth, which is the dominant parameter, and the effect of the altitude distribution of the aerosol may be difﬁcult to extract in the presence of the large variability of . E appears to be mostly controlled by the total aerosol load over the column, as suggested by the good correlation with IB integrated over the column. It may be speculated that a good correlation is found with IB over the region between 5 and 6 km because this quantity is a good indicator of the presence of desert dust. A more detailed investigation is however needed to accurately address this topic. [ ] Minima of the correlation coefﬁcient are found for 20 , while maxima occur for 60 . A smoothing of the slant path of the direct radiation at large solar zenith angles, may partly explain the observed dependence of the correlation on . The presence of a diurnal evolution of the aerosol properties may also contribute to this. Correlation Coefﬁcients r Between the Irradiance at 330 nm and the Indicated Parameters for the Indicated Values of the Solar Zenith angle 13 [ ] Simultaneous measurements of aerosol properties, total ozone, and spectral ultraviolet irradiance were performed during the PAUR II campaign at Lampedusa, in the Mediterranean. Aerosol optical depth and total ozone were negatively correlated. This effect is due to the inﬂuence of tropospheric pressure systems on the transport patterns that regulate the propagation of desert dust to the southern Mediterranean, and to the relationship linking total ozone to surface pressure caused by tropopause vertical motions and stratospheric advection of ozone-poor and ozone-rich air. [ ] A marked dependence of the UV irradiance on the aerosol optical depth appears; this effect competes with the ozone absorption, due to the anti correlated behavior of the two quantities, and is larger than ozone absorption at wavelengths longer than 315 nm. The presence of tropospheric aerosols, and mainly of desert particles from Sahara strongly affects the UV irradiance-ozone dependence. A signiﬁcant reduction of the radiation ampliﬁcation factor with respect to expected values occurs. This reduction, due to the aerosol inﬂuence, is as large as 1, and is observed also for the radiation ampliﬁcation factor for the erythemally weighted irradiance. [ ] The attenuation of the UV irradiance near 350 nm per unit aerosol optical depth at 415 nm, has been estimated; the reduction is between 30 and 54%, depending on the solar zenith angle. For the same optical depth a reduction of the erythemal irradiance by 50 and 55% is estimated at 30 and 60 solar zenith angles, respectively, by assuming the dependence of the UV irradiance on total ozone calculated by means of a radiative transfer model. [ ] A simple method to correct for the aerosol inﬂuence has been developed, and applied to the observations. The radiation ampliﬁcation factors that were estimated after correction are in agreement with those reported in the literature. [ ] These results indicate that tropospheric aerosols, and desert dust in particular, may signiﬁcantly affect the propagation of the UV radiation through the atmosphere. In speciﬁc regions where large aerosol variations can occur and are often dependent on meterological parameters (or show a seasonal evolution or a long-term change), the effect on the UV (and visible) irradiance should not be neglected. In particular, longterm predictions of the UV irradiance behavior should take into account the important role of aerosols. [ ] STOP CONTENT EXTRACTION HERE IN THE NAME OF GOD
test_npjclisci.pickle ---------- ['Projection of temperature-related mortality among the elderly under advanced aging and climate change scenario']
Advanced aging is expected to become a major social problem in China during the second half of the 21st century. Current projections of temperature-related mortality in the context of advanced aging are inadequate, and may underestimate the risks posed by global warming on people aged 90 years. The present study addresses this issue in Nantong City, which was the city in China with the highest aging and advanced aging rates in the 2000, 2010, and 2020 population censuses. Based on 27 global climate models from the Coupled Model Intercomparison Project Phase 6 and statistical downscaling methods, the impacts of climate change and advanced aging on future temperature-related elderly mortality were explored. Our results indicate that global warming will continue to increase the proportion of people who die from non-optimal temperatures even without considering the impact of advanced aging. Moreover, a higher warming range led to a more signi ﬁ cant increase in net-temperature-related mortality and advanced aging is likely to increase heat-related mortality and offset the decline in cold-related mortality. Our study demonstrates a 1 1 > 2 effect between advanced aging and climate change, under the four shared socioeconomic pathway climate change scenarios considered here. These ﬁ ndings contribute to a better understanding of the impact of climate change on elderly health and facilitate the development of more effective adaptive strategies for advanced aging societies. few studies have examined the effects of Global climate change and population aging are two prominent and interlinked concerns of the 21st century . The >1.2 °C global warming relative to preindustrial temperature, which has been driven by human activity , is a recognised challenge to public health. Climate change s direct (e.g., rising global temperatures have signi ﬁ cant impacts on mortality, morbidity, and injury) and indirect (e.g., disturbance of social processes and ecosystem changes) effects pose immediate or deferred health risks to the human population . Several Studies have projected future temperature-related mortality under climate change, either at the city or national and global levels, based mainly on the increase in heat-related deaths caused by global warming. Contrastingly, low temperatures, particularly the interaction between cold and advanced aging (i.e., the increase in the proportion of people over 80 years), primarily because the frequency of low temperatures is expected to decrease in the future. However, the risks imposed by cold and heat do not increase equally with age. According to Global Burden of Disease (GBD) 2019 data (https:// vizhub.healthdat.org/gbd-compare/), low temperatures accounted for a higher percentage of global noncommunicable deaths due to disease than high temperatures, with older age groups at a much higher risk of cold-related deaths than heat-related deaths. Our previous study showed that people aged 70 74, 80 84, and 90 94 who died from cold-associated conditions were at higher risk (2.75-, 4.84-, and 6.54-times, respectively) than those who died from heat-associated conditions . These results indicated that the effect of cold temperatures does not necessarily weaken with aging. Therefore, ignoring the effect of the cold temperatures on the trend of advanced aging could lead to severe public health consequences. Global population aging is accelerating because of declining fertility rates and increased life expectancy. According to the United Nations World Population Outlook 2022, the proportion of elderly individuals will increase globally by 60% from 2022 to 2050. China, for instance, became a moderately aging society in 2021 (aging rate 14%) and is estimated to become a severely aging society (aging rate 21%) by 2035, encompassing more than 400 million elderly people. Demographers predict that the aging rate and size of China s elderly population will continue to rise until 2055 and then stabilise. However, China s population over 80 years of age will continue to grow after 2055, remaining above 120 million from 2055 to 2100, i.e., 3 4 times higher than the 35.8 million registered in 2020, which accounted for 18.8% of the aging population. Under the medium-pace life expectancy growth scenario, this proportion is expected to be 24.2%, 35.6%, 40.0%, and 51.3% in 2040, 2060, 2080, and 2100, respectively. Advanced aging will thus become a substantial demographic issue in China in the second half of the 21st century. Aging plays a critical role in increasing temperature-related deaths . Yang et al. (2021) estimated 128,000 and 229,000 heat-related deaths in China in the 2090s under the RCP4.5 and RCP8.5 emission scenarios, respectively, with no changes in population demographics. However, these numbers increased to 361,000 and 654,000, respectively, under the average of the six population scenarios . Another study found that aging in Beijing would result in a 49 326% increase in temperature-related deaths due to cardiovascular disease in the future, which is the most prominent disadvantage in tackling climate change . Although population aging has been included in some studies focusing on the effects climate change may exert on mortality rates, none has considered changes in the 80 and 90 years population groups, which are the most affected by non-optimal temperatures. Failure ﬁ to include the oldest-old as an independent group in health risk projections related to climate change may therefore lead to a signi ﬁ cant underestimation of health risks. The present study aimed to provide a comprehensive understanding of the dependent and interactive effects of climate change and advanced aging on heat, cold, and net-temperaturerelated deaths among the elderly in China s most heavily aging cities. Speci ﬁ cally, the present study projected these effects under 27 global climate models included in the Coupled Model Intercomparison Project Phase 6 (CMIP6) and four emission scenarios. Figure 1 displays the historical exposure-response relationship between temperature and the elderly population in different age groups. Speci ﬁ cally, the minimum mortality temperature (MMT) for the elderly population in Nantong increased with age. For the elderly aged 65 79, 80 89, and 90 , the MMT was 24, 25, and 26 °C, respectively. In comparison to MMT, the mortality risk (relative risk, RR) at the 2.5th percentile (1 °C) for the same age groups was 1.280 (95% con ﬁ dence interval (CI):1.209 1.355), 1.708 (95% CI:1.583 1.844) and 2.217 (95% CI:1.981 2.480), respectively, and that at the 97.5th percentile (31 °C) was 1.192 (95% CI:1.139 1.246), 1.340 (95% CI:1.283 1.399), and 1.492 (95% CI:1.402 1.588), respectively. The temperature mortality associations were similar when we used 10 21 maximum lag days for temperature, 4 6 df for relative humidity, and 4 8 df for air pollutants (Supplementary Figs. 1 4). ﬁ Figure 2 presents an overview of the changes in the annual average temperature and frequency of extremely high temperatures in Nantong under four different climate change scenarios from 1961 to 2100. The shared socioeconomic pathway (SSP) scenarios SSP1-2.6, SSP2-4.5, and SSP3-7.0 scenarios demonstrate similar temperature increases before 2050, with projected annual average temperatures during 2041 2050 being 2.28, 2.27, and 2.24 °C higher than that during 1961 2000 (15.9 °C), respectively. However, temperature increases under these scenarios after 2050 exhibit signi ﬁ cant differences. Hence, during 2091 2100, projected annual average temperatures are 2.51, 3.67, and 4.98 °C the highest higher than those during 1961 2000. Under i.e., SSP5-8.5, average annual temperature increase scenario, temperatures during 2041 2050 and 2091 2100 are estimated to be 2.78 and 6.51 °C higher than that during 1961 2000, respectively. The annual frequency of extremely high temperatures (i.e., above 31 °C) estimated under the four scenarios showed a similar trend to the average annual temperature. Speci ﬁ cally, under SSP1-2.6, SSP2-4.5, SSP3-7.0, and SSP5-8.5, the annual frequency of extremely high temperatures during 2041 2050 is predicted to increase by 18.1, 17.8, 17.7, and 23.9 days, respectively, which are much higher values than the 6.6 days baseline of 1961 2000. More extended periods of extremely high temperatures are anticipated during 2091 2100, with increases of 22.2, 38.3, 56.8, and 80.2 days under the SSP1-2.6, SSP2-4.5, SSP37.0, and SSP5-8.5 scenarios, respectively, when compared to the baseline period. Figure 3 presents a projection of the age-speci ﬁ c number of deaths under ﬁ ve United Nations life expectancy models. The number of deaths among people aged 65 79 years will decrease steadily after 2040. In contrast, the number of deaths among those aged 80 89 and 90 years is projected to continue to increase. After 2055, the 90 years age group is expected to become the one with the highest number of deaths. Supplementary Fig. 5 presents a detailed projection for the age-speci ﬁ c number of deaths under the medium-pace life expectancy growth scenario and nine United Nations model life tables. Figure 4 shows the changes in the population-attributable fraction (PAF) of heat-, cold-, and net(heat and cold) temperature-related excess mortality under four climate change models, assuming no population changes. Under scenarios SSP2-4.5, SSP3-7.0, and SSP5-8.5, the PAF of cold exhibits a continuous decrease whereas that of heat shows a continuous increase. Interestingly, under SSP1-2.6, the PAF of cold and heat remains stable after 2050, and under SSP1-2.6 and SSP2-4.5, the PAF of heat will not surpass that of cold until 2100. However, under SSP3-7.0 and SSP5-8.5, the PAF of heat will exceed that of cold in the 2090s and the 2060s, respectively. The net PAF will continue to increase, with increase by projections indicating that 2.64%, 6.39%, 13.57%, and 29.46% compared to 2010 2019 values, under the SSP1-2.6, SSP2-4.5, SSP3-7.0, and SSP5-8.5 scenarios, respectively. in 2080 2089 it will Figure 5 shows the age-speci ﬁ c changes in the heat-, cold-, and net-temperature-related PAF under the four SSPs, assuming no ﬁ population changes. Interestingly, the time at which the PAF of heat exceeded that of cold occurred later in older age groups. For instance, under SSP5-8.5, the PAF of heat is expected to surpass that of cold during 2040 2049 in the 65 79 years age group, during 2060 2069 in the 80 89 years age group, and during 2070 2079 in the 90 years age group. The net PAF will continue to increase across all age groups. For instance, the projected net PAF of 65 79, 80 89, and 90 years age groups under SSP5-8.5 during 2080 2089 is estimated to be 11.67 (95% CI: 8.78 14.75), 19.63 (95% CI: 15.93 23.95), and 25.90 (95% CI: 20.58 31.78), respectively, which are 1.50, 1.23, and 1.23 times higher than the corresponding values observed during 2010 2019. Figure 6 presents a holistic evaluation of the interactive effects of climate change and advanced aging on future temperature-related excess mortality rates. Overall, the net-temperature PAF increased under all four climate change scenarios and advanced population aging. Speci ﬁ cally, net-temperature-related excess mortality under SSP1-2.6, SSP2-4.5, SSP3-7.0, and SSP5-8.5 scenarios assuming no population 13.86% (95% CI: estimated 11.39 16.25%), 14.30% (95% CI: 11.46 17.03%), 15.27% (95% CI: 12.13 19.38%), and 17.35% (95% CI: 13.94 21.42%), respectively, during 2080 2089. However, when advanced aging is considered, net-temperature-related excess mortality is estimated to increase changes at is 14.80 21.62%), 18.30% (95% CI: 18.77% (95% CI: to 14.95 22.47%), 19.86% (95% CI: 15.59 24.79%), and 22.05% (95% CI: 17.62 27.00%), respectively, during the same period. In addition, advanced aging is expected to increase the risk of nettemperature-related excessive mortality. Under the SSP1-2.6, SSP24.5, SSP3-7.0, and SSP5-8.5 scenarios, the risk of net-temperature PAF is estimated to be 1.33-, 1.37-, 1.44-, and 1.62-times higher in 2080 2089 than in 2020 2029, respectively, whereas the risk was only 1.03, 1.07, 1.13, and 1.31 when advanced aging was not considered. Advanced aging is also expected to considerably In fact, weaken the decline of cold-related excessive mortality. under SSP1-2.6, SSP2-4.5, and SSP3-7.0 scenarios, cold-related excessive mortality might increase during 2020 2089, 2020 2069, and 2020 2059, respectively. The time at which the heat PAF exceeds cold PAF is estimated to occur later when advanced aging is considered. These ﬁ ndings emphasise the critical importance of identifying effective adaptation strategies to mitigate the risks of climate change-induced temperature-related excessive mortality, particularly in the elderly population. Table 1 presents a comparative analysis of PAF changes when considering the interactive effects of climate change and advanced aging or assuming their independent effects. The scenario assuming no climate change (independent effect of advanced aging) indicates that the temperature-related PAF will increase by approximately 30% by the end of the 21st century compared to ﬁ 2010 2019. On the other hand, assuming no population changes (independent effect of climate change), the temperature-related PAF is expected to increase by 1.87% (SSP1-2.6) to 39.29% (SSP58.5) at the end of the 21st century compared to 2010 2019. However, the combined effect of advanced aging and climate change was greater than the sum of their independent effects, particularly under heat-related PAF under the SSP2-4.5, SSP3-7.0, and SSP5-8.5 scenarios. Similarly, cold-related PAF increased in most periods under the SSP1-2.6 and SSP2-4.5 scenarios. The present study estimated an increase in net-temperaturerelated PAF in Nantong, China, by decade and under all four climate change scenarios considered; this trend will be strengthened by advanced aging. Our ﬁ ndings indicate that advanced aging and climate change will increase heat-related mortality and reverse the declining trend in cold-related mortality. In Nantong, climate change is projected to lead to a continuous increase in the proportion of mortality attributable to non-optimal temperatures, under the assumption of no changes in population demographics. This is because climate change is associated with a decrease in moderately low temperatures (low RR) and an increase in extremely high temperatures (high RR), as indicated in Supplementary Table 1. Although the incidence of heat-related excess mortality is expected to rise globally in the future , it remains unclear whether climate change will result in positive or negative net annual mortality related to temperature. A study ﬁ the net lead to a net In Beijing, China, conducted across 23 countries revealed that climate change generally increases the mortality rate associated with non-optimal temperatures; however, the results also demonstrated signi ﬁ cant regional disparities . annual temperature-related ischaemic stroke deaths were projected to surge by nearly 100% by the 2080s compared to the 1980s, regardless of population changes, under the RCP8.5 scenario . Similarly, research has revealed that climate change in Tianjin, China, will increase in deaths resulting from cardiovascular diseases attributable to temperature and that the increase in heat-related mortality will be higher than the decrease in cold-related mortality . A study conducted in New York, United States (US), revealed that climate change is expected to lead to positive annual net mortality related to temperature . Under the higher-emission RCP8.5 scenario, eight of the ten metropolitan areas in the US are expected to experience a net increase in temperature-related deaths per million people by 2086 2095 . Conversely, studies conducted in 28 cities in the US suggested that climate change will reduce the burden of temperature-related diseases and mortality . In Brisbane and Sydney, Australia, net annual temperature-related deaths are expected to increase in the future, whereas a slight decrease will occur in Melbourne . The present study s ﬁ ndings are consistent with these previous conclusions, wherein most regions across the world had their minimum temperature-related mortality located within the 70 90% local temperature percentile, and the range of high temperatures was narrower than that of low temperatures . However, the relationship between temperature and mortality is affected by various social factors, such as the region s development and economic performance, urbanisation rate, population age structure, central heating, and usage of air conditioning , changes the magnitude of all contributing to different temperature mortality curves across regions and diseases. Furthermore, the temperature increase varies among world regions, resulting in different net-temperature-related mortality across them . A study on 15 diseases in Ningbo, China, projected a decline in deaths resulting from ten of those diseases, represented by chronic lower respiratory diseases, and an increase in deaths resulting from the other ﬁ ve diseases, represented by ischaemic heart disease, attributed to climate change . In addition, whether the PAF of heat exceeds that of cold remains uncertain and depends on several factors that vary among regions, age groups, and causes of death. Research in the United Kingdom (UK) has shown that the number of people dying from low temperatureassociated causes is expected to be 13.0, 5.8, and 2.9 times higher than those dying from high temperature-associated causes in 2020, 2050, and 2080, respectively . Similarly, the present study found that the PAF of cold and heat is expected to vary among the different climate and population change scenarios analysed. This study examined the impact of advanced aging on the risk of climate change, particularly in people aged 90 years. Although the proportion of the oldest old is growing slowly, this growth rate will accelerate every year, becoming a serious social issue after 2050 in China and in Nantong City in particular. The 2050 2100 period is expected to be of intense warming under most climate-change scenarios. The present study found that advanced aging magni ﬁ es heat-related mortality, and that the interactive effect of heat and advanced aging is even higher than the sum of their independent effects. Additionally, advanced aging has an adverse effect on the declining trend of cold-related mortality, which has not been identi ﬁ ed in previous studies. Previous research has shown that aging increases the risk of heatﬁ ﬁ related mortality owing to climate change. For instance, aging will aggravate the risk of heat-related mortality in Guangzhou, China, and every 1% increase in the proportion of the elderly population will increase heat-related years of life lost (YLLs) by 420 in the 2030s . Taking aging into account, the mortality from cardiovascular diseases in Beijing is expected to rise by 16.6%, 73.8%, and 134.0% in 2020, 2050, and 2080, the RCP8.5 scenario . Aging is also expected to lead to an increase in heat-related YLLs due to cardiovascular diseases in Ningbo, China, in the 2050s and 2070s . Research in the UK has shown that climate change has a signi ﬁ cant impact on coldand heatrelated deaths among the elderly. Heat-related deaths are expected to increase sharply in the second half of the 21st century, whereas cold-related deaths will likely not decline signi ﬁ cantly. A study in South Korea has found that regardless respectively, under of aging, temperature-related mortality in the 2090s is expected to be 0.5 1.5 times higher than that in 1992 2010, but it will experience a 4 6 times increase when considering population demographic changes . One review has shown that the elderly are particularly sensitive to climate change . Hence, advanced aging should be considered as a potentially in ﬂ uencing factor, especially after 2055, when people aged 90 years are estimated to stand the largest mortality. According to national population censuses in China, the number of deaths in people over 80 years old accounted for an increasing percentage (14.8% in 1990 to 38.5% in 2020) of total deaths, and people aged 80 89 years and 90 years are expected to become the groups sustaining the highest mortality during 2030 2060 and 2060 2100, respectively. This will lead to an inevitable increase in the excessive mortality attributable to non-optimal temperatures, and not accounting for ﬁ the different mortality rate of people in these age groups will underestimate the public health consequences of climate change. The results obtained in the present study have several major environmental and public health implications. First, irrespective of advanced aging, the net-temperature-related PAF will increase with increasing global warming, and it is urgent for governments worldwide to develop policies that eliminate greenhouse gas emissions to slow the pace of global warming. Second, coldrelated mortality will continue to increase, or at least not decline, owing to advanced aging, and ignoring the health risks of low temperatures will lead to serious public health consequences. local governments should play a positive role in Therefore, reducing the negative impact of cold on the aging population, especially in areas with high advanced aging rates. Third, our study revealed that advanced aging will increase temperature-related deaths among the elderly. Fourth, the time at which the PAF of heat exceeds that of cold varies among age groups and climate change scenarios, and people above 80 years of age will suffer more from cold-related mortality. Therefore, it is crucial to formulate both cold and heat prevention policies according to the local population structure and magnitude of warming. Overall, our ﬁ ndings provide valuable insights for policymakers to develop effective strategies for mitigating the impacts of climate change on public health and aging populations. further Our study had some limitations. First, population adaptation was not considered. Most previous studies have employed population adaptation scenarios where adaptation increases by a certain percentage per decade; however, the extent of this adaptation is uncertain and dif ﬁ cult to predict accurately . With economic development, and the increased use of air conditioning, people s adaptation to hot increasing urbanisation, the temperature exposure of and cold conditions will be strengthened . However, the lower frequency of moderate and extremely low temperatures expected in the future will weaken the people s adaptation to occasional extremely low temperatures . Second, new technologies such as wearable cooling equipment and new building materials may affect individuals and lead to discrepancies between the temperature measured by of ﬁ cial outdoor temperature stations and the temperature to which people are exposed to. Third, all air pollutants could potentially affect the association between temperature and mortality. For example, the concentration of ozone in many Chinese cities has increased in recent years and is positively associated with temperature. This could potentially confound the effects of global warming on mortality and should therefore be considered in future studies. Finally, the present study was conducted in a city located in a north subtropical region and thus the results obtained cannot be generalised to geographic areas with different climates and population characteristics. MMT in Nantong city is increasing with age, but we cannot discern if it is an occasional, local phenomenon, or a general one. A nationwide study in Spain found that MMT decreased with age but varied with population, climatic characteristics, and socioeconomic conditions . However, the underlying mechanisms require further investigation. The research area chosen for this study was Nantong City (121°E, 32°N), located in the northern subtropics, and recognised as the pioneer of an aging society in China. Based on the ﬁ fth, sixth, and seventh national population censuses conducted in 2000, 2010, and 2020, respectively, the proportion of people over 65 years of respectively. This means age in the total population of Nantong was 12.44%, 16.50%, and 22.67%, the city has persistently maintained its position as the city with the highest proportion of old people among 340 cities above the prefecture level in China. In 2010 and 2020, advanced aging rates in Nantong were 3.65% and 5.15%, respectively, ranking ﬁ rst among 340 cities nationwide. The signi ﬁ cant increase in advanced aging rates and the large elderly population (over 1.7 million people over 65 years old in 2020) make Nantong one of the most vulnerable areas to climate change-related health risks. . Daily all-causes mortality data from 1 January 2012 to 31 December 2017 were obtained from the Nantong Health Commission. The data were divided into three groups according to age: young-old (65 79 years, 105,746 records), middle-old (80 89 years, 108,623 records), and oldestold (90 years, 41,668 records). This study has been approved by the Ethics Committee of the Nantong University (No. 2022(05)). No participants were contacted, and data were analysed at an aggregate level. Temperature and humidity data for the same period were collected from the National Meteorological Data Sharing Service Network and air pollutants data were collected from a local air quality monitoring station. . Regarding demography, the scale and number of deaths of the elderly population in a particular region are predicted based on three key parameters: life is for future projections life table, and migration. The primary expectancy, model parameter life expectancy, which determines the number of deaths in different age groups. A higher life expectancy will result in fewer deaths in the young-old and more deaths in the oldest-old. The secondary parameter is the model life table, which represents the mortality rate at speci ﬁ c ages for a given life expectancy. For the present study, the seventh population census conducted in 2020 in Nantong was selected as the base population. Information regarding the age structure of In the base population is provided in Supplementary Table 2. Nantong, the life expectancy in 2020 was 79.58 years, as provided by the National Bureau of Statistics, which was 1.65 years higher than China s nationwide average life expectancy (77.93 years) in the same year. Migration was not included in the present study because Nantong City maintained a migration balance from 1990 to 2020, According to China s population censuses, the annual net migration rates in Nantong City during the last three decades 0.755% were (2010 2020), which are much lower than those in most cities in China. Ageand sex-speci ﬁ c mortality rates between 2021 and 2100 were calculated according to future life expectancy and the model life table. Five UN life expectancy growth models (very slow, slow pace, medium pace, fast, and very fast) were used in the present study, starting from the 2020 study. The results obtained from these are presented in Supplementary Table 3. Nine commonly used model life tables were adopted to calculate the annual age-speci ﬁ c population and the age-speci ﬁ c number of deaths from 2021 to 2100. Each model life table represents a distinct ageand sex-speci ﬁ c mortality rate within the same life 0.204% (2000 2010), 0.492% (1990 2000), expectancy and would lead to different age structures in the future. These included four Coale-Demeny regional model life tables for developed countries (East, West, South, and North) and ﬁ ve UN model life tables for developing countries (Latin, Chile, South Asia, General, and Far East). Calculations were as follows (1): , as determined by the predicted value of (1) refers to the mortality rate of the population aged in where year future life expectancy and the model life table; is the number of people represents the number of deaths in the aged in year ; and population aged in year . Population predictions were obtained using the PADIS-INT software (version 1.70), which is a widely used and recommended population prediction software by the UN Population Division. . The daily temperature prediction dataset for 1961 2100 under 27 General Circulation Models (GCMs, Supplementary Table 4) and four emission scenarios (SSP12.6, SSP2-4.5, SSP3-7.0, SSP5-8.5) provided by CMIP6 were selected. The NWAI-WG statistical downscaling model was used to downscale the GCMs monthly grid data of the corresponding national meteorological station (No. 58259) in Nantong City into daily data . The statistical downscaling model consisted of three main steps: spatial downscaling, bias correction, and temporal inverse distancedownscaling. Spatial downscaling involves weighted interpolation based on the centre of the nearest four grid points in the GCMs to avoid multiple counties within a grid sharing the same projected value. Bias correction of the GCMprojected monthly values and historically observed temperatures was performed using the equidistant quantile method. Finally, a modi ﬁ ed version of the stochastic weather generator was used to downscale the bias-corrected monthly GCM projections to the daily time series of key climate variables such as the daily maximum and minimum temperatures, and the daily average temperature of the 27 GCMs in Nantong was calculated. . Considering the lag effect and nonlinear relationship between temperature and mortality, the distributed lag nonlinear model (DLNM) was used to assess the historical effect of temperature on mortality in the three age groups as follows (2): Log E Temp NS time NS DOW (2) Where represents the number of deaths on day ; is the intercept; the cross-basis function generated by DLNM was used for the daily average temperature with a natural cubic spline function (NS) by placing three knots at the 10th, 50th, and 90th percentiles of temperature, and an NS for the lag dimension (up to 14 days); is the coef ﬁ cient; indicates the covariates, including relative humidity and two major air pollutants (PM and O ), which were adjusted using NS with three ; DOW is the day of the week. The parameters used in the DLNM model and the strategy for sensitivity analyses were similar to those used in our previous work . . To estimate the temperature-related mortality burden in 2020 2099, we incorporated 27 GCMs of CMIP6 to simulate the daily mean temperature using the historical temperature mortality relationship. We calculated the daily number of deaths from mean temperature exposure under different climate change scenarios. temperature (cold, heat, and net)-related Daily non-optimal mortality in the four different climate change scenarios was calculated using the daily number of deaths and the attributable fraction of non-optimal temperature, which was calculated as follows (3): RR 1 RR (3) Where, represents the number of coldor heat-related deaths in a future day (de ﬁ ned as temperatures below or above the MMT; MMT was de ﬁ ned as the speci ﬁ c temperature associated with the lowest mortality risk); represents the number of deaths on each age group (65 79, 80 89, 90 ) on a certain day in the future; is the age group (65 79, 80 89, 90 ); RR represents the mortality relative risk of the projected daily mean temperature relative to MMT. The sum of excess deaths for all cold and hot days is the number of deaths attributed to cold and heat, respectively, and the sum of both is the net effect of cold and heat. The attributable fraction (AF) was calculated by dividing the number of deaths attributed to non-optimal temperatures (i.e., cold and heat) by the total number of deaths. Monte Carlo simulations generating 1000 samples by assuming a multivariate normal distribution for the coef ﬁ cients derived from the cross-basis function were computed to produce the empirical con ﬁ dence intervals. The independent effects of advanced aging and climate change were de ﬁ ned by assuming no climate change or no population changes, respectively. Under the scenario of no climate change, the RR of daily coldand heat-related mortality did not differ from that during the historical period. Under the scenario of no population changes, the number of deaths at 65 79, 80 89, and 90 years ( ) did not differ from that during the historical period. The interactive effect was de ﬁ ned under scenarios of climate change and advanced aging, in which RR was calculated by comparing the projected daily mean temperature to the MMT, and was estimated based on the projections of age structure changes obtained in the previous step.
test_npjclisci.pickle ---------- ['Stronger decadal variability of the Kuroshio Extension under simulated future climate change']
Understanding the behavior of western boundary current systems is crucial for predictions of biogeochemical cycles, ﬁ sheries, and basin-scale climate modes over the midlatitude oceans. Studies indicate that anthropogenic climate change induces structural changes in the Kuroshio Extension (KE) system, including a northward migration of its oceanic jet. However, changes in the KE temporal variability remain unclear. Using large ensembles of a global coupled climate model, we show that in response to increasing greenhouse gases, the time scale of KE sea surface height (SSH) shifts from interannual scales toward decadal and longer scales. We attribute this increased low-frequency KE variability to enhanced mid-latitude oceanic Rossby wave activity induced by regional and remote atmospheric forcing, due to a poleward shift of midlatitude surface westerly with climatology and an increase in the tropical precipitation activity, which lead to stronger atmospheric teleconnections from El Niño to the midlatitude Paci ﬁ c and the KE region. Greenhouse warming leads to both a positive (elongated) KE state that restricts ocean perturbations (e.g., eddy activity) and stronger wind-driven KE ﬂ uctuations, which enhances the contributions of decadal KE modulations relative to shorttime scale intrinsic oceanic KE variations. Our spectral analyses suggest that anthropogenic forcing may alter the future predictability of the KE system. The Kuroshio Extension (KE) is an eastward inertial meandering jet of the Kuroshio current located east of Japan, exhibiting the largest air-sea ﬂ uxes and the strongest mesoscale eddy activity across the North Paci ﬁ c basin . The KE is a major part of the Paci ﬁ c western boundary currents (WBCs) system that transports substantial heat from the tropics to midlatitudes and subsequently releases most of that heat to the atmosphere via turbulent ﬂ uxes of latent and sensible heat . The strongly coupled KE system dynamically interacts with the extratropical Paci ﬁ c storm track as a midlatitude oceanic frontal zone and, in turn, further impacts large-scale climate modes over the midlatitude Paci ﬁ c . Paci ﬁ c sea surface height (SSH) variability is most prominent in the KE region [33° 40°N, 140° 165°E] (black box in Fig. 1a) on seasonal-to-decadal timescales. Changes in the eddy kinetic energy (EKE) ﬁ eld over the upstream [140° 153°E] KE region (left box in Fig. 1b) largely contribute to the seasonal-to-interannual time scales of KE variability . This short-time scale KE variation is strongly linked to oceanic intrinsic nonlinearities, characterized by an apparent bimodality . The bimodal KE ﬂ uctuations include an , when the EKE level and the KE jet is relatively straight and stable, and a , in which the EKE with a spatially convoluted KE path and large meanders . EKE changes are mainly caused by oceanic instability regarding the internal adjustment via the convergence of eddy heat ﬂ ux and also non-linear interactions of the strong current and eddies . In contrast, basin-wide wind changes over the midlatitudes are the primary forcing of the decadal variability of KE SSH ﬂ ucutations . Speci ﬁ cally, atmospheric forcing associated with the North Paci ﬁ c internal variability, which is also largely associated with El Niño and Southern Oscillation (ENSO) atmospheric teleconnections and their imprints on the redness of the spectrum , drives oceanic baroclinic adjustment that carries wind-induced oceanic Rossby waves westwards towards the WBCs, especially the downstream [153° 165°E] KE region (right box in Fig. 1b) . Oceanic Rossby waves are also closely linked to low-frequency variations in the southern recirculation gyre intensity and the latitudinal migration of the KE jet . Satellite altimeter measurements and eddyresolving ocean simulations have shown that the KE state (e.g., KE SSH anomalies) is accompanied by a southern recirculation gyre and zonal-mean KE path . Large-scale oceanic Rossby waves modulate not only the physical characteristics of the WBCs but also the local eddy activity of the KE . Interactions between the windforced and intrinsic eddy variability in eddy-resolving hindcast simulations reveal that the positive (negative) KE state can be described as the elongated (contracted) state, where the internal ocean perturbations are restricted (favored) . The forced and intrinsic KE variability vary in their respective contributions to the total signal over time . Since the mid-1980s, the decadal modulation of the KE variability has become more robust and prominent . Given that the KE dynamics modulates KE temporal behavior, the relative impact of the oceanic (i.e., intrinsic) versus atmospheric (i.e., forced) drivers on the KE region could be a key source of predictability for KE variability. the dominant forcing of Model studies suggest that global warming is associated with intensi ﬁ cation and/or a poleward shift of the KE jet in conjunction with systematic changes in wind stress, ocean strati ﬁ cation, and the southern recirculation gyre over the midlatitude Paci ﬁ c . While these many studies have documented the response of spatial characteristics of the KE system to a warming climate, future temporal changes in the KE variability remain uncertain. Here we use Geophysical Fluid Dynamics Laboratory (GFDL) SPEAR ( eamless System for rediction and rth System esearch) ensembles of simulations that cover the historical (1921 2014) and future (2015 2100) epochs and investigate the contributions of anthropogenic forcing to the dominant time scale of the KE variability (see Methods for details). The historical simulation (HIST) is compared with three additional simulations. The ﬁ rst (NATURAL) of these is driven only by changes in natural forcing (solar irradiance and volcanic aerosols) and has anthropogenic forcing ﬁ xed at 1921 levels. The second (SSP5-8.5) is an extended simulation of the HIST simulation after 2014, driven concentrations by increasing atmospheric greenhouse gas ﬁ ﬁ ﬁ corresponding to the highest projected Shared Socioeconomic Pathway (SSP). The third (SSP5-3.4OS) follows the SSP5-8.5 simulation until 2040, but thereafter is forced by rapidly decreasing greenhouse gas concentrations. SPEAR has been successfully used for climate studies, including seasonal to decadal variability and prediction of the KE . Speci ﬁ cally, SPEAR hindcasts realistically capture the temporal evolution of KE SSH variations, with skillful retrospective KE predictions on both seasonal and multiannual time scales. Given SPEAR s reliable simulations of ocean wave the propagation and wind-induced KE atmospheric forcing, present study focuses on the responses of the spatiotemporal evolution of KE variability to the different future scenarios of SPEAR. Our results suggest that an enhanced positive (elongated) state and the corresponding changes in ENSO atmospheric teleconnections lead to an increase in wind-driven decadal KE variability in anthropogenic warming. We ﬁ rst con ﬁ rm that the SPEAR simulation reproduces the spatiotemporal characteristics of historical KE SSH variability in satellite-derived observations. Like most coupled global climate models with relatively low oceanic horizontal resolutions, SPEAR produces a KE jet with excessive overshoot. However, the model reasonably reproduces the observed KE pattern, with a strong frontal SSH signature and KE SSH variance comparable to the observation (Supplementary Fig. 1). Anthropogenic radiative forcing simulations reveal signi ﬁ cant spatial changes in both the KE mean state with an intensi ﬁ cation of the southern recirculation gyre (Fig. 1a) and poleward shift of the KE front (Fig. 1b) and an increase in SSH variance corresponding to a more positive KE state . The NATURAL simulation closely resembles the HIST simulation (Fig. 1c, left column), while the SSP5-8.5 simulation con ﬁ rms the signi ﬁ cantly altered variance and position of the KE SSH (Fig. 1c, right column), exceeding the range of intrinsic variation represented by the ensemble spread. An increase in SSH variance and a poleward-shift of the KE SSH front appear in the upstream and downstream KE regions, respectively, consistent with the observed changes in recent decades . The increasing variance is prominent in the northern part of the upstream region [36° 41°N, 140° 153°E]. This substantial increase in upstream KE intensity under the external forcing is shown from 1960 to 2060 (pinks in Fig. 1d). We ﬁ nd that the stronger upstream KE SSH variance in SSP5-8.5 mostly stems from the enhanced variance at longer time scales, as shown in the histograms of spectral power (Fig. 1e). In the spectral analysis of upstream KE SSH (Fig. 1f h), the power at high frequencies (monthly to interannual) is similar across the simulations, while the power at low frequencies (~>7 years) is considerably stronger in SSP5-8.5 than in the HIST and NATURAL runs, indicating that the proportion of decadal to interannual KE variance signi ﬁ cantly increases with increasing greenhouse gas concentrations. the projected warmer climate leads to the enhanced decadal variance of the increase in the upstream KE KE (which leads to an overall In summary, variance), and the preferred time scales of the upstream KE variability shift from the interannual toward decadal and longer time scales. In contrast, no changes in the variance and temporal variability of upstream KE SSH are detected between the natural forcing and historical run in Fig. 1. of KE the Based on established mechanisms variability , a projected future shift in the dominant spectral peak of KE variability from interannual to decadal time scales may be due to changes in contributions of seasonal-to-interannual eddy activity and decadal wind-driven forcing to the total KE variability. Our hypothesis is that the portion of (1) short-lived eddy activity may be limited due to favorable conditions for the positive (elongated) KE state, which favors intensi ﬁ ed recirculation gyres and a northward KE jet but restricts internal ocean perturbations, and (2) the role of atmospherically-driven KE ﬂ uctuations (e.g., midlatitude oceanic Rossby wave adjustment) may become more signi ﬁ cant through enhanced ENSO atmospheric teleconnections as a consequence of changes in the mean background climate and increasing tropical forcing. We ﬁ rst present changes in mean background wind circulations over the Northwest Paci ﬁ c (Fig. 2a). A comparison of the HIST and SSP5-8.5 simulations (compare blues and pinks in Fig. 2a) shows an intensi ﬁ cation and poleward shift of the near-surface midlatitude westerly wind stress . These produce an anticyclonic wind stress change over (Fig. 2b and Supplementary Fig. 2), which can enhance the Ekman convergence into the KE region (pink box), interior southward Sverdrup transport, westward SSH upslope, northward western boundary current, and KE southern recirculation gyre, leading to a positive (elongated) KE state as seen in Fig. 1a, b. the WBCs We next show changes in tropical forcing under future climate projections. With increasing greenhouse gas concentrations, Nino3.4 SST anomaly variance strengthens (pink in Fig. 2c), as do the mean and variance of tropical rainfall (Fig. 2d) . We ﬁ nd that a joint impact of the latitudinally-displaced mean background winds (Fig. 2a) with the enhanced remote forcing from the tropics (Fig. 2c) may lead to stronger in ﬂ uences of the ENSO atmospheric teleconnections on large-scale wind forcing of the KE variability (Fig. 3). Changes in ENSO atmospheric teleconnections from the HIST (Fig. 3a) to SSP5-8.5 run (Fig. 3b) show the reinforced quasistationary atmospheric waves, inducing stronger basin-scale atmospheric anomalies over the midlatitudes . ENSO s North Paci ﬁ c teleconnections strengthen and shift northeastward (Fig. 3c), which are probably associated with altered background wind ﬁ eld, driving more signi ﬁ cant wind-induced Rossby wave adjustment of the upper ocean over the Central Paci ﬁ c KE band (pink box in Fig. 3c). The impact of ENSO on the KE SSH In the considerably increases with external warmer climate, the ENSO-induced oceanic Rossby waves propagate westward into the KE region with larger amplitude SSH anomalies (compare Fig. 3e, f). Our results suggest that the upstream KE region, where intrinsic perturbations dominated during the historical epoch, may become increasingly affected by forcing (Fig. 3d). ﬁ ﬁ ﬁ ﬁ wind forcing from ENSO. Thus, we attribute the stronger decadal ﬂ uctuations over the upstream KE (Fig. 1e) to both enhanced ENSO-driven oceanic forcing and the strengthened and poleward shifted midlatitude climatological westerlies. The ENSO-related KE SSH variability strengthens on decadal timescales from the HIST (Fig. 3g) to SSP5-8.5 (Fig. 3h) run. Changes in the ENSO s impacts on the KE (Fig. 3i) resemble the changes in North Paci ﬁ c SSH variability, with an increase in upstream KE intensity and a northward shift of the KE front (compare Figs. 1b and 3i). We show that a ratio of decadal to interannual KE variance has signi ﬁ cantly increased from the HIST to SSP5-8.5 run in the majority (23 of 30) of ensemble members (Fig. 4a and Supplementary Figs. 3 4). The scatterplots using those 23 members con ﬁ rm that the increasing decadal KE variance is largely driven by changes in the background wind ﬁ elds (Fig. 4b) and tropical rainfall variability (Fig. 4c). Speci ﬁ cally, the mean KE zonal wind climatology and Nino3.4 precipitation anomaly variance both predict the ratio of decadal to interannual variance of upstream KE SSH, especially in SSP5-8.5 (~35 40%) (Note that ). Under anthropogenic climate change, the weakened annual-mean zonal wind stress over the KE region reduces the frontal baroclinicity and may limit eddy activity (e.g., reduced short-time scale KE variance) . The signi ﬁ cant relationship between the zonal winds and the KE variance ratio is found in both simulations, but largely increases from the HIST (R 0.38, < 0.1) to the SSP5-8.5 run (R 0.61, < 0.05) in Fig. 4b. On the other hand, the contribution of tropical rainfall activity barely exists in HIST (R 0.1), but substantially increases in SSP5-8.5 (R 0.63, < 0.001). The results indicate that anthropogenic changes in the midlatitude wind stress climatology and tropical precipitation variance may play an important role in modulating the upstream KE SSH time scales. To further examine the sensitivity of response of the KE variability to atmospheric greenhouse gas concentrations, we investigate an additional simulation, SSP5-3.4OS, which resembles SSP5-8.5 until 2040, after which there is a substantial decline in greenhouse gas concentrations . In the SSP5-3.4OS simulation, we note that the KE intensity that had increased with radiative forcing until 2040 (grays in Fig. 1d) immediately responds to the steep greenhouse gas reduction and decreases until 2100. Also, Fig. 4d con ﬁ rms that the KE total amplitude and a ratio of decadal to interannual KE SSH variance increase with greenhouse gas concentrations and decrease when the greenhouse gases are reduced in the SSP53.4OS simulation after 2070. The results indicate that the variance and preferred time scale of KE variability sensitively vary with changing radiative forcing. To address the sensitivity of KE variability to the external climate driver, we revisit behaviors of the anthropogenic-induced climate feedbacks (e.g., wind stress climatology and Nino3.4 SST variability in Fig. 2) by comparing the SSP5-3.4OS and SSP5-8.5 runs. Figure 2a compares the North Paci ﬁ c westerlies between the SSP5-8.5 (pink) and SSP5-3.4 OS (gray) for the ﬁ nal 30-year epoch [2071 2100]. The northward-shifted winds climatological westerly winds move back towards their original position as greenhouse gas concentrations decline (grays in Fig. 2a), implying that the poleward displacement of the KE ocean front may be reversible. In contrast, the amplitude of both midlatitude westerlies climatology ﬁ (grays in Fig. 2a) and ENSO (grays in Fig. 2c) remains strong even after the greenhouse gas concentrations are reduced beyond 2040, suggesting that there may be some critical thresholds or hysteresis in the tropical and subtropical Paci ﬁ c climate system. We suggest that the (reversible) of surface wind climatology (Fig. 2a) might be a more critical factor than the (irreversible) of tropical SST activity (Fig. 2c) for the variance and dominant time scale of KE variability. Using different radiative forcing scenarios, we show that the KE preferred timescale varies with changing greenhouse gas concentrations, and its decadal variability signi ﬁ cantly increases with anthropogenic radiative forcing. Our ﬁ ndings suggest that anthropogenic-forced changes in surface wind climatology favor the positive (elongated) KE mean state and make the upstream KE SSH more stable, which may restrict the role of upstream eddy activity , leading to a reduced contribution of seasonal-to-interannual intrinsic variability to the total KE. The joint in ﬂ uences of poleward-displaced mean background winds and enhanced tropical convective forcing may lead the winddriven decadal variability to become dominant in the upstream KE region. Together, the greenhouse gases weaken the seasonal-tointerannual oceanic intrinsic KE variability while amplifying the wind-forced decadal KE variability (Fig. 4e). The large-ensemble analysis adopted in this study demonstrates signi ﬁ cant and robust contributions of anthropogenic warming to projected changes in the KE system beyond the uncertainty arising from internal climate variability. One may raise doubts whether the above ﬁ ndings would be constrained by the relatively coarse ocean model resolution (1 ) used in this study, which might underestimate intrinsic oceanic processes such as mesoscale eddy activity. It is true that the current con ﬁ guration of SPEAR cannot fully resolve small-scale ocean dynamics. However, we stress in the local and remote atmospheric forcing in a warming climate, which have been extensively demonstrated as the key drivers of KE modulations the evident changes from satellite altimeter observations and ocean model experiments . Moreover, the projected KE variability from this study is highly supported by ongoing climate changes, such as the northward shifted downstream KE jet and the more prominent decadal KE variability during the recent decades . ﬁ ﬁ ﬁ ﬁ ﬁ Given the signi ﬁ cant contributions of midlatitude atmospheric variability to the air-sea coupled KE dynamics and their changes, our ﬁ ndings may also suggest a role for changes in mesoscale oceanic eddy activity, via their known interactions with basinscale atmospheric/oceanic circulations . The future changes in the spatiotemporal patterns of KE variability have implications for both regional and large-scale climate change. A poleward shift in the KE front may alter the KE-induced surface wind anomalies over the North Paci ﬁ c by modulating the path of the storm track and the large-scale atmospheric/oceanic circulations . Also, a link between the the WBC system and the North Paci ﬁ c mechanisms of subtropical mode water suggests possible changes in the formation or subduction rate of the mode water, which play a key role in the biological pump and ocean carbon sinks in the Northern Hemisphere. Thus, an important remaining question is to what extent changes in the KE system would impact the large-scale North Paci ﬁ c regional downstream feedback or Increasing decadal variability of the KE climate in the future. might amplify extreme events and threats to ecosystems , while also possibly lending improved decadal predictability to the Paci ﬁ c climate. ﬁ ﬁ
test_npjclisci.pickle ---------- ['Disentangling the North Pacic Meridional Mode from tropical Pacic variability']
Variations of sea-surface temperature (SST) in the subtropical North Paci ﬁ c have received considerable attention due to their potential role as a precursor of El Niño-Southern Oscillation (ENSO) events in the tropical Paci ﬁ c as well as their role in regional climate impacts. These subtropical SST variations, known as the North Paci ﬁ c Meridional Mode (PMM), are thought to be triggered by extratropical atmospheric forcing and ampli ﬁ ed by air-sea coupling involving surface winds, evaporation, and SST. The PMM is often de ﬁ ned through a statistical technique called maximum covariance analysis (MCA) that identi ﬁ es patterns of maximum covariability between SST and surface winds. Here we show that SST alone is suf ﬁ cient to reproduce the MCA-based PMM index with near-perfect correlation. This dominance of the SST suggests that the MCA-based de ﬁ nition of the PMM may not be ideally suited for capturing two-way wind-SST interaction or, alternatively, that this interaction is relatively weak. We further show that the MCA-based PMM de ﬁ nition con ﬂ ates intrinsic subtropical and remote ENSO variability, thereby undermining its interpretation as an ENSO precursor. Our ﬁ ndings indicate that, while air-sea coupling may be important for variability in the subtropical North Paci ﬁ c, it cannot be reliably identi ﬁ ed by the MCAbased de ﬁ nition of the PMM. This highlights the need for re ﬁ ned tools to diagnose variability in the subtropical North Paci ﬁ c. Climate variability in the subtropical North Paci ﬁ c has been widely studied . While the variability of Paci ﬁ c sea-surface temperatures (SSTs) in the low latitudes is dominated by El Niño-Southern Oscillation (ENSO), numerous studies have suggested that the subtropical North Paci ﬁ c may be home to an independent variability pattern that is maintained by the two-way coupling (hereafter just coupling ) between surface winds, evaporation, and SST (the socalled wind-evaporation-SST or WES feedback ; see Methods for a short description), and forms a central part of the North Paci ﬁ c Meridional Mode (PMM hereafter). In its positive phase, the PMM pattern consists of warm SST anomalies that extend southwestward from the California coast toward the western equatorial Paci ﬁ c, accompanied by a weakening of the northeast trade winds (Fig. 1a). The initial forcing of this pattern is from intrinsic atmospheric variability in the midlatitudes that extends into the subtropics . The PMM is known to have its own regional climate impacts, such as in ﬂ uencing droughts in California and modulating eastern Paci ﬁ c hurricane occurrence , but has probably garnered wider attention due to its potential role as a precursor of ENSO . It has been shown that atmospheric variability in the extratropical North Paci ﬁ c, which is largely stochastic in nature , can seed the development of the PMM during northern hemisphere winter (December-January-February or DJF). As the PMM matures in spring (March-April-May or MAM), it propagates toward the equator as a coupled wind-SST mode, an intrinsic property of the WES feedback . When the SST pattern approaches the equator, the accompanying weakening of the trade winds can initiate the development of an El Niño event that typically matures in the following winter (DJF) and couples tropical winds, SST and ocean circulation. Predicting El Niño from MAM is notoriously dif ﬁ cult . It has been suggested that the PMM may help to overcome this ENSO predictability barrier and enable skillful ENSO predictions at longer lead times. This could also offer a theoretical framework for understanding how stochastic atmospheric variability in the North Paci ﬁ c can in ﬂ uence ENSO. singular value decomposition or SVD; ﬁ Since the PMM is situated just northeast to the region of intense ENSO activity, a major problem has been how to diagnose PMM variability without contamination by the strong ENSO signal. The conventional approach has been to ﬁ rst remove the ENSO signal by linearly regressing out an indicator of ENSO activity called the cold tongue index (CTI; see Methods ). In the second step, a statistical technique called maximum covariance analysis (MCA; also known as see Methods ) is applied to ﬁ nd the dominant pattern of coupled SST-wind variability. The MCA yields two spatial patterns and temporal expansion coef ﬁ cients (one for each of the two input ﬁ elds) that form the basis of the PMM de ﬁ nition . Studies of the PMM often use the SST pattern to de ﬁ ne an index of PMM variability (see Methods ). We will refer to this index as the PMM index, or, where clari ﬁ cation is necessary, as the reference PMM-T index. Two assumptions are key to the MCAbased PMM de ﬁ nition: (1) regressing out the CTI is an effective way of removing ENSO variability; (2) MCA can reliably identify coupled SST-wind variability in the subtropics. While assumption (1) has been examined to some extent , assumption (2) has In the following we provide further received little attention. evidence that assumption (1) is problematic, and show that there are caveats to assumption (2) as well. This has important implications for how we can diagnose coupled variability in the subtropical North Paci ﬁ c, and also raises questions about the utility of the PMM as an independent precursor of ENSO. ﬁ ﬁ ﬁ ﬁ ﬁ ﬁ The PMM is thought to rely on the WES feedback, which is distinct from the Bjerknes feedback which governs equatorial Paci ﬁ c variability and ENSO. By considering the coupled variability of SST and surface winds, the MCA aims to diagnose the coupled processes that underlie the PMM and its equatorward propagation. Statistical analysis of SST alone, however, yields a pattern that is very similar (Fig. 1b; based on principal component analysis (PCA) as described in Methods ) to the one derived by MCA (Fig. 1a). The patterns of SST, wind, and sea-level pressure (SLP) are correlated with the original PMM patterns at 0.97 to 0.98, while the SST expansion coef ﬁ cient correlates with the PMM SST index (de ﬁ ned as the expansion coef ﬁ cient of the SST pattern) at 0.95 (all pattern correlations signi ﬁ cant above the 99.9% level, i.e., value < 0.001). Further sensitivity tests of the MCA reveal, that the MCA SST pattern is rather insensitive to either replacing Paci ﬁ c winds with those from a remote area or to swapping the ﬁ rst and second half of the SST record (Supplementary Note 1 and Supplementary Fig. 4), again highlighting the dominance of the SST ﬁ eld. Thus, the surface winds only make a very small contribution to the reference PMM-T index. This suggests that the MCA of three ﬁ elds can be replaced by PCA of only one ﬁ eld, SST, without much loss of information (90% variance explained). Indeed, even a simple box average of SST (PMM_aave; Fig. 1c) captures a substantial portion of the PMM variability, with the patterns correlated at ~0.95 and the time series at 0.90 (Supplementary Fig. 1b; -value < 0.001 for both pattern and temporal correlations). Even when the ENSO in ﬂ uence is not regressed out prior to calculating the area average, the similarity with the reference PMM-T index and its patterns is high (Fig. 1c), with pattern correlation values of 0.80 for SST and wind ﬁ elds, and 0.78 for SLP ( -value < 0.001). In particular, Previous studies have raised concerns about the use of MCA for identifying coupled variability patterns . it has been argued that the two patterns produced by MCA either the total covariability or, alternatively, are explain little of dominated by the EOFs of the individual ﬁ elds, in which case they contain no new information . Our analysis suggests that the reference PMM SST pattern falls into the latter category: it contains little information that cannot be gathered from the consideration of SST alone. Another possibility is that the MCA actually works well but that the SST-wind coupling is weak due to atmospheric noise. The PMM wind pattern is less well represented by a PCA of wind only (Supplementary Fig. 2). Nevertheless, the PMM wind index, too, can be approximated by a simple area average of SLP in the subtropical North Paci ﬁ c (Supplementary Fig. 2c). This SLP area average is correlated to the subtropical SST area average (Fig. 1c) in much the same way as the reference PMM SST and wind indices (Supplementary Fig. 3), with highest correlation when the former leads the latter. SLP is in ﬂ uenced by SSTs but also feeds back on them through its control of near-surface winds and latent heat ﬂ ux. It is therefore not surprising that an area average of SLP can stand in for 10 m winds. This is supported by the high similarity of the wind patterns in Supplementary Fig. 2a, c. Using SLP instead of 10 m winds can be bene ﬁ cial, as the latter is more easily measured. We note that the relation between SLP and surface winds is complicated by the in ﬂ uence of vertical mixing , which may also be an aspect of the WES feedback that deserves further study. The singular value of the PMM MCA pattern passes a bootstrap test (see Methods ) with a -value of < 0.001. Further analysis, however, suggests that this test may be too permissive and thus not suf ﬁ cient to establish a statistically signi ﬁ cant relation (see Supplementary Note 2 and Supplementary Fig. 4d). ﬂ The PMM is considered to be largely independent of ENSO because it relies on a different type of air-sea interaction, namely the WES feedback. ENSO is an equatorial Paci ﬁ c phenomenon but has worldwide impacts, including in the subtropical North Paci ﬁ c . Therefore, in the commonly used PMM de ﬁ nition, the ENSO signal is removed by regressing out the CTI from all ﬁ elds prior to analysis . The averaging area for this ENSO index extends from the date line to the eastern equatorial Paci ﬁ c. Since the original work de ﬁ ning the PMM was published, an additional type of El Niño has been identi ﬁ ed that is centered in the central equatorial Paci ﬁ c, variously referred to as El Niño ﬁ ﬁ ﬁ ﬁ Modoki or Central Paci ﬁ c (CP) Niño, and which is distinct from the canonical El Niño, which is centered in the eastern equatorial Paci ﬁ c and also referred to as Cold Tongue (CT) Niño . Considering the geographical location of the CP Niño, it is obvious that it cannot be completely removed by regressing out the CTI; indeed, it has been shown that two independent indices are needed to account for both ﬂ avors of ENSO . This, however, means that the standard PMM index is contaminated by the CP ENSO signal, a fact that is apparent in the lagged correlations of the PMM and SST in the western equatorial Paci ﬁ c (Fig. 2). Correlations at lag 0 are about 0.6 and remain statistically signi ﬁ cant ( -value < 0.05) at all lags from 12 to 12 months. Moreover, correlations are roughly symmetric around the peak at lag 0. Thus, it is dif ﬁ cult to argue that the PMM is a precursor of CP ENSO, as has often been done in the literature. Rather, CP ENSO is built into the PMM by de ﬁ nition, an issue that has previously been raised . We further note that contamination by the ENSO signal may also affect statistical prediction models based on linear inverse modeling (LIM; see Methods ), which can be used to identify optimal initial SSTs (comprised of a number of nonorthogonal damped eigenmodes) for ENSO development (i.e., precursors) under stochastic forcing . Whereas the extratropical portion of the precursor, which resembles the PMM, is often emphasized , the precursor includes an SST signal in the central equatorial Paci ﬁ c. This indicates that LIM, too, may not be able to clearly separate extratropical and tropical ENSO precursors. One could argue that CP variability is actually part of the PMM itself because previous studies, as well as the present one, have shown a close correspondence between CP ENSO and the PMM. It is certainly possible to de ﬁ ne the PMM in this manner but, in that it becomes dif ﬁ cult to interpret the PMM as an ENSO case, precursor. This is because it has been shown here and elsewhere that the PMM and CP ENSO have their highest correlation at lag 0. Consistently, it has been found that the PMM is not very useful in the prediction of CP ENSO . More importantly, many studies indicate that the PMM is a subtropical phenomenon that relies on thermodynamic air-sea coupling (WES feedback) while CP ENSO is an equatorial phenomenon that relies on dynamic air-sea coupling (Bjerknes feedback). We therefore believe that the PMM should be clearly separated from tropical variability. The CTI not only fails to remove CP ENSO, it also leaves out a small area between 90°W and the South American coast. Interestingly, this area, just off Peru, is precisely where El Niño was originally discovered ( ﬁ rst by local ﬁ shermen, then by scientists ), and has been de ﬁ ned as the Niño 1 2 region (see Methods ). Regressing out the CTI leaves substantial ENSOrelated variability in this region, and this is shown by the cold SST anomalies in the regression patterns (Fig. 1a, b) and in the lagged correlations of the PMM and Niño 1 2 indices (Fig. 2b). A study by Takahashi et al. recommends characterizing CP and CT variability by two indices that are roughly orthogonal to each other. We refer to this index pair as the CPCT index. When this index is regressed out instead of the CTI before performing MCA, both the cold and warm SST anomalies in the western and eastern equatorial Paci ﬁ c, which characterize the reference PMM pattern (Fig. 1a), are absent (Fig. 1d), and the wind anomalies over the western equatorial Paci ﬁ c (130°W-160°E, 5°S-5°N) weaken from 0.25 to 0.10 m/s. In the North Paci ﬁ c (north of 20°N), on the other hand, the pattern remains quite similar to that of the reference PMM, although the positive SLP anomalies over the Gulf of Alaska are missing. Furthermore, positive SST anomalies emerge in the southeastern Paci ﬁ c, roughly symmetric about the equator. The lagged regression of the PMM and PMM_CPCT indices with SST in the western equatorial Paci ﬁ c (Fig. 2a) con ﬁ rms that regressing out the CPCT index pair effectively removes the CP ENSO signal from the PMM, with correlations not exceeding the 95% signi ﬁ cance level for any lead time. The time series of the PMM_CPCT index (Fig. 1e) shows strong differences with the PMM index around the 1982/1983 and 1997/1998 extreme El Niño events, which raises the possibility that the differences in the PMM and PMM_CPCT patterns are mostly due to those extreme events. By excluding strong ENSO years from the MCA we have veri ﬁ ed that this is not the case; the patterns remain almost unchanged (not shown). leading to a pattern that is Lagged regressions of SST, winds and SLP on the MAM PMM and PMM_CPCT indices show a conspicuous difference in the evolution of these ﬁ elds (Fig. 3). Both the PMM and the PMM_CPCT start with negative SLP anomalies in the North Paci ﬁ c that extend into the subtropics and are accompanied by a weakening of the northeast trade winds. However, while the PMM shows SST and wind anomalies extending into the western equatorial Paci ﬁ c during MAM, the PMM_CPCT does not: The SST anomalies are con ﬁ ned to the subtropics and the western equatorial wind anomalies are much weaker. Consistently, the PMM progresses to El Niño-like conditions toward the end of the year, whereas the PMM_CPCT does not, which indicates a weaker link between PMM-like patterns and subsequent ENSO development. The lagged regressions of the PMM_CPCT with the Niño 1 2 index (Fig. 2b) reveals a further factor complicating ENSO removal, which is the autocorrelation of ENSO variability. While regressing out the CPCT index pair leads to the complete removal of the Niño 1 2 variability at lag 0, correlations reassert themselves at both increasing and decreasing lags, indicating the limits of regressing out the simultaneous ENSO signal; this includes the possibility of equatorial SST anomalies in the preceding season in ﬂ uencing PMM development. In addition, ENSO variance is more pronounced in winter than in other seasons. Therefore, a more thorough procedure for regressing out ENSO-related variability would have to account for its seasonality. Incomplete ENSO removal is also evident in Fig. 3b, which shows positive SST anomalies in the eastern equatorial Paci ﬁ c in DJF, before the peak of the PMM. These CT El Niño-like SST anomalies may explain the more meridionally symmetric SST distribution about the equator, and the northward shift in the North Paci ﬁ c SLP anomalies, both of which are consistent with equatorial forcing on the extratropics, rather than the other way round. As such, we do not suggest that regressing out the CPCT index pair solves the ENSO removal problem. The above analysis, however, does show that the PMM pattern is sensitive to how ENSO removal is performed. ﬁ The PMM is often analyzed in climate models, for example in the context of seasonal predictions , climate model evaluation , or climate change . Typically, these studies use the reference de ﬁ nition of the PMM, which involves regressing out the CTI from ﬁ elds and subsequently applying MCA. When performed on observations, the ﬁ rst mode invariably shows the PMM pattern. For model output, on the other hand, this is not necessarily the case, with 15 of the 44 global climate models examined here yielding the PMM as the second or even third MCA mode (Fig. 4a). Climate models tend to feature ENSO variability that extends too far westward . This may change the amount of residual ENSO variability after CTI removal and thus shift the PMM-pattern to a higher mode. An important implication is that mechanically applying the reference PMM de ﬁ nition to climate models may yield misleading results because the ﬁ rst MCA mode will be identi ﬁ ed as the PMM, whereas in some models the PMM is actually represented by higher modes, as is the case for the widely used CESM2. Therefore, care must be taken to pick the mode that is most similar to the observed PMM (as measured by pattern correlation). In other words, When the PMM is not represented by the ﬁ rst MCA mode, it also tends to be quite different from the corresponding SST PCA (see Methods ). in those models, representing the PMM with SST only is less successful than it is for the observations. In the remaining models, however, the correlation between the PMM and the PMM_PCA is invariably above 0.8 and often quite close to 1. Even when the reference PMM and PMM_PCA are poorly correlated, this does not necessarily mean that the MCA adequately represents coupled SST-wind variability; rather, the PCA may partition the residual ENSO variability in a different manner. When the simple SST area average de ﬁ ned in Fig. 1c (CTI not regressed out) is used to represent PMM variability in the climate models, the correlations with the standard PMM are reasonably high (Fig. 4b), even for those models that have a low correlation between the PMM and PMM_PCA. This indicates that the simple area average provides a relatively robust measure of the PMM. The reason why some models do not represent the PMM in the ﬁ rst MCA mode deserves further analysis. A PCA analysis of SST in the tropical Paci ﬁ c provides some clues. For this analysis, no ENSO index is regressed out prior to PCA. Without regressing out ENSO, the PMM-like SST pattern is well represented by the second EOF in the NCEP/NCAR Reanalysis (Fig. 4c) and the majority of the models (Fig. 4d). In the outlier models, however, the second EOF pattern reveals a conspicuous difference in the South Paci ﬁ c (Fig. 4e): the southeastward branch of warm SST anomalies that is only weakly developed in the observations is quite pronounced in the outlier models and extends toward South America, leading to a V-shaped ﬁ ﬁ ﬁ ﬁ ﬁ ﬁ ﬁ ﬁ pattern that is roughly symmetric about the equator. This results in poor pattern correlations with the reference PMM pattern. with the WES feedback. This indicates that more analysis will be needed to arrive at a satisfactory diagnostic tool for variability in the subtropical North Paci ﬁ c. Our analysis suggests that the MCA-based reference PMM de ﬁ nition does not reliably identify the wind-SST coupling that is thought to underpin variability in the subtropical North Paci ﬁ c because it is dominated by SST. Nor does it succeed in effectively removing the in ﬂ uence of ENSO. The resulting PMM index is therefore contaminated by ENSO variability and cannot be interpreted easily as an independent precursor of ENSO. A similar problem surfaces in statistical analyses that derive optimal precursors based on the LIM framework. As these SST precursors resemble the PMM, the ENSO signal . they already contain part of The above caveats do not necessarily imply that PMM-like variability cannot serve as a potential precursor to ENSO. Nor does it discount the importance of the WES feedback for the subtropical North Paci ﬁ c. Those ﬁ ndings are supported by multiple lines of evidence and are most likely robust. For the reasons stated in the above paragraph, however, we believe that the reference PMM de ﬁ nition is not optimally suited to representing the PMM, and that it may overestimate its role as a precursor. Therefore, previous results should be reexamined in two respects: (1) To what extent is the ENSO signal already present during the peak of the PMM (in MAM)? (2) How sensitive is the precursor role of the PMM to the procedure of ENSO removal? role for Many studies have suggested a precursor the PMM but only a few studies have attempted to quantify this effect in seasonal ENSO predictions . These studies have found some limited contribution to ENSO prediction skill. While a number of model experiments have been conducted to examine the in ﬂ uence of the PMM on ENSO , more experiments will be needed to quantify the PMM s contribution to ENSO prediction skill, and to assess the role of model biases. These experiments should strive to carefully separate subtropical precursors from ENSO itself. The con ﬂ ation of ENSO and subtropical variability in the PMM index can also confound multi-model studies of present and future climate as intermodel differences in the PMM may just re ﬂ ect different ENSO characteristics. To move forward, we suggest using the simple box average of subtropical SST anomalies (indicated in Fig. 1c). The resulting index and regression patterns have some similarity with those of the reference PMM-T index but are not sensitive to how the ENSO in ﬂ uence is removed, or whether it is removed at all (Supplementary Fig. 1c). Moreover, it is relatively robust across most of the climate models examined here. This index can be further re ﬁ ned as shown in Supplementary Fig. 1d. An advantage of using only SST for PMM diagnosis is that SST is more reliably measured and extends further back in time. This allows analyzing longer observational records and, possibly, even paleo proxies. We note that a number of studies have already used alternative de ﬁ nitions of the PMM index that mostly rely on SST . Ultimately, it would be desirable to have an index that better represents the SST-wind coupling, if this coupling is indeed fundamental to the PMM. Recently, Amaya et al. have shown a promising diagnostic method for a related phenomenon, the Atlantic Meridional mode. Their method does not rely on MCA or PCA but rather uses straightforward correlations of SST and surface wind speed. Application of this method, however, may be more dif ﬁ cult in the Paci ﬁ c, where the ENSO in ﬂ uence tends to overwhelm other signals. We have performed an analysis along these lines by examining the propagation of SST anomalies from the subtropical North Paci ﬁ c toward the equator (Supplementary Note 3 and Supplementary Fig. 6). The results, however, only provide very limited support for propagation that is consistent Maximum covariance analysis aims to identify pairs of patterns that explain a maximum fraction of covariance among two spacetime datasets . The technique is also often referred to as singular value decomposition (SVD) but, to distinguish it from the matrix decomposition method by the same name, we use the term MCA. For all points in the spatial dimensions of the ﬁ rst dataset, MCA calculates the temporal covariance with all points in the second dataset. The resulting covariance matrix is subjected to an eigenvalue decomposition that identi ﬁ es the spatial patterns explaining the largest fraction of covariance. Temporal expansion coef ﬁ cients are obtained by projecting the spatial patterns onto the datasets. (2) Mask out land points. The calculation of the reference PMM index follows the method outlined by Chiang and Vimont . For details, please refer to https://www.aos.wisc.edu/~dvimont/MModes/PMM.html. The important steps are summarized here: (1) Take the skin temperature and 10 m wind from the NCEP/NCAR Reanalysis. The analysis region is 175°E to 95°W, 21°S to 32°N, and the analysis period is ﬁ xed as 1950 2005. (3) Calculate the anomalies of all ﬁ elds, i.e., the deviations from the monthly climatology. (4) Remove the linear trend from all ﬁ elds. (5) Regress out the cold tongue index (CTI), a measure of ENSO activity, which is de ﬁ ned as SST averaged over 180°-90°W, 6°S-6°N. (6) Calculate the MCA between SST on the one side and the zonal and meridional surface wind components on the other. (7) Repeat steps (1) (5) but use the entire available period (1948 present). Project the spatial pattern of the ﬁ rst MCA mode onto the SST time series to obtain the temperature PMM index (PMM T). This is the index that is most commonly used in the literature. Projecting the time series of the combined wind components onto ﬁ rst MCA mode of the wind time series yields the wind PMM index (PMM W). Chiang and Vimont suggest that the latter index mixes midlatitude wind forcing with the coupled ocean-atmosphere interaction of the PMM. Thus, the PMM T index is recommended for analyzing coupled PMM variability . We follow exactly the procedure outlined by Chiang and Vimont and perform it on the same dataset (NCEP/NCAR Reanalysis). The resulting reconstructed PMM index agrees very well with the one that is made available by Daniel Vimont on his website , with a correlation of 0.99. The slight discrepancy may be due to the details of the software packages used for the MCA calculation. We take this reconstruction of the PMM index as our reference. Principal component analysis (PCA), also known as empirical orthogonal function (EOF) analysis, is similar to MCA but uses only one dataset to calculate the covariances of all spatial data points. The resulting matrix is subjected to an eigenvalue decomposition and the patterns explaining the highest fraction of variability are identi ﬁ ed. The spatial patterns are called EOF modes and their expansion coef ﬁ cients, obtained by projecting the EOFs on the dataset, are called principal components (PCs). In the present study, we use PCA on the same spatial domain as for the MCA and prepare the dataset in the same manner as for the MCA, using steps (1) (5) outlined under the description of the MCA. LIM is an empirical statistical approach that aims to extract the essence of a complex non-linear system from data . If is the state vector of a subset of the full system, LIM assumes that it can be represented by , where d/dt indicates the time derivative, is a linear operator, is white noise forcing, and nonlinear terms have been neglected. The linear operator can be estimated by performing essentially a lagged covariance analysis 0 , where ( ) is the covariance on the data: matrix at time lag , and (0) the inverse of the covariance matrix at lag 0. Based on the linear operator , optimal precursors can be calculated through an eigenvalue analysis. The state vector can represent a single variable, such as SST, or a collection of different variables. In order to facilitate the matrix calculations, LIM is usually performed on a set of leading principal components from a PCA. ﬁ A two-sided Student s -test is used to determine the statistical signi ﬁ cance of correlation and regression coef ﬁ cients. Serial correlation is accounted for by calculating the effective sample size. The statistical signi ﬁ cance of MCA modes is calculated using a bootstrapping approach . One-year blocks of the wind data are randomly permuted to generate 1000 scrambled time series, so that the temporal relation between wind and SST is lost. It is then determined how many of the scrambled MCAs yield a statistic larger than that of the original, unscrambled time series. This number is divided by the number of permutations to obtain the value. The statistics that are typically examined for a given mode include the explained squared covariance fraction, the correlation between the expansion coef ﬁ cients, and the singular value. Of these, the singular value is typically recommended and is the measure used in the present study. We use the National Centers for Environmental Prediction/ National Center for Atmospheric Research (NCEP/NCAR) Reanalysis product as our observation-based dataset. Reanalyses are climate model simulations that are constrained by observations from many different sources (in-situ, satellite, radiosondes etc.) to obtain a best estimate of the true state of the atmosphere that is gap-free in time and space. The NCEP/NCAR Reanalysis is chosen as it is the dataset used to de ﬁ ne the reference PMM index. Using other datasets yields very similar results. The analysis period is 1950 2005, the same as the one used for the de ﬁ nition of the reference PMM on the PMM website . We use output from the preindustrial control experiment (piControl) of the Coupled Model Intercomparison Project Phase 6 (CMIP6) . piControl is chosen as it offers long time series under steady radiative forcing. The 44 models chosen for our analysis are listed in the Supplementary Table 1. Many measures of ENSO activity have been devised. These are usually simple area averages of equatorial Paci ﬁ c SST. Chiang and Vimont use the cold tongue index (CTI), de ﬁ ned as SST averaged over the region 180°-90°W and 6°S-6°N, to regress out the ENSO in ﬂ uence prior to their MCA. This measure is indeed a good indicator of the canonical ENSO, that is most pronounced in the eastern equatorial Paci ﬁ c and also called cold tongue (CT) ENSO. It does, however, not take into account SST off the Peruvian coast. More importantly, it does not include ENSO variability west of the date line, which is referred to as El Niño Modoki or Western Paci ﬁ c (WP) ENSO . Takahashi et al. suggest using a pair of indices to account for both the CT and WP ﬂ avors of ENSO. One of their suggestions relies on the well-established Niño 4 (SSTs averaged over 160°E-150°W, 5°S-5°N) and Niño 1 2 (SSTs averaged over 90°-80°W, 10°S-0) indices. These two indices are linearly combined to yield a pair of roughly orthogonal indices: C 1.7*Nino4 0.1*Nino12, and E Nino12 0.5*Nino4. We use this index pair to perform a more complete ENSO removal prior to the calculation of the PMM index. We refer to the PMM index modi ﬁ ed in this way as the PMM_CPCT. A coupled air-sea feedback loop, in which a weakening of the subtropical trade winds causes a reduction of sea-surface evaporation . This reduces the cooling by latent heat ﬂ ux and results in a warming of the underlying SSTs. The resulting warm SST anomalies in ﬂ uence the large-scale atmospheric circulation so as to further reduce the strength of the trade winds. Since the weakening of the trades is most pronounced equatorward of the SST anomalies, it has been suggested that the pattern slowly propagates equatorward. The WES feedback relies on thermodynamic processes. This sets it apart from the Bjerknes feedback in the equatorial Paci ﬁ c, which depends on subsurface ocean dynamics.
test_npjclisci.pickle ---------- ['Climate change impact on hurricane storm surge hazards in New York/New Jersey Coastlines using machine-learning']
Recent hurricane losses in the New York Metropolitan area demonstrate its vulnerability to ﬂ ood hazards. Long-term development and planning require predictions of low-probability high-consequence storm surge levels that account for climate change impacts. This requires simulating thousands of synthetic storms under a speci ﬁ c climate change scenario which requires high computational power. To alleviate this burden, we developed a machine learning-based predictive model. The training data set was generated using a highﬁ delity hydrodynamic model including the effect of wind-generated waves. The machine learning model is then used to predict and compare storm surges over historical (1980 2000) and future (2080 2100) periods, considering the Representative Concentration Pathway 8.5 scenario. Our analysis encompassed 57 locations along the New York and New Jersey coastlines. The results show an increase along the southern coastline of New Jersey and inside Jamaica, Raritan, and Sandy Hook bays, while a decrease along the Long Island coastline and inland bays. The heavily populated New York metropolitan area covers a region of narrow rivers, estuaries, islands, and sand barriers with elevations that are <5 m above mean sea level . Millions of residences and transportation, energy, and water infrastructure systems in this area are highly prone to storm surge events. Since 2010, tropical cyclones (TCs) Irene in 2011, Sandy in 2012, Isaias in 2020, Fay in 2020, and Ida in 2021 killed tens of people, damaged thousands of houses, and caused interruptions in clean water and electricity supplies . ExtraTropical cyclones (ETCs) are equally hazardous. The Great Appalachian Storms in 1950 produced storm surges that were only 13% smaller than that of Hurricane Sandy (after removing the trend in sea level) . in their The expectation that climate change will result in an increase in the frequency of very intense (Categories 4 and 5) hurricanes and tracks points to a potentially an eastward shift signi ﬁ cant change in the level of storm surge hazards to this region over the coming decades. These hazards are quanti ﬁ ed by assessing the change in the N-year peak storm surge height (or water level) return periods, de ﬁ ned as the height that has 1/ percent chance of being exceeded in any given year. While Roberts et al. and Lin et al. found that the impact of ETCs climatology change would not be signi ﬁ cant in this region, other studies showed differing impacts of climate change on TCinduced storm surge levels. Lin et al. used the ADvanced CIRCulation (ADCIRC) hydrodynamic model and found that the 100and 1000-year total water level return periods at the Battery will, respectively, increase by 10% and 5.5% due to climate change. In another study, Lin et al. determined that sea level rise and TC climatology change will result in an 85% increase in the 100-year return periods. Garner et al. used ADCIRC and showed that the 100and 1000-year storm surge return periods will, respectively, decrease by 9% and 1.5%. Marsooli et al. showed an increase in the 100-year return period in the New York metropolitan area ranging from 4% to 12% for the future period between 2075 and 2095. Marsooli et al. studied the impact of climate change on hurricane ﬂ ood hazards in Jamaica Bay, NY using a data set for the future period of 2080 2100. Their results showed that the 100and 1000-year total water levels, excluding wave effects, will increase by 10% and 14%, respectively. The wave setup contributes to the total water level by transferring the radiation stresses from breaking waves to the water column, which in turn increases the water level by 5 35%, based on the continental shelf size and slope . However, none of the previous studies included the effect of wind-generated waves on storm surge heights and return period levels. Reliable estimates of the -year ﬂ ood levels under different climate change scenarios must be based on data from × 10 × × storms , where is the number of climate models, and represents the annual storm frequency. Ayyad et al. estimated that, for the 1000-year return period, 600,000 storm scenarios should be considered when assuming a frequency of ﬁ ve storms per year and an ensemble of six climate models. Given the limited number of historical storms, numerical modeling and simulations of synthetic storms must be used in estimating lowprobability high consequence events such as 100 and 1000-year return periods. Performing hydrodynamic simulations for a large number of storm scenarios is a computationally intense task. To simpli ﬁ ed hydrodynamic reduce the computational burden, models (e.g. SLOSH) or coarser computational meshes are used, which could compromise and lead to lower con ﬁ dence in the results. An alternative approach to performing an extensive number of hydrodynamic simulations is to use Arti ﬁ cial Intelligence tools. Lee et al. , Tseng et al. , Lee et al. , De Oliveira et al. , and Kim et al. used arti ﬁ cial neural network (ANN) models to predict surge levels due to synthetic or historical Typhoon data. Hashemi et al. used ANN models to predict maximum water elevation based on synthetic TCs, while Lee et al. predicted the peak storm surge height using tropical cyclone time series. Tiggel et al. predicted hourly surge time series of the global tide and surge model forced using atmospheric variables. Jia et al. and Kyprioti et al. used surrogate models to comprehensively assess risk and coastal hazard. Ayyad et al. were the ﬁ rst to demonstrate the use of ANN and machine learning (ML) models to reliably predict the -year return periods for the idealized computational domain and real domain, respectively. They used highﬁ delity numerical simulations of synthetic TCs to train, validate, and test different ML models that predicted the peak storm surge height. Then, they used the predicted storm surge heights to generate return period curves. The generated curves from one of the ML models showed good agreement with those generated from the hydrodynamic simulations but at a small fraction of the computational time and resources. In this study, we implement a machine learning model to assess variations in probabilistic ﬂ ood hazards from storm surges due to TC climatology change. Furthermore, we include the effects of wind-generated waves that were not considered in previous studies. Because of uncertainties in the TCs timing, we neglect the effect of tides. As demonstrated in recent events, the storm surge could coincide with low tides and cause less hazards as in the case of hurricane Isaias 2020 , or with high tides as in the case of hurricane Sandy 2012 , which caused signi ﬁ cant damage. The peak storm surge heights used to train the ML model are calculated using numerical simulations of the coupled ADvanced CIRCulation and Simulating WAves Nearshore (ADCIRC SWAN) model . These simulations are used to train different ML models at 57 sites in the New York metropolitan area. The sites cover a combination of open coast and inner bay sites. The trained ML models are then used to predict the peak storm surge height considering the in ﬂ uence of wind setup, the inverted barometer effect, and wind-generated waves from TC synthetic storms. Data sets for storms covering the historical period of 1980 2000 (late twentieth century) and the projected future period of 2080 2100 (late twentyﬁ rst century) are used to determine the impact of climate change. The TCs in the future period are generated under the representative concentration pathways (RCP) 8.5 greenhouse gas concentration scenario. Historical and future TC data sets are based on projections from four global climate models. We also utilize TC data sets generated for the observed climate of the historical period of from the National Centers for Environmental Prediction (NCEP) reanalysis to correct any bias resulting from the climate models. Here, we used the predicted storm surges from the ML models to determine probabilistic ﬂ ood events up to the 500-year return period to avoid the large statistical uncertainty in higher return periods, which is due to the limited number, between 1800 and 2000, of synthetic TCs in each dataset. Assessing the impact of tropical cyclone (TC) climatology change on probabilistic ﬂ ood hazards requires a large number of TCs. Due to the limited number of historical events, synthetic TCs must be used. For the purpose of this study, we use the synthetic TC data sets from Marsooli and Lin . These synthetic TCs were generated using the statistical/deterministic hurricane model of Emanuel et al. . This hurricane model generates synthetic TCs for atmospheric and oceanic conditions determined from either observations or climate models. Synthetic TCs from the observed climate over the historical period of 1980 2000 (late twentieth century) were generated based on the National Centers for Environmental Prediction (NCEP) reanalysis . Synthetic TCs were also generated based on the modeled climates of the same historical period and the future period of 2080 2100 (late twentyﬁ rst century). Four global climate models, namely the GFDL5 (Geophysical Fluid Dynamics Laboratory Climate Model, USA) ; HadGEM5 (Hadley Centre Global Environment Model, U.K. Meteorological Of ﬁ ce) ; MPI5 (Max-Planck-Institute for Meteorology, Germany) ; and MRI5 (Meteorological Research Institute, Japan) were used to generate the synthetic TCs. A total of nine TC data sets were generated. Four climate models were used to generate eight data sets for historical and future periods and the observed climate was used to generate one data set for the historical period. The histograms, density maps, and storm surge return period results of the future period are bias corrected using the NCEP data set and presented as the weighted average over the four climate models, as described in the methods section. We consider TCs that pass within a 350 km radius of the New York metropolitan area. Tracks of a random sample of the generated synthetic TCs for the historical and future periods are shown in Fig. 1a. About 1800 synthetic TCs from each climate model for the historical and future periods are considered. The number of TCs in the NCEP data set is around 2000. One important characteristic of the TC, used in their classi ﬁ cation, is its intensity de ﬁ ned by the maximum sustained wind speed. Because the wind speed varies as the TC travels along its track, we de ﬁ ne the TC intensity by its wind speed at the closest location to the Battery. Histograms of TCs maximum sustained wind speed at the closest location to the Battery for the historical and future periods are shown in Fig. 1b. The historical period histogram shows TCs of the NCEP data set, while the future period histogram shows the weighted average of the TCs from the four future climate models. The histograms show right-skewed distributions. More importantly, the plots show an increase in the number of intense ﬁ hurricanes, i.e. Categories 3 and above, and a decrease in the number of less intense TCs that reach the New York metropolitan area in the future period. The percentages of every category out of the total number of storms in the historical and future periods data sets are presented in Table 1. The TC data sets show that the percentages of tropical storms and Category 1 hurricanes that reach the metropolitan area would decrease in the future period, while that of Category 3 hurricanes would triple in the future. Although the data sets show no storms higher than Category 3 reached the study area in the historical period, they show some high-intensity storms (Categories 4 and 5) reach this area in the future period. This projected increase in TC intensity in the future climate is consistent with most other projections . The difference in the weighted density distribution of the TC tracks over our study area is presented in Fig. 2. The density distribution is de ﬁ ned as the number of TCs that cross through a grid box of size 0.5° × 0.5° and normalized by the area of this grid. The historical period density distribution is calculated using the NCEP data set while that of the future period is the weighted average over the biased corrected density distribution of the four data sets. Then, the difference between the density distributions of both periods is shown in the plot. Figure 2a, which shows the density plot of all the TCs, indicates an eastward shift in storm tracks by the end of the twentyﬁ rst century. The TC data sets show more TCs would travel toward Delaware Bay, Cape May, and south of Atlantic City, impacting Delaware and the southern part of the NJ coastline. A lesser number of TCs would impact the western side of Long Island. These ﬁ ndings are consistent with those of Garner et al. who noted an offshore shift of storm tracks. Figure 2b, which shows the density plots of the intense hurricanes only, shows a higher number of intense hurricanes would travel parallel to the NJ coastline in the future. The TC data sets show that a smaller number of these hurricanes would either make landfall on the NJ coastline or on the east side of Long Island. Since the highest wind speeds are encountered on the right side of the hurricane s center, where the total speed is the sum of the hurricane s forward speed and its rotational speed, notable effects on the storm surge height will depend on its track, whether to the right or left of the site of interest. We assess the effect of climate change on storm surge levels at 57 locations along the NJ and NY coastlines, as shown in Fig. 3. These sites are chosen to broadly investigate the spatial variation of the storm surge levels along the NJ and NY coastlines. Speci ﬁ cally, the sites cover ﬁ ve highly populated regions that include the NJ open coastline, Rockaway and Long Beach barrier islands at Long Island, Jamaica bay, upper bay, and lower bay. The locations included 38 equally distributed sites that are 5 km apart along the NJ open coastline between Cape May and Sandy Hook, seven sites along Rockaway and Long Beach barrier Islands in Long Island, NY, ﬁ ve sites along the perimeter of Jamaica bay, six sites in Lower, Raritan, and Sandy Hook bays to capture the effect of topography change and the Battery. Of these locations, we choose six representative sites of the ﬁ ve regions for a detailed assessment of the impact of climate change. ﬂ The effect of climate change is assessed by studying the lowprobability high consequence ﬂ ood levels. Because just about 2000 TCs were generated for each climate model, the maximum number of years for a reliable return period is limited to 500 years. Figure 4 shows the Pareto distribution ﬁ t of the peak TC storm surge heights return period along with the 90th percentile con ﬁ dence interval for the six representative study sites for both historical and future intervals. The plots show a negative or no change in the return periods between historical and future periods at Battery and Long Island. In contrast, increased ﬂ ood levels are noted at the other stations in the future period due to climate change, especially in the 500-year return period levels. The highest impact is in Raritan Bay. Figure 5 shows the spatial variation along the NJ coastline and in the New York metropolitan area of the 100and 500-year return periods of the historical period. The plot also shows corresponding percentage changes between the future ( ) and historical ( ) periods, de ﬁ ned as Percent of change 100 (1) For the historical period, the 100and 500-year storm surge return periods are noted to have higher ﬂ ood levels along the southern parts of the NJ coastline (south of Atlantic City) than the northern part of the NJ coastline and the inner bays. This happens because the TCs move parallel and close to the NJ coastline, as discussed above, and due to the topography of the southern part of the NJ coastline. Along the coastline of Long Island, higher ﬂ ood levels are because this coastline faces the track of most TCs. Also, the inner bays (Sandy Hook, Raritan, Jamaica, upper, and lower bays) experience relatively large 100and 500-year peak storm surge return periods because the bays have a concave inlet, which ampli ﬁ es positive surges through the coastal funneling effect . In the future period, the 100-year return period ﬂ ood levels along the northern part of NJ coastline would decrease slightly by percentages up to 3.5%. In contrast, along the southern part of the NJ coastline, climate change would induce an increase in the 100year return by up to 4%. This happens because the number of TCs, in the synthetic data sets, traveling toward the Northern area of our domain would decrease, while more TCs could make landfall or be directed toward the southern part of NJ and Delaware bay, as shown in Fig. 2a. Because more intense hurricanes in the future period could track toward the coastline, as deduced from Fig. 2b, the percent changes of the 500-year return period along the NJ coastline ranges from zero in the northern part to 12% in the southern part. In contrast, negative changes in the 100and 500year return periods are noted along the coastline of Long Island as the calculated density of synthetic TCs that pass by this area would decrease in the future period in comparison to that in the historical period. Also, most of the intense hurricanes in the data set would not reach the Long Island coastline and deviate eastwards, such that this coastline will be on the west side of hurricanes, which is less prone to high storm surges. On the other hand, the changes in the 100-year return period are between 3.5% at the Battery and 1.5% in Jamaica bay because the density of the TCs that pass by this area would decrease. However, a 12% increase in the 500-year return periods would occur at Sandy Hook and in Raritan Bay, while up to 5% increase would occur in the upperand lower bays and in Jamaica bay. This is because the storm data sets show that in the future period, more intense the bays hurricanes would approach the southern part of entrance, as shown in Fig. 2b. Predicting low-probability events while considering uncertainties is in climate change and using different approaches challenging. As such, it is important to compare the above results to those that have been previously published under different assumptions. Garner et al. predicted a negative change in the storm surge height return periods at the Battery, which matches our ﬁ ndings. The reason for the difference in the percentage may be because they used different data sets and different domains. Also, their future projections were not bias-corrected and their study did not account for the effect of waves. Another study by Marsooli et al. showed an average increase of 6% in the 100-year return period at the southern part of the New Jersey coastline ﬁ ﬁ which is slightly larger than our 4% prediction. Also, Lin et al. , and Marsooli et al. showed positive changes in the Battery which contradicts our ﬁ ndings and those of Garner et al. . This discrepancy might be because Lin et al. and Marsooli et al. considered the effects of tides. They also used a different computational mesh. The same reason applies to the predictions of percentage change in Jamaica bay by Marsooli et al. who showed a positive change but with slightly higher magnitudes than current predictions. When considering the above results, it is important to recognize the sources of uncertainties associated with the projections. One uncertainty results from the nonlinear interaction between tides and storm surge, which could impact total water level, especially in the case of low-tides . However, adding tides to the surge adds large uncertainties in predicted water levels because of the high uncertainty in the hurricanes timing. Another source of uncertainty is the small variation in the size of the synthetic TC, represented by the radius of maximum sustained wind speed. The considered radii range varied between 40 and 60 km restricting the ML model to this range. Moreover, using the ML model to predict the storm surge heights of more severe TCs than those provided in the training data set would include higher uncertainties. These variations can be incorporated into future studies when more data on synthetic storms becomes available. The study of the effect of greenhouse warming on the vulnerability of coastal areas to ﬂ ood hazards is important for long-term development and planning. Such studies require a large number of TCs, which are not available in the historical data. We use thousands of synthetic TCs to determine the impact of climate change on storm surges along the shores of New York and New Jersey. Previously, highﬁ delity hydrodynamic models were used to predict storm surge heights from these TCs, which is computationally expensive. To reduce the computational burden and consider a broader TC distribution, we develop machine learning models to predict the peak storm surge height from the TCs. The modeling and analysis were applied at 57 different locations along NJ, Long Island coastlines, and the Raritan, Sandy Hook, Jamaica, lower, and upper bays. The ML model was trained, validated, and tested using a data set generated from the ADvanced CIRCulation and Simulating WAves Nearshore (ADCIRC SWAN) coupled model, including the effects of waves on storm surge levels. TC parameters including, maximum sustained wind speed, upperand lower-latitudinal, rightand leftlongitudinal distances at three different moments, and the minimum distance between the study site and TC eye, constituted the input features to the ML model. To discern the effects of TC climatology change, we applied the ML model to synthetic storms (1980 2000), and future (2080 2100) periods. over historical Analysis of these storms shows that while climate change would cause more high-intense hurricanes to reach higher latitudes including the study area, most of them would shift further to the east. The analysis also shows a higher probability that storms would make landfall in the southern part of the NJ coastline in the future period. The ML-predicted storm surge heights were used to generate return period curves. The results indicate a decrease in the 100and 500-year storm surge return periods at the Battery and Long Island coastline, in agreement with some previous results. In contrast, an increase in the storm surge levels is noted over the southern parts of NJ coastline and in the inner bays, also in agreement with previous results. These results demonstrate the capability of using ML models, at a fraction of the computational cost of highﬁ delity simulations, when performing risk-informed coastal planning, development, or management require consideration of uncertainties associated with climate change. that The training data set of the ML storm surge model was generated from the coupled ADCIRC SWAN simulations of storm surge resulting from 10,300 synthetic TCs that were used in Ayyad et al. but for different stations except for Battery and stations close to Atlantic City. Thus, the used data sets have the same characteristics when compared to that used in Ayyad et al. (2022). The used data set spans all ﬁ ve hurricane categories and tropical storms. The data set was imbalanced such that the majority of the simulated TCs generate a peak storm surge height of more than 0.5 m. Training an ML model using this imbalanced data set generates a surrogate model that underestimates the predicted storm surge heights. Thus, we followed the procedure of Ayyad et al. by dividing the data set into two smaller ones. The two data sets include TCs that pass within and outside a radius of 100 km from the location of interest, referred to as DS-1 and DS-2, respectively. Following the ﬁ ndings of Ayyad et al. , the ML model input features include six parameters that identify the TC characteristics, namely the maximum sustained wind speed, radius of maximum wind, upper and lower latitudinal distances, and right and left longitudinal distances, at three-time steps, namely 6-h post, 0-, and 6-hours prior to the time of the closest TC location to the study site. Also, the minimum distance between the TC location to the study site is added to the ML model features which makes a total number of 19 features used. Feature selection was conducted by Ayyad et al. using the correlation coef ﬁ cient and mutual information values between the input feature and corresponding simulated storm surge height of the training part of the two data sets separately. Only 13 different features for each of the two data sets were chosen. The radius of maximum wind speed, left longitudinal and upper latitudinal distances were removed from both data sets, while the lower latitudinal and right longitudinal distances were removed from DS-1 and DS-2, respectively. For each of the 57 study sites, we generate two ML models, one for the DS-1 data set and the other for the DS-2 data set. Thus, a total of 114 ML models are trained. Different ML algorithms can be used to train the surrogate model. Ayyad et al. found that Adaptive Boost (AdaBoost) algorithm with support vector regressor (SVR) as the base estimator has the best performance for among seven different ML algorithms. Tuning the hyperparameters is crucial to avoid generating either an underor overﬁ tted model. To tune the model, we ﬁ rstly divided the DS-1 and DS-2 models to 60% for training, 20% for validation, and the testing the model s performance. The training was rest performed using the scikit-learn library on Python . The used hyper-parameters were tuned using the cross-validation grid search method, by trying all possible combinations of the hyperparameters and getting the best-performing con ﬁ guration for training. Ayyad et al. found that the tuned hyper-parameters of DS-1 data set differ from those of the DS-2 data set. For DS-1, the learning rate is set to 0.09, the number of weak learners is set to 15, and the regularization and epsilon-insensitive loss parameters of SVR are set to 90 and 0.09, respectively. For the DS-2 data set, the learning rate is set to 0.05, the number of weak learners is set to 50, and the regularization and epsilon-insensitive loss parameters of SVR are set to 65 and 0.03, respectively. Exponential loss function is used for the two data sets. The predicted peak storm surge height from the trained machine learning model ( ) should be evaluated against those calculated from ADCIRC SWAN model ( ). In this study, we used the correlation coef ﬁ cient ( ), de ﬁ ned as cov , coef ﬁ cient of determination ( 2), de ﬁ ned as 2 1 , and Root mean square error (RMSE), de ﬁ ned as RMSE 1 (2) (3) (4) to evaluate the ML model s performance, where cov(. , . ) and , respectively represent the covariance and standard deviation, is the size of the data set, and the overline represents the average value. A perfect match is considered when and 2 are equal to one, while RMSE is equal to zero. The probabilistic ﬂ ood hazard assessment, shown in Figs. 4 and 5, is presented in terms of the peak storm surge height at the 57 study sites. The return period ( ) of storm surge height ( ) that exceeds a given threshold ( ) is given by 1 1 (5) where the equation assumes a stationary Poisson distribution for the storm s arrival. is the TC annual frequency and is the cumulative density function of the TC storm surge heights where its long tail is modeled using the generalized Pareto distribution (GPD). The GPD threshold value is selected by trial and error so that the modeled CDF well represents the data points. The GPD controlling parameters are estimated using the maximumlikelihood method. Global climate models (GCMs) are designed to model the climate globally and, as such, they may be biased. We used the approach adopted by Lin et al. , and Marsooli et al. to correct the bias in the TC frequency, density, and return period curve estimates for each GCM. The bias is calculated by subtracting the model-based estimates, i.e. results based on the GCM data set, for the historical period from the NCEP-based estimates, i.e. results based on the NCEP data set. Then, this bias is removed from the model-based estimates for the future period. The presented results in this study are the weighted average of the results of the four used GCMs. A weighting factor ( ) is allocated for each GCM ( ) which is given by (6) is the Willmott skill score of GCM . This score is where determined by comparing the NCEP-based storm surge height return period with the one projected by the GCMs for the historical period, which is de ﬁ ned as 1 (7) where, is the th-year storm surge return period which is summed over the years, and is the mean value of . The skill value ranges between zero and one with a perfect agreement at one. The weights of the four climate stations are presented in Fig. 6. The weights range between 0.16 and 0.34. The weights show that the historical data of MPI5 and MRI5 GCMs matches those of the NCEP data along the NJ coastline, while the weights of all GCMs are almost the same over the other regions. This approach was used previously by Lin et al. , and Marsooli et al. . To establish the goodness of the model ﬁ t, we compare peak storm surge heights as predicted from the ML model and those calculated from ADCIRC SWAN model for the 57 study sites. The trained ML models are tested using the DS-1 and DS-2 test data sets. The performance metrics, namely the correlation and determination coef ﬁ cients and the RMSE, are presented in Fig. 7. The plots show that the minimum values of correlation coef ﬁ cient ( ) and coef ﬁ cient of determination ( 2) of the two data sets are 0.84, and 0.71, respectively. The RMSE ranges between 6.5 and 11 cm for data set DS-1, which has a maximum storm surge height value of 2.2 m, and between 2.5 and 4.5 cm for data set DS-2, which has a maximum storm surge height value of 90 cm. Given that peak surge heights are respectively up to 2.5 and 0.9 m for data sets DS-1 and DS-2, the relatively low RMSE values assert the goodness of the ML predictions. The scatter plots of Fig. 8, showing peak storm surge heights calculated using ADCIRC SWAN model with those predicted from the ML models, con ﬁ rm ﬁ ﬁ further the goodness of the ML model. The plots are presented for the six representative stations. For a perfect ﬁ t, the scatter points should ﬁ t a diagonal line having a slope of 1. The slopes of the linear ﬁ t for the representative sites range between 0.985 and 1.001. The mean, and standard deviation of the error, de ﬁ ned by the difference between the storm surge height calculated using ADCIRC SWAN and predicted from ML models for the two test data sets, at the six stations are, respectively, near zero and 7.8 cm. The reference lines, represented by dashed lines, in Fig. 8 indicate the 95th and 99th percentiles calculated from the normal distribution ﬁ ts of the errors, on average 53 out of 2072 storms are outside the 99th percentile range and 107 are outside the 95th percentile range. These results show that, to a great extent, the peak storm surge heights predicted from the ML models match those simulated by the ADCIRC SWAN model.
test_npjclisci.pickle ---------- ['Incorrect Asian aerosols affecting the attribution and projection of regional climate change in CMIP6 models']
Anthropogenic aerosol (AA) forcing has been shown as a critical driver of climate change over Asia since the mid-20th century. Here we show that almost all Coupled Model Intercomparison Project Phase 6 (CMIP6) models fail to capture the observed dipole pattern of aerosol optical depth (AOD) trends over Asia during 2006 2014, last decade of CMIP6 historical simulation, due to an opposite trend over eastern China compared with observations. The incorrect AOD trend over China is attributed to problematic AA emissions adopted by CMIP6. There are obvious differences in simulated regional aerosol radiative forcing and temperature responses over Asia when using two different emissions inventories (one adopted by CMIP6; the other from Peking university, a more trustworthy inventory) to driving a global aerosol-climate model separately. We further show that some widely adopted CMIP6 pathways (after 2015) also signi ﬁ cantly underestimate the more recent decline in AA emissions over China. These ﬂ aws may bring about errors to the CMIP6-based regional climate attribution over Asia for the last two decades and projection for the next few decades, previously anticipated to inform a wide range of impact analysis. Asia is one of the most vulnerable regions facing climate change risks because of its large and dense population, rapid industrial development, and severe water stress . Climate change due to anthropogenic factors, such as greenhouse gases (GHGs), aerosols, and land use, has seriously impacted natural ecosystems (e.g., agriculture, biodiversity, water, and ocean) and human society in Asia . Asia also features the highest loading of anthropogenic aerosols (AA) over the globe . The absolute value of aerosol radiative forcing is even larger than GHG in Asia during certain periods . Many studies have shown that AA forcing is a key factor driving historical climate change over Asia . A widespread summertime drying in South Asia during the second half of the 20th century has been primarily attributed to increased AA . Regional aerosolcloud interaction could be responsible for changes in extreme rainfall over India and China during 1979 2005 . Recent studies also showed that AA forcing dominated the observed interdecadal upper-tropospheric cooling over East Asia during summer and weakening of the East Asian summer monsoon after the 1950s . Mostly, these attribution studies rely on global climate models (GCMs), especially from the previous four phases of Coupled Intercomparison Project (CMIP). Attribution works pubModel lished in the last years to quantify human impact on observed climate trends, especially aerosol s role, focused on the late 20th century when AA emissions increase monotonically in Asia. The consideration of the more recent period of the ﬁ rst two decades of the 21st century is usually limited by the fact that the various specially designed historical experiment setup of CMIP5 ends in 2005. The latest CMIP6 has extended the historical simulation up to 2014, thus enabling the attribution of a more recent period. However, robust quanti ﬁ cation of the role of aerosols in historical climate trends requires a correct representation of the spatiotemporal variation of aerosols in GCMs, which can be problematic in the early 21st century, because the fast economic growth is also accompanied by increasingly stricter air pollution regulations in China and India . Here we examine the simulated 2006 2014 trends in aerosol optical depths (AODs) at 550 nm over Asia (India and China) in the historical simulations of the 32 CMIP6 models. We explain the model-observation discrepancy by tracking the emissions inventory assumption, as in Paulot et al. . We estimate the impact of alternative AA emissions inventories on effective radiative forcing (ERF) using a global aerosol-climate model. Lastly, we discuss the implication of the apparently ﬂ awed Community Emissions Data System (CEDS) inventory adopted by CMIP6 models on nearterm climate projection beyond 2015 2020. from multiple sources of observation, Trends of AOD and AA emissions over Asia China and India are the two largest emitters of AA in Asia. Figure 1 shows the relative changes in annual mean AODs at 550 nm over eastern China (EC, 100° 122°E, 20° 40°N) and India (70° 90°E, 8° 30°N) including the Moderate Resolution Imaging Spectroradiometer (MODIS), Multiangle Imaging Spectroradiometer (MISR), and Modern-Era Retrospective Analysis for Research and Applications, version 2 (MERRA2). The results from the MERRA-2 and satellite products are also shown separately in Supplementary Figure 1. Consistent with the growth in previous decades, AOD in India steadily increases in the early 21st century (Fig. 1b), with a trend of 14.7% per decade for 2006 2014. There is the largest increase of 18% per decade from MODIS data, followed by smaller trends of 13% per decade from MERRA-2 and MISR data (Supplementary Fig. 1). Almost all CMIP6 models used in this study reproduce the upward trend of AOD in India, with a mean trend of 14.5% (Fig. 1b), slightly less than the observation mean. The increased AOD is entirely from the increase in anthropogenic AOD in those models (Fig. 1d). The increase in AOD over India is driven by an increase in AA loadings fueled by rapid industrialization and urbanization . In both the inventories from CEDS and Peking university (PKU), there are almost monotonous increases in anthropogenic sulfur dioxide (SO ), black carbon (BC), organic carbon (OC) emissions in India from 2006 to 2014 (Fig. 2), with each trend being more than 2% per year. In particular, the increase in anthropogenic SO reaches 4.5 8.5% per year. Previous studies have indicated an increase of over 40% in anthropogenic SO emissions over India between 2005 and 2010 and a corresponding increase of 54% from 2006 to 2014 . The increases in major AA emissions in India were also reported by a study based on the Ozone Monitoring Instrument (OMI) Ultraviolet Aerosol Index . In stark contrast, AOD over EC starts a decade long decrease since 2006, reversing the trends in previous decades (Fig. 1a). Observation mean shows a drop of 10.4% per decade over EC for the period 2006 2014 ( 10% and 14% per decade for MODIS and MISR; Supplementary Fig. 1). Downward trends of AODs to varying degrees persist in most key areas of China (Supplementary Fig. 2), with the largest drop in Sichuan Basin (SCB) at 18% per decade. The AOD decrease is also supported by Aerosol Robotic Network (AERONET) and Cloud-Aerosol Lidar with Orthogonal Polarization (CALIOP) data sets, and is consistent with reported surface PM2.5 concentration trend . Surprisingly, most of the CMIP6 models (25 of the 32 models, Supplementary Fig. 2) simulate opposite AOD trends over EC compared with observations, with the model average at 7.5% per decade (Fig. 1a and Supplementary Table 2). The wrongfully simulated upward trend is completely due to the anthropogenic portion (Fig. 1c). The largest increase of 13.2% per decade occurs over SCB in the multimodel mean (MMM), contradicting the observed trend of 18% per decade (Supplementary Fig. 2). For some other important industrial areas North China Plain (NCP), Yangtze River Delta (YRD), and Pearl River Delta (PRD), there is also an obvious contradiction between observation and MMM (NCP: 6.4 vs. 3.2% per decade, YRD: 9.2 vs. 4.5% per decade, and PRD: 15.4 vs. 10.3% per decade; Supplementary Fig. 2). Notably, the observed AOD trend prior to 2006 appears to be well simulated by the models. The major discrepancy between CMIP6 models and observations after 2006 needs scrutiny. The local AOD change (Fig. 1) is indicative of emission trend, although the complexity can arise from cross-region transport. For example, the western sub-regions of China can be affected by Indian emissions. Previous study reported that the increases in Indian aerosol emissions could enhance the aerosol burdens in East Asia. This further demonstrates that for the entire EC, the decline of AOD must be primarily due to the decrease in local aerosol emissions in China. Aerosol species over EC primarily consist of anthropogenic components, so it is likely that the reported reduction in anthropogenic emissions has driven the observed decline of AOD . Indeed, emissions of major AA over key regions of China have dropped since 2006 in the inventory developed at PKU (Fig. 2). There are statistically signi ﬁ cant trends of 3.1, 1.4, and 3.4% per year in anthropogenic SO , BC, and OC emissions. Conversely, AA regions of China are assumed to be emissions over most continuously increasing during 2006 2014 in CEDS historical inventory (Fig. 2), leading the models to consistently fail to capture the observed downward trend. The CEDS inventory shows trends of 0.13% (but statistically insigni ﬁ cant), 2.7, and 3.4% per year in anthropogenic SO , BC, and OC emissions over EC during 2006 2014, respectively, with OC contradicting with PKU inventory the most. Comparing CEDS and PKU inventories, there are completely opposite trends of all three types of AA emissions over PRD, SCB, and central China (Supplementary Fig. 2). Despite having declining trends of anthropogenic SO emissions over NCP and YRD, CEDS has much weaker trend than those in PKU inventory. Previous study has also reported that an incorrect AOD trend over EC after 2007 was simulated due to the biases in AA emissions in CEDS inventory. Are the changes during 2006 2014 in the PKU inventory trustworthy? Many measures have been put into effect pushing the transformation of energy system and improvement of air quality in China since 2006. The Chinese government had set strict emissions reduction targets in the 11th Five-Year plan (FYP), which called for SO (precursor of dominating AA in China) emissions to be decreased by 10% during the period of 2006 2010. Recent studies showed that the decline of SO emission might have exceeded the target, thanks to ﬂ ue gas desulfurization and closure small but high-emitting power-generation units . In of particular, China added PM2.5 into its air quality standards for the ﬁ rst time in 2010, and since then implemented a suite of clean air policies . The CEDS inventory follows the International Energy Agency (IEA) energy statistics, and may not fully consider the effects of recent measures in China . Based on satellite data, Li et al. showed that SO emissions in China decreased by 76% from 2006 to 2016. An improved technology-based inventory developed at Tsinghua University also shows similar trend as the one used here. The decline of aerosol emission is also consistent with the surface brightening in recent observational record . Another important aspect is that the rural residential energy consumption data for China have been updated based on a nationwide survey and a nationwide fuel weighing campaign in PKU inventory . It was found that the consumption of wood and crop residues in rural China for cooking and heating decreased by 63 and 51%, respectively, from 1992 to 2012, much greater than the 15 and 8% values reported by the IEA and Food and Agriculture Organization . In addition, there are differences in emission factors (EFs) between both inventories. Many EFs for developing countries are not used in CEDS inventory , but are included in PKU inventory . These contribute to the underlying differences in AA emissions between the two inventories. ERF due to different AA emissions over Asia To con ﬁ rm that the emission assumption is the main reason for the model-observation difference in AOD trend, we simulate AOD changes using a global aerosol-climate model (BCC_AGCM2.0_CUACE/Aero) separately driven by both inventories at two time points of 2006 and 2014 (Fig. 3). The model reasonably reproduces the observed dipole pattern of changes in AODs over Asia when using PKU inventory (Fig. 3b), with an increase of 0.04 over India but a decrease of 0.05 over EC between 2006 and 2014, both of which are close to the observed changes (India: 0.04~0.06, China: 0.01 to 0.05). However, the dipole feature (i.e., increase in India but decrease in China) is missing when the simulation is driven by CEDS inventory (Fig. 3a). The China region sees AOD increase as in CMIP6 models. Note that a simulated increase of 0.02 in AOD over India when using CEDS inventory is only half of that when using PKU inventory. This is partly attributable to the smaller increase in anthropogenic SO emission over India in the CEDS inventory. The contradicting AOD trends can have profound climatic implications. We quantify the effects on the aerosol effective radiative forcing (ERF), one of the most widely used metrics to examine how various factors contribute to climate change. The magnitudes of simulated AA ERFs over India between 2006 and 2014 are roughly comparable for CEDS and PKU inventories ( 1.0 vs. 0.9 W m , Fig. 3c). However, there is a major difference over ﬁ ﬁ ﬁ ﬁ EC using both inventories (CEDS: 0.8 W m vs. PKU: 0.7 W m ). Such a difference is especially evident on a seasonal scale (Fig. 3d). Simulated AA ERF over EC in summer is 1.6 W m for CEDS inventory, but the corresponding value reaches up to 2.5 W m for PKU inventory. The spatial contrast of AA ERFs due to inventories assumption can lead to different responses of local climate, such as monsoon circulation , precipitation , and climate extremes , and also further produce signi ﬁ cantly different impacts on remote regions . Figure 4 shows that there are large differences in simulated surface air temperature responses to aerosol forcing over Asia between 2006 and 2014 due to various emissions inventories. Simulated surface temperatures averaged over India and EC are decreased by 0.17 K for CEDS inventory, respectively. However, the corresponding changes are near zero and 0.18 K for PKU inventory. The point is that these regional climate responses are only from the rapid adjustment of the atmosphere to aerosol forcing, without ocean mediation. Further study will be needed to quantify the total equilibrium response to aerosol forcing. In addition, note that the competing of absorbing and scattering aerosols are always complex. If the spatial dipoles of them are different, the response of climate could be also different. Given the well-known importance of AA in forcing regional climate change over Asia, the incorrect AA emissions as adopted in CMIP6 models likely affect the retrospective analysis and attribution of past regional climate change based on those models, when the focused time period includes the early part of the 21st century. Implication for future climate projection Looking beyond 2014 and into the future, a few recent studies demonstrated that the AA emissions over China were cut at an even greater rate after 2014 , supported by the stronger downward trend in observed AODs (Fig. 1a). Notably, in 2013 China promulgated the toughest-ever clean air policy Action Plan for the Prevention and Control of Air Pollution (known as Ten Statements of Atmosphere ) with intensive 5 years of efforts (2013 2017). The surface mass concentrations of ﬁ ne particulate matters nationwide have decreased since then . The removal of AA will induce local warming and perturb the climate system . A correct depiction of this unmasking is key for reliable decadal prediction . However, Fig. 4 shows that the reductions of SO , BC, and OC emissions from 2015 to 2017 in the four socio-economic pathways (SSPs) adopted by CMIP6 models are far slower than the reported observation-based changes over China . Most SSPs, even the SSP1-1.9 and SSP1-2.6 that have very stringent air pollution control, will likely to underestimate the AA emission cut. Notably, SSP3-7.0, a pathway with weak mitigation that seems to agree better with the carbon emission trajectory and the current political reality, even show further increases in AA emissions over China, such as BC and OC, which contributes to the incorrect trend in AOD (Fig. 5). Although the drop of AOD over EC for the period of 2006 2017 has been shown by combining the historical and SSP2-4.5 data sets from 5 CMIP6 models , the trend is due to the reduced AA emissions from 2015 to 2017 in SSP2-4.5 (Fig. 5), which is signi ﬁ cantly weaker than the observation. Beyond 2020, more clean air policies have been designed. According to the established air quality control plan and mediumto long-term cleaning air goal (2030 2050), China aims to cut the annual mean PM2.5 concentration down to 35 µg m in 2030 and 15 µg m in 2050 in all regions of the country (national average level of 39 µg m in 2018). In addition, an ambitious plan of carbon emission peak before 2030 and a goal of possible carbon neutralization before 2060 have been announced by the Chinese government recently, which require large decrease of coal burning. These will likely lead to continuous and stringent reduction in AA emissions over China in the coming decade. All these apparent ﬂ aws may bring about errors to the projection of regional climate change based on CMIP6. We expect that the in ﬂ uence of emissions biases will likely hold on by the middle of the 21st century. Note that although the full range of SSPs (from the greenest pathways of SSP1-1.9 to the dirty ones such as SSP5-8.5) will likely cover the future pathway, it is dif ﬁ cult for the modeling groups to have computationally resources to conduct simulations for all these Instead, most of the modeling pathways for future projection. centers participating in the Aerosol Chemistry Model Intercomparison Project (AeroChemMIP) have opted to select only a limited subset. Some greener pathways may be able to capture the emission trend in recent years and next decades (Fig. 5), but they are the ones that get heavily used in the Scenario Model not (ScenarioMIP) and post-CMIP6 large Intercomparison Project ensemble simulations. For example, CESM2 s ongoing large ensemble (100) will use SSP3-7.0, and their submission to ScenarioMIP has 10 for SSP3-7.0 and only three for other three pathways (http://www.cesm.ucar.edu/projects/community-projects/ LENS2/). Adopting a higher emission pathway is understandable, because apparently the carbon dioxide (CO ) emission in those pathways is already different from observation (Fig. 5a) or deemed unlikely in the next decade . and mitigation . Regional climate attribution/projection for Asia region will be affected by the known bias in AOD trend for the last ten years and its potential extension into future. It is worth noting that a dipole pattern of AOD changes over Asia likely will persist for a long time in the future . While the bias/error as revealed here is for EC, the importance of aerosol trajectory also applies to other emerging economies, such as India and Africa. Therefore, a deeper understanding of the climate response to such an even distribution of AA forcing (analogous to the decrease over the western hemisphere and increase over Asia since the 1980s) is vital for projecting regional climate change. The purpose of this study is to bring more awareness to the known bias and, more importantly, its implication to attribution/ projection studies especially for Asia region. The timely communication is critical given the decentralized structure of CMIP6 activities. For example, the regional aerosol forcing bias may have been noted by the AeroChemMIP participants, but its climate implication may not be well known to other research communities, such as the Detection and Attribution Model Intercomparison Project (DAMIP) and ScenarioMIP, which focus more on detection/attribution and future climate projection, respectively. We acknowledge that the projection of future climate, especially for the long-term (i.e., 2100), is subject to various sources of model structural uncertainty (e.g., aerosol-cloud interaction, cloud physics, convection schemes, and ocean-atmosphere interaction) . However, the issue we are addressing in this paper is not a source of uncertainty due to limited understanding, but a known systemic bias in almost all models, clearly demonstrated for the last 15 years and likely continuing into future. Although global warming will be dominated by the levels of greenhouse gases (GHG) for the long-term (e.g., the 2nd half of 21st century), the near-term projection for the next 30 years is also in Paris critical, because the 1.5 and 2 °C targets laid out agreement can be easily breached if the GHG emissions are left In a separate study , we have quantitatively unchecked. demonstrated that the assumption of aerosol unmasking rate will have major effect of warming rate and therefore, the timing and likelihood of meeting/breaching the warming targets of 1.5 and 2 °C. Numbers of previous studies have indicated the leading role of aerosol forcing in many aspects of observed climate change at regional scale and the near-term climate projection can be affected by the future aerosol trajectory . The exceedance of 1.5 and 2 °C targets can be earlier if the aerosol unmasking is quicker than anticipated, as hinted by this paper. This underestimation of aerosol decline trends and its regional warming consequences need to be brought to great awareness. The recommended practice of using the existing CMIP6 model output, when the research goal is to study aerosol s role in the near-term climate change (e.g., next 30 years), is to adopt greener pathways of SSP1-1.9 and SSP1-2.6, rather than other more popular high-end pathways, because the underestimated CO warming (lagging the emission change) will be small in the near-term. This study also hopes to motivate the research groups whose focuses are on decadal climate attribution/prediction to rerun the simulation since 2006 with alternative pathways from CESD (for 2006 2014) and SSPs (for 2015 and beyond). The updated pathway should be informed by more recent observations and social-economic dataset (e.g., the PKU dataset here). The updated simulation needs to be a larger ensemble (>10) to demonstrate the impact of mis-estimated AA emission on regional climate and to test its statistical signi ﬁ cance. the scienti ﬁ c community should Our study emphasizes that cautiously treat the outputs after 2006 from CMIP6 models, which will be forming the basis for future climate assessments, adaptation, AOD and emissions data Simulations
test_npjclisci.pickle ---------- ['A possible relation between Arctic sea ice and late season Indian Summer Monsoon Rainfall extremes']
The out-of-phase inter-decadal co-variability between summer (JJA) sea ice extent (SIE) in the Kara Sea (KS) sector of the Arctic Ocean and Indian Summer Monsoon Rainfall (ISMR) is found to be weakened during the recent decades with rapidly declining SIE in the KS (since the 1980s). However, SIE in the KS and frequency of ISMR extremes are found to have a consistent out-of-phase relation during the rapidly declining SIE periods. A possible physical mechanism for the relation between the late-season ISMR extremes and summer SIE in the KS is suggested, focusing on the recent years since the 1980s. The Indian Summer Monsoon Rainfall (ISMR) is the major source of drinking water to more than a billion people, owing to its roughly 70% contribution to the annual precipitation. The variability in it has a direct impact on agriculture and thus strongly in ﬂ uences the national economy. The increasing frequency of extreme ISMR events , causing severe ﬂ ooding and huge socio-economic challenges, demand adequate adaptation and mitigation strategies. Understanding both the local driving factors and remote teleconnections of extreme ISMR events is key for better assessment and improved future projections of extreme ISMR events at different time scales. This is in particular of great importance given that in a warmer climate, the climate models project further increase in the frequency of ISMR extremes . Although a considerable amount of studies have been conducted on northern hemisphere mid-latitude teleconnections to ISMR, only a few of those have identi ﬁ ed linkages between ISMR and sea ice in the Arctic. Krishnamurty et al. proposed that a large amount of heat, released in the atmosphere during extreme rainfall events over northwest India, ultimately travels to the Canadian Arctic region causing signi ﬁ cant sea ice loss. It is further noted that the amount of sea ice concentration (SIC) variability in the Arctic due to the Rossby wave train generated from East Asian Summer monsoon and Indian Summer Monsoon together is comparable with the SIC variability induced by Arctic Oscillation . On the other hand, while the effects of Arctic sea ice changes on the mid-latitudes are still debated , it is often argued that concurrent increase in mid-latitude extreme weather events is associated with Arctic Ampli ﬁ cation induced changes in sea ice conditions . A recent study further suggests that the impact of projected future sea ice changes in the Arctic can also reach the tropics . Since the beginning of the satellite records in 1979, the Arctic sea ice extent (SIE) has been consistently declining at a very alarming rate with the largest trend of 12.9 ± 2.2% per decade in September and about 4.4% per decade in annual mean . However, it is still unclear if this rapid sea ice decline can in ﬂ uence the tropical extremes, or in particular the extreme rainfall events during ISMR. Here, we investigate the Arctic sea ice and ISMR relation for the last ~100 years. The speci ﬁ c focus of the study is on the Kara Sea (KS) SIE, which is argued to have a strong in ﬂ uence on the lower latitudes . Further, the KS is one of the regions with the largest summer sea ice loss causing strong seasonal variability in sea ice cover and heat ﬂ uxes to the atmosphere . A possible physical mechanism for the effect of SIE variability in the KS on ISMR extremes is also proposed. The multi-decadal variability of SIE in the KS during summer (JJA) and ISMR (JJAS) in central India (19 26 N; 75 85 E) is shown in Fig. 1a. Rapid decline of SIE is observed since the 1980s, and during the Early Twentieth Century Warming period (ETCW, 1920 1940); the time period which exhibited rapid warming of the surface air temperature (SAT) with reduced SIE in the Arctic Ocean and followed by an increase in SIE. The mean ISMR showed an opposite phase co-variability with an increasing trend during the ETCW and a subsequent decrease. However, during the recent rapid SIE decline since 1980, mean ISMR does not show a similar opposite phase co-variability. The correlation between the time series of JJA SIE in the KS and mean ISMR rainfall, as shown in Fig. 1a, reduces from 0.6 ( < 0.01) during 1901 1979 to 0.1 ( > 0.1) for the period 1980 2016. It should be noted here that the mid-latitude natural climate variabilities, e.g., Atlantic Multidecadal Oscillation (AMO), Paci ﬁ c Decadal Oscillation (PDO), are argued to contribute to the warming in the Arctic during ETCW . Further, their potential in ﬂ uence on multidecadal variability of ISMR is also known . On the contrary, the recent warming trend in the Arctic is mostly driven by anthropogenic forcing . Thus, it can be argued that the observed out-of-phase co-variability in SIE and ISMR during ETCW is mostly driven by the mid-latitude natural climate variabilities (e.g AMO, PDO), whereas the differential response of those to anthropogenic forcing induced warming could possibly have affected the mid-latitude control on their relation. Interestingly, the frequency of ISMR extremes (de ﬁ ned as number of grid points in central India with daily rainfall > 150 mm day ) is found to have a consistently increasing trend with declining SIE during both ETCW and recent warming since the 1980s. During these periods the correlation between JJA SIE in the ﬁ ﬁ ﬁ ﬂ ﬁ KS and frequency of IMSR extremes, as shown in Fig. 1a, shows a very high correlation ( 0.9, < 0.01 during 1920 1940 and 0.8, < 0.01 during 1980 2016). To further analyse this relation and the possible physical mechanism for this, we next focus on the recent warming period since 1980, when the reanalysis products are of considerably better quality than earlier periods. This would also allow us to delineate the possible mechanisms associated with rapidly increasing ISMR extremes in absence of any prominent change in the mean ISMR trend. ﬂ The intra-decadal variability of the frequency of extreme rainfall events during September is shown in Fig. 1b. We found the intradecadal out-of-phase co-variability between JJA SIE in the KS and frequency of extreme ISMR rainfall is most robust during the later phase of ISMR (Fig. S1), particularly during September. This prompted us to identify the episodes with increased (P1: 1992 1997 and P2: 2004 2010) and reduced (N1: 1986 1991 and N2: 1998 2003) frequency of September extreme events in India as marked in Fig. 1b (see the ﬁ gure caption for Central details). We then performed a composite analysis for those years to obtain further insights on the possible physical mechanism responsible for the observed relation between SIE in the KS and frequency of September extreme events over central India referred to as extreme events only for brevity). (hereafter Considering the relatively longer memory of sea ice than the atmosphere, it can be expected that the atmospheric response to the changes in JJA sea ice is realized in successive months. Thus we performed the composite analysis based on averaged monthly anomalies during August September. To obtain the spatial pattern of sea ice changes associated with the variability in extreme events we plotted the averaged difference in SIC between years with increased and reduced frequency of extreme events (Fig. 1c). The analysis suggests signi ﬁ cant negative SIC anomalies, with maximum magnitude in the KS region, associated with increased frequency of extreme events. The changes in surface heat ﬂ ux due to reduced sea ice can potentially in ﬂ uence the atmospheric conditions . Consistent with the SIC pattern, the largest contribution in heat ﬂ ux to the atmosphere (negative values in Fig. 1d) is observed in KS region indicating the potential importance of the KS sea ice to in ﬂ uence the overlying atmospheric conditions. Next, we investigated the KS sea ice-induced large-scale circulation anomalies associated with the variability in extreme events. Figure 2a shows the averaged difference in upper level (200 hPa) ﬁ geopotential height (GPH) anomaly during August September, between the increased and reduced extreme events years. Signi ﬁ cant positive GPH anomaly over northwest Europe can be noticed, depicting an anomalously strong Euro-Atlantic blockinglike pattern. Simultaneous strengthening of sub-tropical high over East Asia (Fig. 2a), an important upper atmospheric feature favourable for ISMR , is also found. The warming in the Arctic and resulting sea ice loss has been widely argued to in ﬂ uence the mid-latitude weather patterns through altering the jet stream characteristics due to reduced pole-midlatitude temperature gradient (see Cohen et al. and references therein). However, to what extent Arctic sea ice loss is responsible for altering the jet stream characteristics is still being debated . A recent modelling study suggests a combined effect of the Arctic sea ice loss and Eurasian snow cover can induce blocking high events over Europe through anomalous Eurasian wave train . Nonetheless, the signi ﬁ cantly weakened zonal ﬂ ow with increased meridionality (Fig. 2b, c) can induce favourable conditions for anomalous high over northwest Europe during reduced sea ice years in the KS. Further, it has been argued that the dynamical response of the atmosphere to reduced sea ice and surface warming in the Arctic can be important during summer . An anomalous meridional circulation is established with an ascending branch over the warm Barents/KS region and descending branch over northwest Europe (Fig. 2d). This can further result in anomalous high over northwest Europe and warm the SAT (Fig. S2). Analysis of the eddy stream function and Rossby wave activity ﬂ ux during years with increased and reduced extreme events (Fig. 3) suggests propagation of Rossby wave trains from northwest Europe towards East Asia, in ﬂ uencing the subtropical high over East Asia. The wave trains show two major pathways; the ﬁ rst one zonally propagates eastward locked around 60 N latitude and the other one moves southward from Europe before diverting towards the east and reaching the East Asian region. Associated eddy stream functions along this pathway are also notable in Fig. 3, consistent with the GPH anomalies as observed in Fig. 2a. Note that a similar path had been earlier attributed to linking the Arctic Oscillation-induced anomalies and the tropical Indian Ocean precipitation during winter . The above ﬁ ndings suggest a plausible physical mechanism through which sea ice anomalies in the KS region can potentially in ﬂ uence the sub-tropical high over East Asia. In short, reduced SIE in the KS can induce anomalous high over northwest Europe, which triggers a Rossby wave train and induces positive upper-level ﬂ GPH anomalies over the East Asian region. However, the uppertropospheric anomalies thus established in the East Asian region cannot alone cause the extreme events over central India as they require a suf ﬁ cient amount of lower atmospheric moisture supply into the region. We found that the anomalous circulation due to strengthened East Asian sub-tropical high induces upper-level divergence over northwest central India (dashed contour lines in Fig. 2a) during years with increased extreme events. This can further favour the development of cyclonic circulation at the low level. Warm sea surface temperature anomaly in the northwestern Arabian Sea (Fig. S3) along with the upper-level divergence results in the development of anomalous cyclonic circulation at the surface (Fig. 4). Associated with this, enhanced convection can be realized from the anomalous upward vertical velocity over the central Indian region (Fig. 4). Further, it should be noted that the anomalous cyclonic circulation and enhanced convection may not be enough to result in extreme precipitation unless there is an adequate amount of moisture available in this region. In fact, it is known that moisture supplied predominantly from the Arabian Sea plays an important role in causing extreme precipitation events in central India . The anomalous cyclonic circulation, as observed in Fig. 4, the Arabian Sea and causes strengthens the westerlies over enhanced moisture convergence over central India (Fig. S4). Analogous opposite phase circulation features as described above can be found during years with reduced extreme events. Thus, we propose that the superimposition of the upper (induced by SIE changes in KS) and lower level (induced by warm SST anomalies in northern Arabian Sea) circulation anomalies can potentially favour extreme rainfall events over central India during the late ISMR season (Fig. 5). In summary, our results indicate (1) since the 1980s, rapidly declining summer SIE in the KS region exhibits a more robust relationship with the frequency of ISMR extremes, compared to mean ISMR intensity; (2) extreme precipitation events in central India during the late phase of ISMR season can be explained by the combined effect of the upper atmospheric circulation anomalies resulting from reduced SIE in the KS region and lowlevel circulation anomalies over west-central India supported by warm SST anomalies in the north-western Arabian Sea. The extent of sea ice contribution to developing the large-scale upper-level circulation anomalies and their role in favouring ISMR extremes need to be studied in further detail with a combination of observation and modelling studies, given that they often diverge in conclusions on extra-polar impacts of Arctic sea ice changes . ﬁ
test_npjcliac.pickle ---------- ['When, where, and which climate activists have vandalized museums']
Some climate groups have employed disruptive but non-violent tactics to draw public attention to the slow progress in reducing greenhouse gas emissions. In 2022, a new disruptive tactic emerged: vandalizing art and museums. In this Brief Communication, we describe the key ﬁ ndings which are based on an exhaustive search of media articles and social media postings. We ﬁ nd that almost all 38 reported incidents occurred during May December 2022, with protests peaking around the COP 27 conference in Sharm El Sheikh, November 6 18. Once the COP conference was over, museum incidents dwindled to only three in December. Museum vandalism took place in eleven countries, nine of which are in Europe. Even within Europe, 60% of the incidents occurred in just three countries: Germany, Italy, and the U.K. We ﬁ nd sixteen groups were involved in these incidents, but three groups account for 58% of them: Ultima Generazione (Italy and Vatican), Just Stop Oil (the U.K.), and Letzte Generation (Germany). Importantly, these groups are part of the A22 network, which suggests the possibility of some informal coordination on the staging and timing of museum events. None of the legacy environmental groups (such as Greenpeace) are involved in museum protests, although historically some have staged dramatic events to garner media attention. Environmental advocacy has existed for decades. Starting with the 1970 Earth Day protest to the more recent Greta Thunberg s Fridays for Future strikes and the Sunrise movement, activists have used protests, blockades, naming-and-shaming, boycotting, divesting, and litigation to bring attention to their cause . In developing countries, Indigenous Nations have protested against pollution and mining . In Indian Himalayas, the Chipko movement led women to hug trees to prevent their logging . Broadly, a well-developed literature examines repertoires . Scholars note that the speci ﬁ c tactics advocacy groups adopt depend on a variety of factors including the resources available to them, the political opportunity structure within which they can advocate speci ﬁ c causes , the characteristics of the advocates, and the characteristics of the target . social movement Activists target governments, corporations, and even citizens regarding climate policies and behaviors . Scholars note that media plays an important role in amplifying the social movement s message . Climate advocates have skillfully deployed both legacy media and social media . In part, the success of media coverage translating into public support depends on how the issue gets framed . Thus, narrative control is critical for the success of climate advocacy. In recent years, given the slow pace of emission reductions, some climate groups have resorted to non-violent but disruptive (NVD) action . We view this as radical in terms of tactics, though not necessarily in terms of their goals. Moreover, we recognize that the level of radicalness of different tactics varies, in part by the response they provoke from targeted actors. The tactical objective of NVD action is to generate widespread media coverage. These activists have sometimes stopped trains or disrupted traf ﬁ c on major highways. They have blocked oil terminals or demonstrated near oil pipeline projects as in the Standing Rock protests against the Dakota Access Pipeline . For some commentators, these actions are disruptive and confrontational and not likely to generate either public sympathy or policy change. After all, a lack of public awareness is not hindering climate progress. They believe that sources of opposition to climate policy are complex, requiring careful political negotiations instead of confrontation. Social movement scholars debate whether radical actions support or subvert movement goals . After all, most social movements have mainstream and radical (both nonviolent and violent) factions. Might even nonviolent radical action provoke a countermovement or provide a pretext for governments to crack down on social movement activists? For example, in response to the picketing of oil and gas infrastructure, about 17 U.S. states have enacted critical infrastructure laws that criminalize protests against fossil fuel pipelines. Other scholars suggest that radical action might for mainstream groups and therefore lead to policy action; this is sometimes called the radical ﬂ ank effect . The idea is that radical groups make mainstream groups look more reasonable and therefore persuade public of ﬁ cials to respond to their moderate demands. Thus, the radical ﬂ ank potentially changes the political opportunity structure that mainstream groups can take advantage of. increase support Recently, climate groups such as the Extinction Rebellion, Letzte Generation, and Ultima Generazione have employed NVD tactics to draw public attention to the slow progress in reducing greenhouse gas emissions. In 2022, they began vandalizing art and museums, although in most cases the art pieces were not damaged. These actions which were carefully choreographed over social media, are designed to shock citizens, mobilize them, and compel governments to enact aggressive climate policies. Arguably, these protests should not be dismissed as emotional responses by actors with little policy radical activists professionally knowledge because sometimes Museum vandalism is predominantly a European phenomenon. These events took place in eleven countries, nine of which are in Europe: Germany Italy, the U.K., France, Spain, the Netherlands, Norway, Austria, and the Vatican. Non-European countries, Australia and Canada, account for only 10% (four of the thirtyeight) incidents. Even within Europe, 60% (23) of the incidents Italy, and the U.K. occurred in just three countries: Germany, in 2022 we did not ﬁ nd any museum vandalism Interestingly, incidents in the U.S., although some climate groups have employed disruptive tactics. Importantly, the absence of such events in the developing world which has well-established climate movements, raises important questions on how some tactics to raise public awareness might work in speci ﬁ c countries only. If museums are an important part of a country s cultural life, museum vandalism will probably receive extensive media coverage. In other countries where cultural life is located at the community level and not part of a formally organized structure, museum vandalism will probably not appear in the tactical repertoires of climate groups (Fig. 2). We ﬁ nd sixteen groups were involved in these incidents. Organized groups (as opposed to individuals) are responsible for 95% (thirty-six) of incidents and they targeted museums in their countries of origin. Even among these, three groups account for 58% of these incidents: Ultima Generazione (Italy and Vatican) is responsible for nine, Just Stop Oil (the U.K.) for seven, and Letzte Generation (Germany) for six incidents. While these groups targeted museums in the countries in which they are located, they may have some sort of coordination mechanisms as well. The reason is that these organizations are members of the A22 network (https://ultima-generazione.com/a22network/). The A22 website notes: As the Last Generation, we will do whatever it takes to protect our generation and all future generations. As is our inalienable right. The old world is dying. We are in the last hour, the darkest hour. This world is being decimated before our eyes. We are in between moments. What we do now decides the fate of both this world and the next. The Climate Emergency Fund (https://www.climateemergency fund.org/a22), which is the lead funder for the A22 group, notes: In less than a year, most A22 groups had become the most prominent climate group in their home countries. Each group generated incredible amounts of press coverage and fundamentally changed the conversation around their chosen demand. In 2022, 23,000 press stories covered these 11 groups and their evaluate policy options by employing scienti ﬁ c knowledge . Thus, the museum vandalism tactic could be viewed as part of a wellthought-out plan to mobilize public opinion against fossil fuels. How many of such incidents took place? When, where, and who was responsible? To provide a comprehensive overview of the museum vandalism tactic, we describe the key ﬁ ndings which are based on an exhaustive search of media articles and social media postings. We have posted the dataset on the Harvard (https://dataverse.harvard.edu/dataset. xhtml?persistentId doi:10.7910/DVN/SAYIJ5). We ﬁ nd that in 2022, thirty-eight incidents took place. None took place in 2021 and only three so far in 2023. Below are our key ﬁ ndings. Dataverse Almost all reported incidents seemed to have occurred during May-December 2022. The ﬁ rst museum incident took place on May 29 when an activist threw cake on the Mona Lisa in the Louvre. There were two incidents in June, ﬁ ve in July, and six in August. After a lull in September with only one recorded incident, we ﬁ nd nine incidents in October. Protests peaked in November with eleven incidents, eight of which occurred during the COP 27 conference in Sharm El Sheik, November 6 18. This suggests that activist groups, probably in some sort of informal coordination, sought to employ museum tactics to amplify the COP s climate message. Indeed, once the conference was over, museum incidents dwindled to only three in December (Fig. 1). Museum vandalism has almost stopped in 2023, with only three incidents to date: the smearing of paint over Degas Little Dancer in Washington DC and the Monet Painting at Sweden s National Museum as well as the pouring of diluted charcoal in the water of Rome s Trevi Fountain. demands! Thus, future work should examine whether speci ﬁ c acts of museum vandalism are part of a coordinated plan, or whether A22 members individually choose speci ﬁ c locations and times of action. In addition, three groups were involved in two museum incidents each, and the remaining ten engaged in one incident each. None of the legacy environmental groups (such as Greenpeace) are involved in museum protests, although historically they have staged dramatic events (such as boarding ships or unfurling banners from the top of prominent buildings) to garner media attention. This raises important questions such as whether legacy groups focus on speci ﬁ c types of NVD actions only, and why they are keeping away from the museum vandalism tactic (Fig. 3). Did these groups outline a speci ﬁ c demand? Just Stop Oil, Letzte Generation, and Ultima Generazione target the fossil fuel sector and want quick emission reductions. They typically do not advocate for a speci ﬁ c policy instrument to achieve this objective. In contrast, Scientist Rebellion, which participated in one incident, had a speci ﬁ c demand: the German government reinstate a speed limit. Futuro Vegetal, which organized two incidents, demanded the revocation of Coca-Cola s COP27 sponsorship. It appears that the less visible groups tended to make focused demand for a speci ﬁ c policy instrument or objective, while the more visible groups had a more generic message on climate change and reducing fossil fuel use. Martinez-Alier . differentiates among three types of environmentalism based on their origins, discourses, and tactics. The ﬁ rst, the Cult of Wilderness re ﬂ ects the traditional conservation movement that seeks to protect pristine nature, without paying adequate attention to who might bear the costs of such conservation measures. Second, the gospel of eco-ef ﬁ ciency advocates for ecological modernization coupled with economic and technological changes to move the modern industrial society towards sustainable development. The environmentalism of the poor, views environmental third type, problems from the prism of the poor and underprivileged whose daily lives are impacted by environmental destruction. The climate movement incorporates all three elements but where might we place museum protests? Given that these protests took place in rich countries and museums are not the sites where the livelihood of the poor (even in these countries) is impacted, they probably do not re ﬂ ect the environmentalism of the poor. Moreover, given the demand for decoupling from fossil fuels, as opposed to sustainably managing them, it also does not ﬁ t in the category of the gospel of eco-ef ﬁ ciency either. Arguably, and with some caveats, museum protests share some similarities with the conservation movement. Both seek to protect future generations by eliminating current economic activities. Conservationists sought to protect pristine nature by protecting it from logging and other economic interests. Moreover, like the conservationists, museum vandals do not pay adequate attention to distributional and justice issues (della Porta, 2015), speci ﬁ cally, how eliminating fossil fuel could increase energy costs which hurt the poor or communities dependent on the production or use of fossil fuels. Yet, unlike the conservationists, the museum vandalism movement employs outsider tactics. Its leadership is anti-establishment, as opposed to a part of it. Thus, museum vandalism, and NVD action in general, call for additional theorizing about the different types of radical tactics employed by the climate movement. This Brief Communication raises additional questions for the study of climate action. It is not clear whether museum vandalism is effective in spurring governments to adopt more aggressive climate mitigation policies, at least in the short term. On the face of it, drilling for oil and gas continues, Coca-Cola did not drop its COP 27 sponsorship, and the German government has not put speed limits on autobahns. Regarding the broader climate policy goals demanded by some groups, the effectiveness of a single tactic is dif ﬁ cult to evaluate because governments operate in a complex political environment. Moreover, with the Ukraine crisis, energy security issues may have temporarily slowed down the energy transition. What if the tactical effectiveness is evaluated in terms of the public support it generates? Many museum incidents were widely covered in both legacy and social media. Activists often made highly emotional statements. After gluing themselves to Vermeer painting in the Hague, Just Stop Oil activist said: "How do you feel when you see something beautiful and priceless apparently being destroyed before your eyes? Do you feel outraged? Good. Where is that feeling when you see the planet being destroyed?" . Some opinion polls suggest public disapproval of these tactics . it s completely nutty to German Chancellor Scholz said that somehow stick yourself to a painting or on the street . Directors of prominent museums released a statement noting: In recent in weeks, international museum collections. The activists responsible for them severely underestimate the fragility of these irreplaceable objects, which must be preserved as part of our world cultural heritage . Will climate advocacy become more radical (both in terms of tactics and goals) over time if policy progress remains sluggish? Or there have been several attacks on works of art will it shift towards more collaborative approaches to work with both governments and ﬁ rms? The picture is unclear. In January 2023, Extinction Rebellion announced that it would temporarily pause disruptive protests. Other groups, such as Just Stop Oil and Ultima Generazione, however, are continuing with this tactic. Recent examples include the attempts at disrupting the Wimbledon and the British Open. Broadly, it seems two sorts of social repertoires will continue to ﬂ ourish. Mainstream movement groups will focus on established tactics such as protests, lobbying, boycotts, divestment, and litigation. In contrast, smaller organizations with social media skills will probably selectively engage in museum protests and other forms of dramatic NVD action. It remains to be seen whether the good cop/bad cop strategy, the radical ﬂ ank effect , will increase public support for the climate goals espoused by the mainstream climate movement and motivate additional governmental response to the climate crisis. The data was collected via internet searches. No Human subjects were involved. Further information on research design is available in the Nature Research Reporting Summary linked to this article.
test_jclimate.pickle ---------- ['The Impact of Global Warming on Marine Boundary Layer Clouds over the Eastern Paciﬁc—A Regional Model Study']
5844 A L K H Y W V T. J. P R B State-of-the-art comprehensive global climate models (GCMs) display a wide range of global and regional sensitivity to imposed large-scale climate forcings. The 5845 equilibrium global surface temperature increase projected to result from a doubling of atmospheric CO concentration reported for the models in the latest Intergovernmental Panel on Climate Change (IPCC) intercomparison varies from 2.1 to 4.4 K. This range has not narrowed appreciably compared to that found in earlier model intercomparisons (e.g., Houghton et al. 2001). The variation in global climate sensitivity among these GCMs is largely attributable to differences in cloud feedbacks and feedbacks of low-level clouds in particular (e.g., Bony and Dufresne 2005; Stowasser et al. 2006; Solomon et al. 2007; Medeiros et al. 2008). Persistent stratocumulus decks found predominantly in the subtropical eastern ocean margins have a major impact on the radiation budget by reﬂecting incoming solar radiation (e.g., Randall et al. 1984; Hartmann and Doelling 1991). These clouds are prominent over cool ocean surfaces in regions where large-scale atmospheric subsidence leads to the formation of sharp temperature inversions, which trap moisture in the marine boundary layer (MBL; e.g., Albrecht et al. 1988). The simulation of these marine clouds has been a particular challenge for global and regional models (e.g., Bretherton et al. 2004; Wang et al. 2004a,b). This results in a particularly high uncertainty of the climate feedback of these low-level marine clouds (e.g., Bony and Dufresne 2005; Solomon et al. 2007). Medeiros et al. (2008) showed that trade wind cumuli might also play an important role; they are also not well captured by global climate models (Medeiros and Stevens 2009). The radiative effect of low marine clouds is dominated by their contribution to the planetary albedo as their impact on outgoing longwave radiation is limited because of the small temperature difference between cloud tops and the underlying surface. The cloud optical depth for these low-level clouds is proportional to cloud geometrical thickness, the liquid water content (LWC), and the size of the cloud droplets. There have been attempts to use empirical guidance to determine how these basic cloud properties, and hence albedo, may respond to changes in large-scale climate. The empirical relationship between cloud LWC and temperature obtained by Feigelson (1978) from aircraft measurements of midlatitude clouds for the temperature range between 25 and 5 C predicts an increase in cloud water with temperature. Somerville and Remer (1984) noted that if a constant cloud geometrical thickness for marine stratocumulus decks is assumed, a negative cloud–climate feedback would be implied (i.e., warmer temperatures would lead to more reﬂective clouds). On the other hand, studies analyzing satellite data from the International Satellite Cloud Climatology Project (ISCCP), the Advanced Very High Resolution Radiometer (AVHRR), and the Clouds and the Earth’s Radiant Energy System (CERES) indicate that cloud optical depth of low marine clouds might be expected to decrease with increasing temperature (Tselioudis et al. 1992; Greenwald et al. 1995; Chang and Coakley 2007; Eitzen et al. 2008). This suggests a positive shortwave cloud–climate feedback for marine stratocumulus decks. In a recent paper, Clement et al. (2009) analyzed several decades of ship-based observations of cloud cover along with more recent satellite observations, with a focus on the northeastern (NE) Paciﬁc between 15 and 25 N. They found that there is a negative correlation between cloud cover and sea surface temperature (SST) apparent on a long time scale—again suggesting a positive cloud– climate feedback in this region. Bony and Dufresne (2005) analyzed 17 yr of observed SST, top of atmosphere (TOA) net radiative ﬂux, and 500-hPa vertical velocity ( ) from satellite data and reanalyses, respectively. Focusing only on the ocean regions between 30 S and 30 N, they scaled the anomalies in monthly mean TOA ﬂuxes with the coincident SST anomalies. This analysis was done for grid points in different dynamical regimes deﬁned by the 500-hPa vertical velocity. They showed that the cloud feedback parameter deﬁned this way is dominated by changes to the shortwave ﬂux and that the feedbacks are positive and in the range of 0–6 W m K . The Bony and Dufresne estimate of this feedback is largest in the regions with the strongest 500-hPa subsidence (corresponding to the regions of low-level marine clouds). Of course, as emphasized by Bony and Dufresne, the cloud responses to natural interannual variations of SST may differ from the response expected to large-scale forced global warming. Cloud feedbacks have also been assessed by a number of modeling studies using a variety of models—ranging from single-column radiative–convective equilibrium models to GCMs with conventional cloud parameterizations (e.g., Somerville and Remer 1984; Xu et al. 2010; Roeckner et al. 1987; Caldwell and Bretherton 2009; Tselioudis et al. 1998; Zhang and Bretherton 2008) or to GCMs with superparameterizations in which a cloudresolving model (CRM) is run within each GCM column (e.g., Wyant et al. 2009). However, state-of-the-art GCMs display a wide range of simulated cloud–climate feedbacks in the marine stratocumulus regions. In addition, such models generally do a poor job in simulating the present-day climatology of marine stratocumulus clouds. The dynamics of marine stratocumulus clouds involve tightly coupled interactions among atmosphere, ocean, and land making them extremely challenging for climate models to capture (e.g., Bony and Dufresne 2005). Singlecolumn models and large-eddy simulations (LES) can explicitly represent detailed cloud microphysics, but the interaction between clouds and the large-scale atmospheric 5846 circulation in such models has to be prescribed or determined on the basis of simpliﬁed assumptions. This paper describes a modeling study of the response of clouds in the eastern tropical and subtropical Paciﬁc region to large-scale climate forcing. The eastern Paciﬁc region features extensive stratocumulus decks and the cloud feedbacks in this region in climate models contribute signiﬁcantly to the global mean feedbacks and climate sensitivity (e.g., Stowasser et al. 2006). For this investigation we used the version of the International Paciﬁc Research Center (IPRC) Regional Atmospheric Model (iRAM) described in Lauer et al. (2009). Lauer et al. (2009) also showed that iRAM is able to simulate a reasonable present-day seasonal climatology of stratocumulus clouds in the eastern Paciﬁc region. As part of the present study we will show that iRAM simulates the basic cloud climatology in the eastern Paciﬁc better than current GCMs. We will also show that iRAM successfully simulates the main features of the observed interannual variation of clouds in this region, including the evolution of the clouds through the ENSO cycle. Section 2 describes the regional climate model used in this study and the details of the present-day and global warming simulations. This is followed by a comparison of modeled cloud properties over the east Paciﬁc with observations in section 3. Section 4 presents the results of the cloud response to global warming. The conclusions are summarized in section 5. a. iRAM IPRC iRAM is based on the hydrostatic primitive equations and uses coordinates in the vertical (Wang et al. 2004a). All model simulations presented here were conducted at a horizontal resolution of 0.5 0.5 , with the model domain covering the tropical and subtropical eastern Paciﬁc as well as large parts of South America (40 S–40 N and 160 –50 W). There are 28 model levels from the surface up to about 10 hPa ( 30 km) with 10 levels below 800 hPa. We used the ﬁnal analysis data (FNL) from the U.S. National Centers for Environmental Prediction [(NCEP); NCEP FNL Operational Model Global Tropospheric Analyses, continuing from July 1999, are updated daily. Dataset ds083.2 is published by the Computational and Information Systems Laboratory (CISL) Data Support Section at the National Center for Atmospheric Research (NCAR), Boulder, Colorado, available online at http://dss.ucar.edu/datasets/ ds083.2/] as initial and lateral boundary conditions for the model integrations. The FNL data with a horizontal resolution of 1 1 and 26 vertical pressure levels (NCEP–NCAR reanalysis with a horizontal resolution of 2.5 2.5 and 17 pressure levels prior to the year 2000; Kalnay et al. 1996) at 6-h time intervals are interpolated linearly in time and using cubic splines to the model grid. SSTs employed are the National Oceanic and Atmospheric Administration (NOAA) analyses (Reynolds et al. 2007), which are based on daily mean satellite observations from AVHRR and the Advanced Microwave Scanning Radiometer (AMSR) instruments. The prognostic model variables are nudged to the NCEP FNL analysis data within a 10 buffer zone along the lateral boundaries. The buffer zone is not in the analyses of the results shown here. Grid-scale cloud processes are calculated using a double-moment cloud microphysics scheme with a semiprognostic aerosol component considering six aerosol species—sulfate, sea salt, soluble and insoluble organic matter, black carbon, and mineral dust (Phillips et al. 2007, 2008, 2009)—which replaces the original singlemoment cloud microphysics module of Wang (2001). The cloud microphysics scheme predicts the mass mixing ratios of water vapor, cloud liquid water, cloud ice, rain, snow, and graupel as well as the number mixing ratios of cloud droplets and ice crystals. The size distributions of cloud and precipitation particles are assumed to follow gamma distributions. Diffusional growth of cloud particles and precipitation is predicted explicitly with a linearized supersaturation scheme from the modeled updraft and properties of cloud liquid and water vapor. The predicted supersaturation is applied to calculate the activation of aerosol particles at cloud base using the aerosol activation scheme of Ming et al. (2006) or inside the cloud when supersaturation becomes high enough. Critical droplet diameters and supersaturations as well as the equilibrium supersaturations of the droplets are obtained from the -Ko¨ hler theory using the hygroscopicity parameters from Petters and Kreidenweis (2007). The autoconversion of cloud droplets to rainwater is parameterized after Liu et al. (2007). We chose the parameterization from Liu et al. (2007) over other schemes as it results in improved agreement for our regional model with a 50-km resolution between modeled and observed liquid water path (LWP) and cloud cover. Primary and secondary ice nucleation (Hallet and Mossop 1974), as well as homogeneous freezing of aerosols (Koop et al. 2000) and cloud droplets (Phillips et al. 2007), are included. All the known and empirically quantiﬁed mechanisms for initiation of cloud droplets and ice are represented (Phillips et al. 2007). The cloud microphysics module is coupled to the radiation scheme and provides effective radii of cloud droplets and ice crystals as well as the liquid water and ice content as input for the radiative transfer calculations. 5847 The radiation scheme is based on the radiation package of Edwards and Slingo (1996) with improvements by Sun and Rikus (1999). It considers four bands in the solar spectral range and seven bands in the thermal spectral range. Cloud amount is diagnosed from cloud liquid water/ice content and relative humidity following Xu and Randall (1996). Subgrid-scale convection including shallow, mid-level, and deep convection is parameterized following Tiedtke (1989) with modiﬁcations by Gregory et al. (2000). The average entrainment rate for shallow convection and relative mass ﬂux at a level of zero buoyancy (overshooting cumuli) have been adjusted using results from large-eddy simulations (Wang et al. 2004a,b). Cloud water and cloud ice detrained at the cloud tops are considered as an additional source of cloud water/ice used by the grid-scale cloud microphysics (Wang et al. 2003). The iRAM results with double-moment cloud microphysics have been compared extensively to measurements from aircraft, ships, and satellites to evaluate the model performance simulating clouds over the eastern Paciﬁc (Lauer et al. 2009). This evaluation showed that the model is able to simulate average cloud properties such as liquid water content, cloud droplet number concentration, cloud cover, and the radiative effect of clouds [also referred to as cloud radiative forcing (CRF)] that compare well with the observed climatology. Lauer et al. (2009) also showed that the diurnal cycle of cloud liquid water over the eastern Paciﬁc is reasonably well simulated by iRAM. For additional details on iRAM, we refer to Wang (2001), Wang et al. (2004a), and the literature cited therein. Additional details on the double-moment cloud microphysics scheme and a model evaluation can be found in Phillips et al. (2007, 2008, 2009) and Lauer et al. (2009), respectively. b. Model experiments In the present study, we performed two kinds of experiments: a simulation of January 1997–December 2008 using observed SSTs and lateral boundary conditions and a set of 10-yr integrations designed to simulate late twenty-ﬁrst-century conditions. For the twenty-ﬁrst-century experiments we apply what has been termed the ‘‘pseudo-global-warming’’ (PGW) method, which has been employed in other recent studies to downscale global climate change projections using a regional atmospheric model (Kimura and Kitoh 2007; Sato et al. 2007; Knutsen et al. 2008). In the PGW method, initial and lateral boundary conditions for the model integration are given by the sum of 6-h reanalysis data as used for the present-day experiment and a climate change signal based on results from a coupled global climate model (or an ensemble of such models). We based the climate change signals used in iRAM on the monthly averaged differences between present-day climate and projections for the end of the twenty-ﬁrst century made by GCMs included in the IPCC Fourth Assessment Report (AR4). Speciﬁcally, the climate change signal adopted here was computed as the difference in 10-yr means for each calendar month for the late twentieth century [1990–99 in the AR4 twentieth-century forced runs (20C3M) and for the late twenty-ﬁrst century 2090–99 in the Special Report of Emissions Scenarios (SRES) A1B runs]. Data were obtained from the World Climate Research Programme’s (WCRP’s) Coupled Model Intercomparison Project phase 3 (CMIP3) data archive (Meehl et al. 2007). Following the A1B scenario, we increased the CO concentration in iRAM from 370 ppm used in the present-day run to 720 ppm. Here, we only consider global warming perturbations of the meteorological boundary conditions [i.e., temperature, horizontal wind components, sea level pressure (SLP), and humidity] and of the SST. Concentrations of trace gases other than CO such as ozone or aerosols were not changed in our global warming simulations and remained at their present-day levels. Of course the global change signals differ quite signiﬁcantly among the CMIP–AR4 GCMs. We performed three 10-yr experiments using 1999–2008 as the base and adding different climate change signals derived from the results of the CMIP–AR4 model simulations: 1) IPCC AR4 ensemble mean (case A): The climate change signal is averaged over all 19 AR4 models (see Table 1) that provided all data needed for specifying the climate change contribution to the boundary conditions in iRAM. All model results are interpolated to the 1 1 grid and 26 pressure levels of the FNL data before averaging. 2) Canadian Centre for Climate Modelling and Analysis (CCCma) Coupled General Circulation Model, version 3.1(T63) (CGCM3.1; case B): The climate change signal is obtained from simulations with CGCM3.1 (McFarlane et al. 1992; Flato 2005) of CCCma. Among the AR4 GCMs, the CGCM3.1 has one of the higher global climate sensitivities and also has a strong positive cloud–climate feedback over the eastern Paciﬁc (see Fig. 9 below). 3) NCAR Community Climate System Model, version 3 (CCSM3; case C): The climate change signal is obtained from NCAR CCSM3 (Collins et al. 2006). Among the AR4 GCMs, the CCSM3 has one of the lower global climate sensitivities and also has a negative cloud–climate feedback over the eastern Paciﬁc (see Fig. 9 below). 5848 5849 The PGW method has some obvious limitations, notably the variability from daily to interannual periods in the boundary conditions is necessarily the same in the warming simulations and in the present-day simulation (e.g., Hara et al. 2008). We would also like to note that this study examines cloud response to a given climate change signal only. The usage of prescribed SSTs does not allow for possible atmosphere–ocean feedbacks. We expect that an interactive coupling of atmosphere and ocean could modify the climate change signals and may thus result in a different cloud response. In this section, we compare the cloud ﬁelds in our present-day iRAM simulation with observations. We compare 10-yr mean simulated values with observed climatology. We also evaluate the interannual variations in the simulation, which provides an opportunity to see how realistically the simulated clouds respond to changes in large-scale meteorological forcing. We also evaluate correlations between simulated low-level cloud amount and, for instance, sea surface temperatures, lowertropospheric stability (LTS), or 500-hPa vertical velocities. These correlations are then compared to corresponding correlations obtained from observations. a. Shortwave cloud forcing Shortwave cloud forcing (SCF) at the top of the atmosphere is calculated as the difference between all-sky and clear-sky shortwave radiation at the top of the atmosphere. Figure 1 shows a comparison of the multiyear annual average SCF from iRAM as well as from 16 IPCC AR4 models with multiyear (2000–05) satellite observations from CERES (Loeb et al. 2009). Observations show a large area of small (absolute) SCF south of the intertropical convergence zone (ITCZ) and between the western domain boundary at 150 W and about 100 W. These weakly negative SCF values correspond to a low average cloud amount over the warm-pool region. The size and extent of this area are reproduced by iRAM reasonably well, although the maximum SCF values are overestimated by about 5 W m compared with the CERES observations. The satellite data show the most negative SCF in our domain in the ITCZ and in the two stratocumulus decks off the coasts of North and South America. Here, iRAM overestimates the 5850 magnitude of the SCF in the ITCZ by about 25%, but the modeled SCF of the stratocumulus decks agrees well with the observations. However, the stratocumulus deck in iRAM over the southeastern (SE) Paciﬁc is shifted by about 9 ( 1000 km) northwestward compared with the observed, also seen in the simulated cloud liquid water and cloud cover. Lauer et al. (2009) speculated that this deﬁciency could be related to the model horizontal resolution, which leads to an overly smooth representation of the steep Andes. Table 2 summarizes the multiyear mean cloud properties averaged over the ocean region of the model domain. Speciﬁcally cloud forcing, cloud amount, liquid water path, and rain rate from iRAM are compared with satellite observations. The details of the satellite datasets used for comparison are given in the table along with relevant references. The model overpredicts the average SCF over the ocean by 7 W m and underpredicts the magnitude of the longwave cloud forcing (LCF) by 4 W m compared with satellite measurements. This overestimation in the magnitude of SCF is mainly caused by a too large (absolute) SCF in the ITCZ as well as an underprediction of the extent of the region of weak SCF associated with the warm pool. The small values of domain-averaged LCF in the model mainly reﬂect an underestimation of cirrus clouds in, and north of, the ITCZ. The difference between domain-averaged modeled and observed total cloud forcing (CF ) is about 10 W m . Figure 1 also shows that the 16 IPCC AR4 models investigated here, with the possible exception of the Met Ofﬁce (UKMO) Hadley Centre Global Environmental Model version 1 (HadGEM1) model, fail to adequately reproduce the large area of small magnitude of SCF over the warm-pool region. Among the better models in reproducing observed SCF in the ITCZ and the two stratocumulus regions are the two Geophysical Fluid Dynamics Laboratory (GFDL) models that, however, fail to reproduce the extent and position of the stratocumulus deck in the southeastern Paciﬁc. b. Cloud amount, liquid water path, and rainfall The results in Table 2 show that the domain-averaged iRAM simulated low cloud cover (35%) is in good agreement with satellite observations (33%). Here, lowlevel cloud amount refers to clouds below 680 hPa. While low-level cloud amount can be averaged over all time steps in the model, the satellite data cover only periods not obstructed by high-level clouds. This is, however, not expected to be a problem as the satellite data show only small differences between low-level and total cloud amount in the stratocumulus regions, which are the main focus of this study. The domain-averaged total cloud cover in iRAM is 48%, rather less than the 58% from the satellite climatology, a difference that reﬂects the underprediction of the cirrus clouds in and north of the ITCZ in iRAM. The modeled multiyear annual average LWP over the ocean, 63 g m , is in good agreement with 62 g m determined from satellite observations. Figure 2 shows the geographical distribution of the iRAM simulated LWP compared with observations and the 20C3M simulations in the IPCC GCMs. The iRAM captures the observed overall pattern reasonably well, whereas the IPCC models vary widely among themselves and none reproduces all the major features in the observed LWP. The domain-average rainfall rate in iRAM over the ocean is 3.4 mm day , which is considerably higher than the 2.0 mm day in the satellite-based climatology. Li and Fu (2005) showed that the rainfall climatology from the Tropical Rainfall Measuring Mission (TRMM) satellite data has lower average rain rates than the Global Precipitation Climatology Project (GPCP; Huffman et al. 1997; Adler et al. 2003), particularly over the ocean. A comparison of the geographical pattern of long-term mean rain rate with satellite observations (not shown) reveals that iRAM captures the location and intensity of the rain rate over most of the ocean reasonably well, but the belt of heavy rainfall in the ITCZ is overestimated by iRAM in both its meridional extent and its intensity. 5851 c. Low-level cloud amount and lower-tropospheric stability Observations show that the low-level cloud cover in tropical and subtropical regions is strongly correlated with LTS, deﬁned as the difference in potential temperatures at 700 hPa and the surface (LTS – ) (Slingo 1980, 1987; Klein and Hartmann 1993). For the tropical and subtropical clouds over the eastern Paciﬁc in our model domain we ﬁnd very similar correlations between observed low-level cloud amount and LTSestimated inversion strength (Wood and Bretherton 2006). In this study, we use LTS for our analysis. We combined monthly mean ISCCP satellite observations of low-level cloud amount (Rossow et al. 1996) with LTS values calculated from monthly mean NCEP ﬁnal analysis data (NCEP–NCAR reanalysis before the year 2000; Kalnay et al. 1996). The ISCCP data (2.5 2.5 ) are interpolated to the 1 1 grid of the FNL data. For comparison with results from iRAM we averaged the model data onto the 1 1 FNL grid. The black and blue dots in Fig. 3a show low-level cloud amount binned by LTS values from the combined ISCCP–NCEP dataset and from iRAM for the years 2000–07. The mean low-level cloud amount and its standard deviation are calculated for all grid cells in the whole domain (30 S–30 N and 150 –60 W) and all individual monthly means in the time period 2000–07 within the same LTS bin. The vertical bars show 1 standard deviation. The standard deviation within each LTS bin will reﬂect spatial, annual, and interannual variability. Observations and model show an approximately linear increase in low cloud amount with increasing LTS. Such a linear relationship between seasonal mean LTS and low-level cloud amount for regions in the subtropics has also been found by Klein and Hartmann (1993). A linear ﬁt to the observations in Fig. 3a has a slope of 0.031 K , which is close to the 0.030 K obtained for the present-day iRAM simulation. The range of variability of cloud amount for any given LTS value is larger in the model than in the observations. The difference even persists when the iRAM data are averaged to 2.5 resolution to be directly comparable to the ISCCP data. The corresponding probability density functions (PDFs) of monthly mean LTS from the present-day iRAM simulation and NCEP FNL data are shown as the blue and black curves in Fig. 3b. For both model and FNL data the most common LTS values are found to be in the range of 12–14 K. Maximum LTS densities are found 5852 to be at 12.8 K for NCEP FNL data and 13.2 K for the iRAM present-day simulation. The model reproduces the LTS PDF from NCEP FNL data for the east Paciﬁc region reasonably well, although the modeled distribution is wider than the observed one for small LTS values (LTS 10–12 K). Figure 3c shows the changes in the LTS–low-level cloud amount relationship between the strong El Nin˜ o year 1997 and the year 2005 (no El Nin˜ o or La Nin˜ a events) from iRAM and NCEP/ISCCP data. Average LTS and low-level cloud amount in the El Nin˜ o year were calculated for the same grid cells and months that 5853 were used to calculate low-level cloud amount for each of the year 2005 LTS bins. LTS decreases in the El Nin˜ o year for all bins with year 2005 LTS values larger than 14 K in the NCEP data and larger than 12.5 K in the model data, respectively, while corresponding low-level cloud amount decreases particularly in the LTS range most relevant for stratocumulus clouds (LTS 15 K). The displacement arrows from NCEP/ISCCP and iRAM are almost parallel within this LTS range, indicating that the model simulates the observed changes in the LTS– low-level cloud amount relationship during El Nin˜ o reasonably well. d. Interannual variations in low-level cloud amount and liquid water path To evaluate the response of the modeled low-level clouds to interannual variations in local thermal structure and circulation, we compare monthly mean cloud anomalies with other observed properties in the stratocumulus regions off the coasts of North and South America. Cloud properties of primary interest are lowlevel cloud amount and liquid water path as these are key parameters determining the cloud radiative properties. SST and LTS reﬂect the local thermal structure, while 500-hPa vertical velocities are indicative of largescale circulation changes. Figure 4 shows time series of anomalies in monthly mean low-level cloud amount, liquid water path, SST, LTS, and 500-hPa vertical velocities from iRAM in comparison with observations. Monthly mean anomalies are calculated by subtracting the average seasonal cycle calculated over the entire period. Observed low-level cloud amounts are obtained from ISCCP satellite data (Rossow et al. 1996); liquid water path from the Special Sensor Microwave Imager (SSM/I), TRMM Microwave Imager (TMI), and AMSR for Earth Observing System (AMSR-E; O’Dell 5854 et al. 2008); SSTs are taken from NOAA daily highresolution blended analyses (Reynolds et al. 2007); and LTS as well as 500-hPa vertical velocity are calculated from NCEP FNL data (NCEP–NCAR reanalysis before 2000; Kalnay et al. 1996). The time series cover the period 1997–2007 (for which we have satellite data for liquid water path and cloud cover) and are averaged over the southeastern Paciﬁc stratocumulus region (25 – 5 S, 100 –75 W, Fig. 4). The warm and cold ENSO episodes denoted by shading in Fig. 4 are based on observed Nin˜ o-3.4 SST anomalies. Even though they are averaged over a large domain, the monthly mean anomalies still show signiﬁcant variability. To reduce the noise introduced by the subseasonal variability we calculate 1-yr running means shown as thick curves in Fig. 4. SSTs in the southeastern Paciﬁc region show strong positive deviations from average values during the 1997/98 El Nin˜ o event and negative deviations from the average in the subsequent cold ENSO episode (Fig. 4c). From 2001 through 2006 SST anomalies are fairly small and it seems that the weak El Nin˜ os of 2002/03, 2004/05, and late 2006 have at most small effects on low clouds in the southeastern Paciﬁc. Both model and observations show a strong negative low-level cloud amount anomaly ( 8%) during the strong El Nin˜ o event in 1997/98 and a small positive anomaly (2%–3%) in the years 2002–04 (Fig. 4a). During the rest of the time period 1997–2007, the 1-yr running mean anomalies of observed low-level cloud amount are small. This behavior is reproduced by iRAM except for a 15-month period following the strong El Nin˜ o event of 1997/98 where the model predicts a positive low-level cloud amount anomaly of 4%. Anomalies in the liquid water path show a high positive correlation with low-level cloud amount anomalies (Fig. 4b). The top part of Table 3 shows correlations of the time series of the southeastern Paciﬁc region mean value of low cloud amount with other quantities averaged over the same region (using the 1-yr running mean of all quantities). The correlations of observed and modeled low-level cloud amount and LWP are 0.85 and 0.89, respectively. SST is strongly anticorrelated with observed and modeled low-level cloud amount with correlations coefﬁcients of 0.81 and 0.75, respectively. Figure 4d shows a comparison of modeled LTS anomalies with those calculated from NCEP data. The 1-yr running mean from iRAM agrees reasonably well with the FNL data, showing smaller than average LTS values between 1997 and 2001 and larger than average values thereafter. Earlier observational studies have shown that LTS is strongly correlated with subtropical low-level stratocumulus cloud fraction (Slingo 1980, 1987; Klein and Hartmann 1993). Correlation coefﬁcients for the modeled and FNL LTS with low-level cloud amount over the southeastern Paciﬁc stratocumulus region are 0.81 and 0.80, respectively. By contrast, 500-hPa vertical velocities (Fig. 4e) have a much weaker correlation with low-level cloud amount anomalies over the east Paciﬁc stratocumulus regions during the period studied here. Table 3 also gives the correlation coefﬁcient with domain-averaged SLP, which is 0.69 in observations but much smaller (0.19) in the iRAM simulation. We repeated this analysis for the averages over the northeastern Paciﬁc stratocumulus region (20 –30 N, 120 –130 W). In this region as well, there is a correlation of the SST with the ENSO state, notably with anomalously warm surface waters during the 1997/98 El Nin˜ o and cold water during 1999. The correlation coefﬁcients of low cloud amounts averaged over 20 –30 N, 120 – 130 W, with SST, LWP, LTS, SLP, and midtropospheric vertical velocity, are given in the bottom part of Table 3. These correlations are similar in the observations and in the iRAM simulation. The ability of iRAM to reproduce the interannual variations of cloud properties in stratocumulus regions through the ENSO cycle is much better than that of typical current coupled GCMs. Clement et al. (2009) showed that many global models have difﬁculties even in reproducing the correct sign of the correlations between cloud properties and meteorological quantities that we show in Table 3. Of course, the results in Fig. 4 and Table 3 involve iRAM run with prescribed SSTs and lateral boundary conditions and might be more directly comparable to prescribed SST GCM simulations than free-running coupled GCMs. However, the reality is that climate change experiments in AR4 have been performed with models that have poor representation of 5855 the mean cloud climatology in the eastern Paciﬁc stratocumulus regions and do not reproduce the connections between tropical and subtropical clouds and large-scale meteorological variables (e.g., Stowasser and Hamilton 2006; Clement et al. 2009). The much better cloud representation for current climate in iRAM provides the motivation for conducting the climate change experiments described in the next section. a. iRAM global warming simulations We estimate the response of clouds to global warming by calculating the differences between each of the three global warming cases A–C (see section 2) and our present-day reference experiment. We compare 10-yr means for each case [i.e., including only the last 10 yr (1999–2008) of the control run]. Figure 5 shows changes in low-level cloud amount as well as the imposed changes in SST for all three global warming cases. Also shown is the local cloud feedback parameter calculated as the change in net cloud forcing (CF ) divided by the change in surface temperature T : CF T . (1) The net cloud forcing is calculated as the sum of SCF and LCF, where SCF and LCF are calculated as the difference between the all-sky and clear-sky shortwave and longwave radiation at the top of the atmosphere, respectively. Negative values correspond to a cooling effect on the climate system. Although this deﬁnition 5856 [Eq. (1)] of the cloud feedback parameter depends on changes in both cloud and clear-sky properties, such as changes in water vapor, temperature, or surface albedo (Soden et al. 2004), it is commonly used to diagnose global climate simulations because its calculation is straightforward and the cloud forcing deﬁned in this way can be estimated in a fairly direct way from observations (Bony et al. 2006). The spatial structure of the late twenty-ﬁrst-century SST warming patterns taken from the multimodel ensemble (case A), CGCM3.1 (case B), and CCSM3 (case C) are rather similar, but the overall magnitude of the warming differs quite signiﬁcantly among the cases (largest for CGCM3.1, smallest for CCSM3). In each case, the largest warming occurs in the equatorial east Paciﬁc and the smallest warming occurs in the southernmost part of our model domain between 20 and 30 S. Changes in the amount of low-level marine clouds calculated by iRAM in response to the global warming signals (cases A–C) have similar geographical patterns showing a strong decrease of 5%–10%, particularly in the two stratocumulus regions, and an increase in lowlevel cloud amount in the range of 2%–8% over the equatorial Paciﬁc between 150 and 100 W. Consistent with the amplitudes of the imposed global warming signals, case B shows the largest decrease in low-level cloud amount in both horizontal extent and amplitude, whereas case C has the smallest cloud response. The local cloud feedback parameters [Eq. (1)] are shown in the bottom panels of Fig. 5 and basically scale the cloud changes (speciﬁcally in shortwave cloud forcing) by the imposed SST changes. The feedback parameters are quite similar in cases A–C and are in the range of 4–7 W m K in the stratocumulus regions, 2 to 4 W m K over the equatorial Paciﬁc between 150 and 100 W, and about 1 W m K over much of the rest of the Paciﬁc. Clement et al. (2009) estimate a warming effect from changes in net cloud forcing because of changes in SST in the northeast Paciﬁc stratocumulus region (15 –25 N, 115 –145 W) of about 6 W m K . This observation-based estimate compares reasonably well to results from iRAM ranging between 4.2 and 5.9 W m K averaged over the same region (global warming cases A–C). As noted above, there is a strong similarity in the feedback parameters among the cases A–C, despite the different warming increments imposed in SST. However, it is possible that the close agreement in may depend on the overall geographic pattern of SST warming being similar among the three cases. This issue was investigated in a fourth experiment in which a uniform 2-K warming was applied to the sea surface throughout the domain and through the depth of the atmosphere on the lateral boundaries. The distribution in that experiment (not shown) was indeed rather different from that seen in cases A–C (the domain-average feedback in this uniform warming case was 3 W m K ). The red dots in Fig. 3a show the dependence of lowlevel cloud amount on LTS in the global warming simulation case A. The mean relation between LTS and low-level cloud amount is signiﬁcantly different in the perturbed climate from that in the control run. Speciﬁcally, in the warmer climate there are systematically smaller low-level cloud amounts for any given LTS value, except for a narrow region around LTS 14.5 K. Also the slope of the linear ﬁt to results from the global warming scenario (0.025 K ) is somewhat smaller than that for the present-day model results or from observations. The model results suggest that the average relation between LTS and low-level cloud amount obtained from present-day observations over the east Paciﬁc can change signiﬁcantly in an altered climate. Application of simple models (e.g., Miller 1997) or parameterizations of the boundary layer cloud amount based on the observed present-day relation between LTS and low-level cloud cover may not be appropriate for climate change scenarios. The red curve in Fig. 3b shows the LTS PDF in the global warming simulation case A—compared with the present-day result there is a shift toward higher LTS values. Figure 3d shows the changes in the LTS–lowlevel cloud amount relationship between our presentday simulation and global warming case A. As for the 1997/98 El Nin˜ o case discussed above (Fig. 3c), average LTS and low-level cloud amount in the global warming case were calculated for the same model grid cells and months that were used to calculate low-level cloud amount for each of the present-day LTS bins. In other words, the blue dots for the present-day simulation in Fig. 3d are identical with the ones in Fig. 3a, whereas the red dots show LTS and low-level cloud amount values averaged over the same model grid cells but for the global warming case A. LTS increases in the global warming scenario for all bins while low-level cloud amount decreases for bins with present-day LTS values smaller than 13 K or larger than 16 K. However, lowlevel cloud amount remains close to its present-day level for the bins in the LTS range 13–16 K. Here, the increase in low-level cloud amount in the equatorial region between 150 and 100 W (see Fig. 5) balances approximately the decrease in low-level cloud amount within the same LTS range over other parts of the ocean. The general increase in average LTS is consistent with the reduction in mean tropospheric lapse rates and increased dry stability, which are robust predictions from current GCMs in a warmed climate. 5857 Figure 6 shows the mean diurnal cycles of cloudbottom and cloud-top heights for the core regions of the stratocumulus regimes over the northeastern (20 – 30 N, 120 –130 W) and southeastern Paciﬁc (25 –5 S, 85 –95 W). We deﬁne cloud-bottom height as the lowest level between the surface and 4 km at which the monthly mean cloud liquid water content exceeds 0.025 g kg and cloud-top height as the highest level at which LWC falls below this threshold value. The results shown have been averaged over the whole 10-yr period of the presentday simulation and the global warming scenario case A. While the cloud-bottom heights in the stratocumulus regions change only modestly, the average cloud-top heights in the global warming case (A) are about 50– 100 m lower compared with those of the present-day scenario. The vertical model resolution in the vicinity of the cloud tops over the northeastern Paciﬁc is about 200 m and over the southeastern Paciﬁc about 300 m. The overall thinning of the stratus cloud in the global warming case is consistent with the reduction in cloud shortwave forcing. To provide the thermal structure context for the cloud changes, an analysis of the vertical temperature proﬁle and lapse rate in the iRAM experiments is conducted. Conventional averaging with the vertical coordinate ﬁxed in time and horizontal space will blur any marked feature of the vertical structure that is strongly variable in time (and horizontal space; Birner 2006). This blur effect makes the temperature inversion atop the MBL in the east Paciﬁc region hard to see in a multiyear climatology. Following the approach adopted by Birner (2006) to characterize behavior near the tropopause, we use the inversion layer base height as a common reference level to composite all temperature proﬁles. This is done by introducing a modiﬁed vertical coordinate deﬁned as z z with z as altitude and z as inversion layer base height. The data are interpolated from model levels onto vertical levels in z z with a cubic spline interpolation. Proﬁles that do not contain a temperature inversion in the lower troposphere (0–3 km) are not included in the average. The inversion layer base height is taken as the minimum temperature in this altitude range calculated from daily mean temperature proﬁles. Figure 7 (left panel) shows the results for the composited temperature proﬁles. We added the average of the inversion layer base height to the vertical coordinates shown in Fig. 7. The right panel of Fig. 7 shows the corresponding lapse rates ( dT / dz ). The mean inversion heights in the presentday iRAM simulation are about 1.4 km in the southeast Paciﬁc region and 0.7 km in the northeast Paciﬁc region. These are somewhat lower than the mean cloud-top heights presented in Fig. 6 (1.6 km and 1.0 km) as the mean heights for the clouds were computed including occasions when there is no well-deﬁned inversion and also depend on the threshold value for monthly mean LWC (see above). The drop in diurnal mean cloud heights by about 100 m in the southeast Paciﬁc and 50 m in the northeast Paciﬁc (Fig. 6) in the global warming simulation is paralleled by the very similar reductions in the mean inversion heights (Fig. 7). In contrast, our sensitivity experiment with a uniform 2 K increase in SST throughout the domain and in atmospheric temperatures on the lateral boundaries shows only a little change or slight increase in inversion layer base heights in the stratocumulus regions. This suggests that the reduction in mean tropospheric lapse rates predicted by the GCMs in a warmed climate (cases A–C) is important for the shallowing of the marine boundary layer in these regions. Analysis of the entrainment rates at the top of the boundary layer shows that entrainment in the global warming run is reduced by 9% in the northeast and by 12% in the southeast Paciﬁc stratocumulus region compared with the present-day simulation. Reduced entrainment could be a reason for the reduction in boundary layer height (e.g., Stevens 2006), causing the inversion 5858 to drop and the clouds to thin. Consistent with Caldwell and Bretherton’s (2009) hypothesis that a decreased radiative cooling of the boundary layer in an enhanced greenhouse case could cause the inversion to drop, we ﬁnd average turbulent kinetic energy (TKE) is less in our global warming run in both stratocumulus regions. In addition to less turbulence, entrainment could also be reduced by greater inversion strength in the global warming case particularly in the southeastern Paciﬁc stratocumulus region (see also Fig. 7). b. Comparison with IPCC model results We calculated the local feedback parameters for all 16 IPCC AR4 models that provided both TOA clear-sky and all-sky ﬂuxes needed to compute TOA cloud forcings [Eq. (1)]. Just as for the other aspects of the global warming signal (see section 2), we calculate the change in cloud forcing due to global warming by subtracting 10-yr averages for the present-day simulation (experiment 20C3M, years 1990–99) from projections for the end of the twenty-ﬁrst century (SRES scenario A1B years 2090–99). Figure 8 shows a comparison of from IPCC AR4 models with the results from iRAM for global warming case A. The geographical patterns as well as the amplitudes of the local feedback parameters vary widely among the IPCC AR4 models. Of the 16 IPCC models, six of them [Centre National de Recherches Me´ te´ orologiques Coupled Global Climate Model, version 3 (CNRM-CM3); Institute of Numerical Mathematics Coupled Model, version 3.0 (INM-CM3.0); L’Institut Pierre-Simon Laplace Coupled Model, version 4 (IPSL CM4); ECHAM5–Max Planck Institute Ocean Model (MPI-OM); the third climate conﬁguration of the Met Ofﬁce Uniﬁed Model (UKMO HadCM3); and UKMO HadGEM1] simulate fairly strong positive local feedback parameters throughout most of the stratocumulus regions. By contrast, the Commonwealth Scientiﬁc and Industrial Research Organisation Mark version 3.5 (CSIRO-Mk3.5) and CCSM3 simulate fairly strong negative local feedback parameters in the two stratocumulus regions. The other IPCC models have feedback parameters in the stratocumulus areas that are either quite small (CGCM3) or that vary in sign through these regions. In other parts of the domain shown in Fig. 8 the simulated local feedback parameter differs greatly among the IPCC models. While the IPCC models disagree widely among themselves, none of the GCM simulated patterns of compare well with that in the iRAM simulation. The domain-averaged from iRAM is 1.8 W m K for global warming case A (1.9 W m K when averaged over ocean grid cells only). This positive feedback parameter mainly reﬂects the decrease in shortwave cloud forcing resulting from decreased low-level cloud amount and liquid water path. The response of clouds to global warming in cases B and C gives similar domain-averaged local feedback parameters of 1.8 and 1.9 W m K (2.1 and 2.0 when averaged over ocean grid cells only), respectively, even though the amplitude of the global warming signals varies signiﬁcantly among these cases. The domain-averaged changes in shortwave and net cloud forcing as well as the local feedback parameters for all global warming cases are summarized in Table 4. 5859 The light gray bars in Fig. 9 compare the local feedback parameters from the IPCC AR4 models averaged over the domain of the regional model (30 S–30 N, 150 –60 W) with iRAM. The domain-averaged feedback parameter simulated by iRAM is higher than that simulated by any of the 16 IPCC AR4 models. Out of the 16 IPCC models, 10 simulate positive feedback parameters for the east Paciﬁc region, and 6 predict a negative domain-averaged feedback parameter. The dark gray bars in Fig. 9 show the feedback parameter for each of the IPCC models averaged over the entire tropical– subtropical belt (30 S–30 N, 0 –360 ). The mean feedbacks in the entire tropical–subtropical belt in each model are fairly closely related to those for the east Paciﬁc domain (the correlation coefﬁcient over the 16 models is 0.95). The east Paciﬁc cloud feedbacks in the GCMs also correlate reasonably well with the equilibrium global climate sensitivities given in Table 8.2 of Solomon et al. (2007). The GCMs that have the highest east Paciﬁc cloud feedback (and hence are closest to the iRAM result) are the Model for Interdisciplinary Research on Climate 3.2 (MIROC3.2), IPSL-CM4, and UKMO-HadGEM1. These (along with the medium-resolution version of MIROC3.2 not considered in this paper) are the GCMs with the highest global climate sensitivity according to the IPCC Table 8.2. It may also be noted that UKMO-HadGEM1 was identiﬁed by Clement et al. (2009) as the GCM that 5860 had the most realistic cloud responses to variations in the large-scale environment. We have examined the cloud simulations and cloud– climate feedbacks in the tropical and subtropical eastern Paciﬁc region in 16 state-of-the-art coupled GCMs and in the regional atmospheric model iRAM using prescribed boundary conditions. We ﬁnd that the simulation of the mean cloud climatology for this region in the GCMs is very poor. The cloud feedbacks to imposed climate forcings vary widely among the GCMs in the east Paciﬁc and in the 30 N–30 S band in general. These variations account for a large fraction of the uncertainty in global climate sensitivity. Following Lauer et al. (2009), we have found that iRAM forced with observed boundary conditions simulates rather realistic mean cloud ﬁelds in the east Paciﬁc domain. Going beyond the earlier analysis of Lauer et al., we have also shown that the iRAM reproduces the observed interannual variations in cloud ﬁelds (as well as LTS), notably correctly simulating the response of the clouds through the 1997–99 El Nin˜ o to La Nin˜ a transition. By contrast, Clement et al. (2009) note that low clouds in GCMs generally do not respond realistically through the ENSO cycle. To investigate cloud feedbacks in iRAM, three global warming scenarios have been run with SSTs and horizontal boundary conditions meant to be appropriate for late twenty-ﬁrst-century conditions; speciﬁcally, warming signals based on IPCC AR4 SRES A1B simulations from 1) an ensemble mean of 19 GCMs, 2) the CGCM3.1 model, and 3) the CCSM3 model. All three global warming cases simulated with iRAM show a distinct reduction in low-level cloud amount particularly in the stratocumulus regime, resulting in positive local feedback parameters in these regions in the range of 4–7 W m K . The model results suggest that the reduction in stratocumulus clouds because of global warming is caused by a drop in average inversion layer base height and a consequential decrease in cloud-top height. As the cloud-base height remains approximately unchanged the decrease in cloud-top height causes the stratocumulus clouds to thin and liquid water path to decrease. This results in a less efﬁcient reﬂection of solar radiation and a reduction in shortwave cloud forcing— domain-averaged feedback parameters from iRAM range between 1.8 and 1.9 W m K (cases A–C). We have analyzed the relation between monthly mean low-level cloud cover and LTS in our iRAM simulations. The present-day simulation reproduces quite well the long-term mean relation in observations (NCEP data and satellite cloud retrievals). In both present-day iRAM simulation and observations, the El Nin˜ o perturbations in cloud cover are largely accounted for by the reduction in LTS. By contrast, in the global warming simulation the clouds and thermal structure change in such a way that the cloud cover versus LTS relation is signiﬁcantly different from the present-day simulation. This suggests that the decrease in low-level cloud amount during the 1997/98 El Nin˜ o, and the decrease because of global warming by doubled CO , is controlled by different physical processes as proposed by Zhu et al. (2007). Furthermore, this shows rather dramatically the inadequacy of cloud parameterization schemes based purely on present-day empirical relations between cloud cover and large-scale environmental ﬁelds. The cloud–climate feedback averaged over the east Paciﬁc region has also been calculated from SRES A1B simulations for 16 AR4 GCMs. The GCM feedbacks vary from 1.0 to 1.3 W m K , which are all less than the 1.8 to 1.9 W m K obtained in the comparable iRAM simulations. The iRAM results by themselves 5861 cannot be connected deﬁnitively to global climate feedbacks, but we have shown that among the GCMs the cloud feedbacks averaged over 30 S–30 N and the equilibrium global climate sensitivity are both correlated strongly with the east Paciﬁc cloud feedback. To the extent that iRAM results for cloud feedbacks in the east Paciﬁc are credible, they provide support for the high end of current estimates of global climate sensitivity. Acknowledgments. This research was supported by the Japan Agency for Marine-Earth Science and Technology (JAMSTEC), by NASA through Grant NNX07AG53G, and by NOAA through Grant NA09OAR4320075, which sponsor research at the International Paciﬁc Research Center. This research was also supported by NOAA/ CPPA Grant NA07OAR4310257 and DOE Regional and Global Climate Modeling (RCGM) Program Grant ER64840. NCEP FNL data for this study are from the Research Data Archive (RDA), which is maintained by CISL at NCAR. NCAR is sponsored by the National Science Foundation (NSF). NCEP–NCAR reanalysis data have been provided by the NOAA/OAR/ESRL PSD, Boulder, Colorado, available online from their Web site at http://www.cdc.noaa.gov/. We acknowledge the modeling groups, the Program for Climate Model Diagnosis and Intercomparison (PCMDI) and the WCRP’s Working Group on Coupled Modelling (WGCM) for their roles in making available the WCRP CMIP3 multimodel dataset. Support of this dataset is provided by the Ofﬁce of Science, DOE. STOP CONTENT EXTRACTION HERE IN THE NAME OF GOD
